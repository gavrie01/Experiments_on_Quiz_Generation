{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are downloading PDF file, converting it to TXT and doing some \"pre-cleaning\": removing not meaningful parts of document and leaving just the most valuable leftovers for our future generator.\n",
    "THe outcome of the below code is pre-processed but still raw data.\n",
    "\n",
    "\n",
    "\"extracted_text\" variable has \"StringIO\" type: The StringIO object is part of Python's io module and is a class that provides an in-memory file-like object that can be used for reading from or writing to strings as if they were files. It allows you to treat strings as file-like objects, which can be useful in various situations, such as when you want to read from or write to a string in a way that mimics file operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of libraries\n",
    "from io import StringIO # extracted_text is the main variable, contains the whole text of document in stringIO format in memory\n",
    "import requests\n",
    "import re  # provides reg. exp. support\n",
    "import math\n",
    "import api\n",
    "from selenium import webdriver\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "#import fitz\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "#from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import sentencepiece\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, BertForQuestionAnswering, BertTokenizer, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "#from transformers import AutoTokenizer\n",
    "from keybert import KeyBERT\n",
    "import gradio as gr # UI part for the quize\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import fuzzywuzzy\n",
    "\n",
    "# libraries for conversion from csv to json, results of \"Flag\" button click CSV -> JSON\n",
    "import csv\n",
    "import json\n",
    "import socket #search for port\n",
    "#import pickle #decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/ad/97/b8253236dfedb9094f4273393a3fd03997da81f27f15822e56128da894ae/gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\elena\\anaconda3\\envs\\qgmc\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\elena\\anaconda3\\envs\\qgmc\\lib\\site-packages (from gensim) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\elena\\anaconda3\\envs\\qgmc\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB 1.9 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/24.0 MB 1.2 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 0.1/24.0 MB 1.2 MB/s eta 0:00:20\n",
      "    --------------------------------------- 0.3/24.0 MB 1.7 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.4/24.0 MB 1.6 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.5/24.0 MB 1.9 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.7/24.0 MB 2.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.8/24.0 MB 2.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.1/24.0 MB 2.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.3/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.6/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.7/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.9/24.0 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.0/24.0 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.3/24.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.8/24.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 3.0/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.3/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.5/24.0 MB 3.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.7/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.9/24.0 MB 3.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.1/24.0 MB 3.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.4/24.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.6/24.0 MB 3.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.0/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.1/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.4/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.6/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.9/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.1/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.1/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.5/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.0/24.0 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.2/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.5/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.8/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.0/24.0 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.2/24.0 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.6/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.8/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.0/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.2/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.4/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.5/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.8/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.1/24.0 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.6/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.8/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 10.9/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.2/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.3/24.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.5/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.6/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.9/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.1/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.3/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.5/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.8/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.0/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.2/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.7/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.0/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.1/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.4/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.6/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.9/24.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.1/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.3/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.4/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.6/24.0 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 15.8/24.0 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.0/24.0 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.2/24.0 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.7/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.5/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.7/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.0/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.2/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.5/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.7/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.0/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.1/24.0 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.3/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.4/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.5/24.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 19.9/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.0/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.4/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.9/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.0/24.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.3/24.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.7/24.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.9/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.4/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.7/24.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.9/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.2/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.4/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install PyMuPDF # this is fitz\n",
    "#!pip install gradio\n",
    "#!pip install keybert\n",
    "#!pip install sentencepiece\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113747"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading pdf to '/data/' folder\n",
    "url = 'https://astqb.org/assets/documents/ISTQB_CTFL_Syllabus-v4.0.pdf'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('data/ISTQB_CTFL_Syllabus-v4.0.pdf', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r\"Page \\d{4,74} of 74\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' saved to 'data/ISTQB_CTFL_Syllabus-v4.0.txt'\n"
     ]
    }
   ],
   "source": [
    "#converting pdf to text and saving into .txt file initial version\n",
    "output_string = StringIO()\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0.txt'\n",
    "with open('data/ISTQB_CTFL_Syllabus-v4.0.pdf', 'rb') as in_file, open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "    # Getting the extracted text from StringIO, it means the entire text extracted from the PDF is stored as a single string in memory.\n",
    "    extracted_text = output_string.getvalue()\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "\n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "\n",
    "\n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of string in bytes : 198489\n",
      "File size, document contains 70+ pages:  193.84 KB\n"
     ]
    }
   ],
   "source": [
    "# let us check size of StringIO on the full size of converted file, just out of curiosity\n",
    "size_bytes = len(extracted_text.encode('utf-8'))\n",
    "print ('The length of string in bytes : ' + str (size_bytes))\n",
    "\n",
    "# function's code is taken from stackoverflow ---\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "# ---\n",
    "print(\"File size, document contains 70+ pages: \", convert_size(size_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.1 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v01.txt'\n"
     ]
    }
   ],
   "source": [
    "# Looking up for the text to remove everything before it\n",
    "target_text = \"1.1. What is Testing?\"\n",
    "\n",
    "# Finding the position of the target text in the extracted text\n",
    "start_position = extracted_text.find(target_text)\n",
    "\n",
    "# Checking if the target text was found, just in case\n",
    "if start_position != -1:\n",
    "    # Removing everything before the target text\n",
    "    extracted_text = extracted_text[start_position:]\n",
    "\n",
    "\n",
    "# let us save the content to .txt file with prefix '_v0.1' for further debugging purpose and human evaluation process\n",
    "\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v01.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "\n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "\n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.1 saved to '{output_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing empty lines\n",
    "# _ - is iterator, if s.strip(): This part of the list comprehension checks whether the line s contains any non-whitespace characters. \n",
    "# If it does, the line is included in the resulting list.\n",
    "\n",
    "# extracted_text = \"\".join([_ for _ in extracted_text.strip().splitlines(True) if _.strip()])\n",
    "# \n",
    "# output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v02.txt'\n",
    "# with open('data/ISTQB_CTFL_Syllabus-v4.0_v01.txt', 'rb') as in_file, open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    " #   Writing the extracted text to the output file\n",
    "    # out_file.write(extracted_text)\n",
    "# \n",
    "#Closing the stream\n",
    "# output_string.close()\n",
    "# \n",
    "#Printing message to indicate that the text has been saved to the file\n",
    "# print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.2 saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.3 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v03.txt'\n"
     ]
    }
   ],
   "source": [
    "# Removing text from 'Page 56 of 74' till the end of the text\n",
    "\n",
    "# Looking up for the text to remove everything after it\n",
    "target_text = \"Page 56 of 74\"\n",
    "#print(extracted_text)\n",
    "# Finding the position of the target text in the extracted text\n",
    "end_position = extracted_text.find(target_text)\n",
    "\n",
    "# Checking if the target text was found, just in case\n",
    "if end_position != -1:\n",
    "    # Removing everything before the target text\n",
    "    extracted_text = extracted_text[:end_position]\n",
    "\n",
    "\n",
    "# let us save the content to .txt file with prefix '_v0.1' for further debugging purpose and human evaluation process\n",
    "\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v03.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "\n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "\n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.3 saved to '{output_file_path}'\")\n",
    "#print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your stop words list\n",
    "# stop_words = [\"v4.0\", \"Page\", \"74\", \"18\", \"15\", \"of\", \"2023-04-21\", \"©\", \"Certified Tester\", \"Foundation\", \"Level\", \"International Software Testing Qualifications Board\"]\n",
    "# \n",
    "#Split the extracted_text into words\n",
    "# words = extracted_text.split()\n",
    "# \n",
    "#Filter out words that are in the stop words list\n",
    "# filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "# \n",
    "#Join the filtered words back into a text\n",
    "# extracted_text = \" \".join(filtered_words)\n",
    "# \n",
    "#Print the cleaned text\n",
    "#print(extracted_text)\n",
    "# \n",
    "# \n",
    "# output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v05.txt'\n",
    "# with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "#    Writing the extracted text to the output file\n",
    "    # out_file.write(extracted_text)\n",
    "# \n",
    "#Closing the stream\n",
    "# output_string.close()\n",
    "# \n",
    "#Printing message to indicate that the text has been saved to the file\n",
    "# print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.5 saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case all words in stringIO\n",
    "#extracted_text = extracted_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#punctuation\n",
    "# Load the language model\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text with SpaCy\n",
    "###doc = nlp(extracted_text)\n",
    "\n",
    "# Create a list of tokens that are not punctuation\n",
    "#filtered_tokens = [token.text for token in doc if not token.is_punct]\n",
    "\n",
    "# Join the filtered tokens back into a text\n",
    "#extracted_text = \" \".join(filtered_tokens)\n",
    "\n",
    "# Print the text without punctuation\n",
    "#print(extracted_text)\n",
    "\n",
    "#output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v04.txt'\n",
    "#with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "#    out_file.write(extracted_text)\n",
    "\n",
    "# Closing the stream\n",
    "#output_string.close()\n",
    "\n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "#print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.1 saved to '{output_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment#\n",
    "\n",
    "## Define the stop words list\n",
    "#stop_words = [\n",
    "#    \"©\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", r\"\\b20\\b\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"International Software Testing Qualifications Board Certified Tester Foundation Level\", \"21.04.2023\", \"01.07.2021\", \"11.11.2019\", \"27.04.2018\", \"1.04.2011\", \"30.03.2010\", \"01.05.2007\", \"01.07.2005\", \"25.02.1999\", \"the\", \"market\", \"(\", \")\", \"in\", \"or\"]#\n",
    "\n",
    "## Split the extracted_text into words\n",
    "#words = extracted_text.split()\n",
    "##print (words)#\n",
    "\n",
    "## Initialize an empty list to store the filtered words\n",
    "#filtered_words = []\n",
    "## Iterate through the words in the extracted_text#\n",
    "\n",
    "#filtered_words = [word for word in words if word not in stop_words]#\n",
    "\n",
    "## Join the filtered words back into a text with spaces and line breaks\n",
    "#extracted_text = \" \".join(filtered_words)#\n",
    "#\n",
    "#\n",
    "\n",
    "## Join the filtered words back into a text\n",
    "#extracted_text = \" \".join(filtered_words)\n",
    "##print(extracted_text)#\n",
    "\n",
    "#output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v05.txt' \n",
    "#with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "#    # Writing the extracted text to the output file\n",
    "#    out_file.write(extracted_text)\n",
    "#output_string.close()\n",
    "# \n",
    "## Printing message to indicate that the text has been saved to the file\n",
    "#print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.5 saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results, looks like some parts are not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.5 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v05.txt'\n"
     ]
    }
   ],
   "source": [
    "# built by chatgpt on provided context from my side, I used a part of text of file above, reviewed and customized by me as well\n",
    "#stop_words = [\"buxton\", \"a\", \"about\", \"above\", \"additional\", \"an\", \"and\", \"another\", \"are\", \"as\", \"be\", \"being\", \"by\", \"can\", \"common\", \"commonly\", \"do\", \"does\", \"each\", \"even\", \"for\", \"from\", \"has\", \"have\", \"in\", \"including\", \"is\", \"it\", \"its\", \"it's\", \"many\", \"may\", \"more\", \"most\", \"not\", \"of\", \"74\", \"often\", \"on\", \"or\", \"over\", \"such\", \"than\", \"that\", \"the\", \"there\", \"these\", \"this\", \"to\", \"under\", \"was\", \"we\", \"what\", \"when\", \"which\", \"who\", \"why\", \"will\", \"with\", \"within\", \"work\", \"you\", \"2023\", \"04\", \"21\", \"v4.0\", \"page\", \"2023-04-21\", \"©\", \"international\", \"qualifications\", \"board\", \"certified\", \"tester\",  \"foundation\", \"level\", \"FL-\", \"K2\", \"see\", \"section\" , \"didn't\", \"doesn't\", \"don't\", \"i.e.\", \"it's\", \"let's\", \"that's\", \"there's\", \"they're\", \"you're\", \"e.g.\"]\n",
    "stop_words = [ \"©\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", r\"\\b20\\b\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\",\n",
    "              \"37\", \"38\",\"39\", \"40\",\"41\", \"42\",\"43\", \"44\",\"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \n",
    "              \"International Software Testing Qualifications Board Certified Tester Foundation Level\", \"21.04.2023\", \"01.07.2021\",\n",
    "              \"11.11.2019\", \"27.04.2018\", \"1.04.2011\", \"30.03.2010\", \"01.05.2007\", \"01.07.2005\", \"25.02.1999\", \"the\", \"market\", \"(\", \")\", \"in\", \"or\"]\n",
    " \n",
    "# Regular expression pattern to match phrases like \"15 74\", \"16 74\", ..., \"54 74\"\n",
    "pattern = re.compile(r\"(?s)^v4.0.*Foundation Level$\", re.DOTALL)\n",
    "# Split the extracted_text into words\n",
    "words = re.split(r'\\s+', extracted_text)\n",
    "# \n",
    "# Filter out words that match the regular expression pattern or are in the stop words list\n",
    "filtered_words = [word for word in words if not re.match(pattern, word) and word.lower() not in stop_words] #match\n",
    "# Join the filtered words back into a text\n",
    "extracted_text = \" \".join(filtered_words)\n",
    "\n",
    "# Ph. removal\n",
    "phrase_to_remove = \"International Software Testing Qualifications Board Certified Tester Foundation Level\"\n",
    "phrase_to_remove_v = \"v4.0 Page of 74 2023-04-21\"\n",
    "\n",
    "# Replace the phrase with an empty string and comas removal (across the whole text)\n",
    "extracted_text = extracted_text.replace(phrase_to_remove, \"\")\n",
    "#extracted_text = extracted_text.replace(\",\", \"\")\n",
    "extracted_text = extracted_text.replace(phrase_to_remove_v, \"\")\n",
    "# Regular expression pattern to match and remove text inside brackets and brackets as well\n",
    "pattern_brackets = r'\\([^)]*\\)'\n",
    "\n",
    "# removal of text inside brackets and brackets\n",
    "extracted_text = re.sub(pattern_brackets, '', extracted_text)\n",
    "\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v05.txt' \n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "output_string.close()\n",
    " \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.5 saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r'[0-9]'\n",
    "\n",
    "# Match all digits in the string and replace them with an empty string\n",
    "#extracted_text = re.sub(pattern, '', extracted_text)\n",
    "\n",
    "#extracted_text = ''.join((x for x in extracted_text if not x.isdigit()))\n",
    "\n",
    "\n",
    "#output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v06.txt'\n",
    "#with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "#    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "#output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "#print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.6 saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Load the language model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Your text\n",
    "# text = extracted_text\n",
    "\n",
    "# # Process the text with SpaCy\n",
    "# doc = nlp(text)\n",
    "\n",
    "# # Create a StringIO object to store the NER results\n",
    "# output_string = io.StringIO()\n",
    "\n",
    "# # Extract named entities and write them to the StringIO object\n",
    "# for ent in doc.ents:\n",
    "#     output_string.write(f\"Entity: {ent.text}, Type: {ent.label_}\\n\")\n",
    "\n",
    "# # Get the NER results as a string\n",
    "# ner_results = output_string.getvalue()\n",
    "\n",
    "# output_file_path = 'data/NER.txt'\n",
    "# with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "#     # Writing the extracted text to the output file\n",
    "#       out_file.write(ner_results)\n",
    "\n",
    "# # Closing the stream\n",
    "# output_string.close()\n",
    "\n",
    "# # Printing message to indicate that the text has been saved to the file\n",
    "# print(f\"Extracted NER list for 'The Certified Tester Foundation Level in Software Testing; {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point NER dict is saved into /data folder, edited manually and now let us import this file into stop_list StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check the content of stop_list_stringio\n",
    "#content = stop_list_stringio.getvalue()\n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markov Chain\n",
    "# Sample text (replace with your extracted_text)\n",
    "# Tokenize the text into words\n",
    "#tokens = nltk.word_tokenize(extracted_text)\n",
    "\n",
    "# Create a dictionary to store transition probabilities\n",
    "#transition_probabilities = {}\n",
    "\n",
    "# Build the transition probability matrix\n",
    "#for i in range(len(tokens) - 1):\n",
    "#    current_token = tokens[i]\n",
    "#    next_token = tokens[i + 1]\n",
    "    \n",
    "#    if current_token in transition_probabilities:\n",
    "#        transition_probabilities[current_token].append(next_token)\n",
    "#    else:\n",
    "#        transition_probabilities[current_token] = [next_token]\n",
    "\n",
    "# Start with an initial word\n",
    "#current_word = random.choice(tokens)\n",
    "\n",
    "# Generate a sentence of a certain length\n",
    "#generated_text = [current_word]\n",
    "#sentence_length = 10\n",
    "\n",
    "#for _ in range(sentence_length - 1):\n",
    "#    if current_word in transition_probabilities:\n",
    "#        next_word = random.choice(transition_probabilities[current_word])\n",
    "#        generated_text.append(next_word)\n",
    "#        current_word = next_word\n",
    "#    else:\n",
    "#        break\n",
    "\n",
    "# Join the generated words into a sentence\n",
    "#generated_sentence = \" \".join(generated_text)\n",
    "#print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.7 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v07.txt'\n"
     ]
    }
   ],
   "source": [
    "# remove chapter 4 beginning\n",
    "\n",
    "# Define the regular expression pattern for the text to remove\n",
    "pattern = r'4\\. Test Analysis and Design – 390 minutes.*?(K3) Use acceptance test-driven development (ATDD) to derive test cases'\n",
    "\n",
    "# Use re.sub to replace the matched text with a marker (e.g., 'REMOVED')\n",
    "extracted_text = re.sub(pattern, \"\", extracted_text, flags=re.DOTALL)\n",
    "\n",
    "# Define the phrase you want to remove\n",
    "phrase_to_remove = \"Learning Objectives for Chapter 4:\"\n",
    "\n",
    "# Replace the phrase with an empty string\n",
    "extracted_text = extracted_text.replace(phrase_to_remove, \"\")\n",
    "# \n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v07.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.7 saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.8 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v08.txt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remove chapter 4 beginning\n",
    "# Define the regular expression pattern to remove the desired text\n",
    "pattern = r'4\\.1 Test Techniques Overview.*?4\\.5\\.3 \\(K3\\) Use acceptance test-driven development \\(ATDD\\) to derive test cases'\n",
    "\n",
    "# Use re.sub to replace the matched text with an empty string\n",
    "extracted_text = re.sub(pattern, '', extracted_text, flags=re.DOTALL)\n",
    "\n",
    "\n",
    "\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v08.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.8 saved to '{output_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.9 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v09.txt'\n"
     ]
    }
   ],
   "source": [
    "# remove chapter 3 beginning\n",
    "# Define the regular expression pattern for the text to remove\n",
    "pattern = r'3\\. Static Testing – 80 minutes.*?FL-3\\.2\\.5 \\(K1\\) Recall the factors that contribute to a successful review'\n",
    "\n",
    "# Use re.sub to replace the matched text with a marker (e.g., 'REMOVED')\n",
    "extracted_text = re.sub(pattern, \"\", extracted_text, flags=re.DOTALL)\n",
    "\n",
    "# Define the phrase you want to remove\n",
    "phrase_to_remove = \"Learning Objectives for Chapter 4:\"\n",
    "\n",
    "# Replace the phrase with an empty string\n",
    "extracted_text = extracted_text.replace(phrase_to_remove, \"\")\n",
    "# \n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v09.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.9 saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.10 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v10.txt'\n"
     ]
    }
   ],
   "source": [
    "# remove chapter 2 beginning\n",
    "\n",
    "# Define the regular expression pattern for the text to remove\n",
    "pattern = r'2\\. Testing Throughout the Software Development Lifecycle.*?FL-2\\.3\\.1 \\(K2\\) Summarize maintenance testing and its triggers'\n",
    "# Use re.sub to replace the matched text with a marker (e.g., 'REMOVED')\n",
    "extracted_text = re.sub(pattern, \"\", extracted_text, flags=re.DOTALL)\n",
    "\n",
    "# Define the phrase you want to remove\n",
    "phrase_to_remove = \"Learning Objectives for Chapter 4:\"\n",
    "\n",
    "# Replace the phrase with an empty string\n",
    "extracted_text = extracted_text.replace(phrase_to_remove, \"\")\n",
    "# \n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v10.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.10 saved to '{output_file_path}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.11 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v11.txt'\n"
     ]
    }
   ],
   "source": [
    "# remove chapter 2 beginning\n",
    "\n",
    "# Define the regular expression pattern for the text to remove\n",
    "\n",
    "pattern = r'5\\. Managing the Test Activities – 335 minutes.*?FL-5\\.5\\.1 \\(K3\\) Prepare a defect report'\n",
    "# Use re.sub to replace the matched text with a marker (e.g., 'REMOVED')\n",
    "extracted_text = re.sub(pattern, \"\", extracted_text, flags=re.DOTALL)\n",
    "\n",
    "# Define the phrase you want to remove\n",
    "phrase_to_remove = \"Learning Objectives for Chapter 4:\"\n",
    "\n",
    "# Replace the phrase with an empty string\n",
    "extracted_text = extracted_text.replace(phrase_to_remove, \"\")\n",
    "# \n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v11.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.11 saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#pattern = r'\\d+\\.\\d+\\.\\d+\\.'\n",
    "#matches = re.findall(pattern, extracted_text)\n",
    "\n",
    "#for match in matches:\n",
    "#    match_without_dot = match[:-1]  # Remove the last dot\n",
    "#    print(match_without_dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.12 saved to 'data/ISTQB_CTFL_Syllabus-v4.0_v12.txt'\n"
     ]
    }
   ],
   "source": [
    "# Remove bullet points using regular expressions\n",
    "extracted_text = re.sub(r'•', '', extracted_text)\n",
    "\n",
    "output_file_path = 'data/ISTQB_CTFL_Syllabus-v4.0_v12.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as out_file:\n",
    "    # Writing the extracted text to the output file\n",
    "    out_file.write(extracted_text)\n",
    "# \n",
    "# Closing the stream\n",
    "output_string.close()\n",
    "# \n",
    "# Printing message to indicate that the text has been saved to the file\n",
    "print(f\"Extracted text for 'The Certified Tester Foundation Level in Software Testing' pre processed version 0.12 saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section Title: 1.1\n",
      "Section Content: What is Testing? Software systems are an integral part of our daily life. Most people have had experience with software that did not work as expected. Software that does not work correctly can lead to many problems, including loss of money, time business reputation, and, extreme cases, even injury death. Software testing assesses software quality and helps reducing risk of software failure operation. Software testing is a set of activities to discover defects and evaluate quality of software artifacts. These artifacts, when being tested, are known as test objects. A common misconception about testing is that it only consists of executing tests . However, software testing also includes other activities and must be aligned with software development lifecycle . Another common misconception about testing is that testing focuses entirely on verifying test object. Whilst testing involves verification, i.e., checking whether system meets specified requirements, it also involves validation, which means checking whether system meets users’ and other stakeholders’ needs its operational environment. Testing may be dynamic static. Dynamic testing involves execution of software, while static testing does not. Static testing includes reviews  and static analysis. Dynamic testing uses different types of test techniques and test approaches to derive test cases . Testing is not only a technical activity. It also needs to be properly planned, managed, estimated, monitored and controlled . Testers use tools , but it is important to remember that testing is largely an intellectual activity, requiring testers to have specialized knowledge, use analytical skills and apply critical thinking and systems thinking . ISO/IEC/IEEE 29119-1 standard provides further information about software testing concepts.\n",
      "----------------------------------------\n",
      "Section Title: 1.1.2\n",
      "Section Content: Testing and Debugging Testing and debugging are separate activities. Testing can trigger failures that are caused by defects software  can directly find defects test object . When dynamic testing  triggers a failure, debugging is concerned with finding causes of this failure , analyzing these causes, and eliminating them. typical debugging process this case involves:  Reproduction of a failure  Diagnosis   Fixing cause Subsequent confirmation testing checks whether fixes resolved problem. Preferably, confirmation testing is done by same person who performed initial test. Subsequent regression testing can also be performed, to check whether fixes are causing failures other parts of test object . When static testing identifies a defect, debugging is concerned with removing it. There is no need for reproduction diagnosis, since static testing directly finds defects, and cannot cause failures .\n",
      "----------------------------------------\n",
      "Section Title: 1.2.1\n",
      "Section Content: Testing’s Contributions to Success Testing provides a cost-effective means of detecting defects. These defects can then be removed , so testing indirectly contributes to higher quality test objects. Testing provides a means of directly evaluating quality of a test object at various stages SDLC. These measures are used as part of a larger project management activity, contributing to decisions to move to next stage of SDLC, such as release decision. Testing provides users with indirect representation on development project. Testers ensure that their understanding of users’ needs are considered throughout development lifecycle. alternative is to involve a representative set of users as part of development project, which is not usually possible due to high costs and lack of availability of suitable users. Testing may also be required to meet contractual legal requirements, to comply with regulatory standards.\n",
      "----------------------------------------\n",
      "Section Title: 1.2.3\n",
      "Section Content: Errors, Defects, Failures, and Root Causes Human beings make errors , which produce defects , which turn may result failures. Humans make errors for various reasons, such as time pressure, complexity of work products, processes, infrastructure interactions, simply because they are tired lack adequate training. Defects can be found documentation, such as a requirements specification a test script, source code, a supporting artifact such as a build file. Defects artifacts produced earlier SDLC, if undetected, often lead to defective artifacts later lifecycle. If a defect code is executed, system may fail to do what it should do, do something it shouldn’t, causing a failure. Some defects will always result a failure if executed, while others will only result a failure specific circumstances, and some may never result a failure. Errors and defects are not only cause of failures. Failures can also be caused by environmental conditions, such as when radiation electromagnetic field cause defects firmware. A root cause is a fundamental reason for occurrence of a problem . Root causes are identified through root cause analysis, which is typically performed when a failure occurs a defect is identified. It is believed that further similar failures defects can be prevented their frequency reduced by addressing root cause, such as by removing it.\n",
      "----------------------------------------\n",
      "Section Title: 1.4\n",
      "Section Content: Test Activities, Testware and Test Roles Testing is context dependent, but, at a high level, there are common sets of test activities without which testing is less likely to achieve test objectives. These sets of test activities form a test process. test process can be tailored to a given situation based on various factors. Which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation . following sections describe general aspects of this test process terms of test activities and tasks, impact of context, testware, traceability between test basis and testware, and testing roles. ISO/IEC/IEEE 29119-2 standard provides further information about test processes.\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: Test monitoring and control. Test monitoring involves ongoing checking of all test activities and comparison of actual progress against plan. Test control involves taking actions necessary to meet objectives of testing. Test monitoring and control are further explained section\n",
      "----------------------------------------\n",
      "Section Title: 1.4.2\n",
      "Section Content: Test Process Context Testing is not performed isolation. Test activities are an integral part of development processes carried out within an organization. Testing is also funded by stakeholders and its final goal is to help fulfill stakeholders’ business needs. Therefore, way testing is carried out will depend on a number of contextual factors including:  Stakeholders   Team members   Business domain   Technical factors   Project constraints   Organizational factors   Software development lifecycle   Tools  These factors will have an impact on many test-related issues, including: test strategy, test techniques used, degree of test automation, required level of coverage, level of detail of test documentation, reporting, etc.\n",
      "----------------------------------------\n",
      "Section Title: 1.4.1\n",
      "Section Content: There is a significant variation how different organizations produce, shape, name, organize and manage their   work products. Proper configuration management  ensures consistency and integrity of work products. following list of work products is not exhaustive:  Test planning work products include: test plan, test schedule, risk register, and entry and exit criteria . Risk register is a list of risks together with risk likelihood, risk impact and information about risk mitigation . Test schedule, risk register and entry and exit criteria are often a part of test plan.  Test monitoring and control work products include: test progress reports , documentation of control directives  and risk information .  Test analysis work products include:  test conditions , and defect reports regarding defects test basis .  Test design work products include:  test cases, test charters, coverage items, test data requirements and test environment requirements.  Test implementation work products include: test procedures, automated test scripts, test suites, test data, test execution schedule, and test environment elements. Examples of test environment elements include: stubs, drivers, simulators, and service virtualizations.  Test execution work products include: test logs, and defect reports .  Test completion work products include: test completion report , action items for improvement of subsequent projects iterations, documented lessons learned, and change requests .\n",
      "----------------------------------------\n",
      "Section Title: 1.4.5\n",
      "Section Content: Roles Testing this syllabus, two principal roles testing are covered: a test management role and a testing role. activities and tasks assigned to these two roles depend on factors such as project and product context, skills of people roles, and organization. test management role takes overall responsibility for test process, test team and leadership of test activities. test management role is mainly focused on activities of test planning, test monitoring and control and test completion. way which test management role is carried out varies depending on context. For example, Agile software development, some of test management tasks may be handled by Agile team. Tasks that span multiple teams entire organization may be performed by test managers outside of development team. testing role takes overall responsibility for engineering  aspect of testing. testing role is mainly focused on activities of test analysis, test design, test implementation and test execution. Different people may take on these roles at different times. For example, test management role can be performed by a team leader, by a test manager, by a development manager, etc. It is also possible for one person to take on roles of testing and test management at same time.\n",
      "----------------------------------------\n",
      "Section Title: 1.5.1\n",
      "Section Content: Generic Skills Required for Testing While being generic, following skills are particularly relevant for testers:  Testing knowledge   Thoroughness, carefulness, curiosity, attention to details, being methodical   Good communication skills, active listening, being a team player   Analytical thinking, critical thinking, creativity   Technical knowledge   Domain knowledge  Testers are often bearers of bad news. It is a common human trait to blame bearer of bad news. This makes communication skills crucial for testers. Communicating test results may be perceived as criticism of product and of its author. Confirmation bias can make it difficult to accept information that disagrees with currently held beliefs. Some people may perceive testing as a destructive activity, even though it contributes greatly to project success and product quality. To try to improve this view, information about defects and failures should be communicated a constructive way.\n",
      "----------------------------------------\n",
      "Section Title: 1.5.3\n",
      "Section Content: Independence of Testing A certain degree of independence makes tester more effective at finding defects due to differences between author’s and tester’s cognitive biases . Independence is not, however, a replacement for familiarity, e.g., developers can efficiently find many defects their own code. Work products can be tested by their author , by author's peers from same team , by testers from outside author's team but within organization , by testers from outside organization . For most projects, it is usually best to carry out testing with multiple levels of independence . main benefit of independence of testing is that independent testers are likely to recognize different kinds of failures and defects compared to developers because of their different backgrounds, technical perspectives, and biases. Moreover, an independent tester can verify, challenge, disprove assumptions made by stakeholders during specification and implementation of system. However, there are also some drawbacks. Independent testers may be isolated from development team, which may lead to a lack of collaboration, communication problems, an adversarial relationship with development team. Developers may lose a sense of responsibility for quality. Independent testers may be seen as a bottleneck be blamed for delays release.   2. Testing Throughout Software Development Lifecycle – 130 minutes Keywords acceptance testing, black-box testing, component integration testing, component testing, confirmation testing, functional testing, integration testing, maintenance testing, non-functional testing, regression testing, shift-left, system integration testing, system testing, test level, test object, test type, white-box testing Learning Objectives for Chapter 2: 2.1 Testing Context of a Software Development Lifecycle FL-\n",
      "----------------------------------------\n",
      "Section Title: 2.1\n",
      "Section Content: 2  Recall good testing practices that apply to all software development lifecycles FL-\n",
      "----------------------------------------\n",
      "Section Title: 2.1\n",
      "Section Content: 4  Summarize how DevOps might have an impact on testing FL-\n",
      "----------------------------------------\n",
      "Section Title: 2.1\n",
      "Section Content: 6  Explain how retrospectives can be used as a mechanism for process improvement 2.2 Test Levels and Test Types FL-\n",
      "----------------------------------------\n",
      "Section Title: 2.2\n",
      "Section Content: 2  Distinguish different test types FL-\n",
      "----------------------------------------\n",
      "Section Title: 2.3\n",
      "Section Content: 1  Summarize maintenance testing and its triggers\n",
      "----------------------------------------\n",
      "Section Title: 2.1.1\n",
      "Section Content: Impact of Software Development Lifecycle on Testing Testing must be adapted to SDLC to succeed. choice of SDLC impacts on the:  Scope and timing of test activities   Level of detail of test documentation  Choice of test techniques and test approach  Extent of test automation  Role and responsibilities of a tester sequential development models, initial phases testers typically participate requirement reviews, test analysis, and test design. executable code is usually created later phases, so typically dynamic testing cannot be performed early SDLC. some iterative and incremental development models, it is assumed that each iteration delivers a working prototype product increment. This implies that each iteration both static and dynamic testing may be performed at all test levels. Frequent delivery of increments requires fast feedback and extensive regression testing. Agile software development assumes that change may occur throughout project. Therefore, lightweight work product documentation and extensive test automation to make regression testing easier are favored agile projects. Also, most of manual testing tends to be done using experience-based test techniques  that do not require extensive prior test analysis and design.\n",
      "----------------------------------------\n",
      "Section Title: 2.1.3\n",
      "Section Content: Testing as a Driver for Software Development TDD, ATDD and BDD are similar development approaches, where tests are defined as a means of directing development. Each of these approaches implements principle of early testing  and follows a shift-left approach , since tests are defined before code is written. They support an iterative development model. These approaches are characterized as follows: Test-Driven Development :  Directs coding through test cases    Tests are written first, then code is written to satisfy tests, and then tests and code are refactored Acceptance Test-Driven Development  :  Derives tests from acceptance criteria as part of system design process   Tests are written before part of application is developed to satisfy tests Behavior-Driven Development :  Expresses desired behavior of an application with test cases written a simple form of natural language, which is easy to understand by stakeholders – usually using Given/When/Then format.   Test cases are then automatically translated into executable tests For all above approaches, tests may persist as automated tests to ensure code quality future adaptions / refactoring.\n",
      "----------------------------------------\n",
      "Section Title: 2.1.5\n",
      "Section Content: Shift-Left Approach principle of early testing  is sometimes referred to as shift-left because it is an approach where testing is performed earlier SDLC. Shift-left normally suggests that testing should be done earlier , but it does not mean that testing later SDLC should be neglected. There are some good practices that illustrate how to achieve a “shift-left” testing, which include:  Reviewing specification from perspective of testing. These review activities on specifications often find potential defects, such as ambiguities, incompleteness, and inconsistencies  Writing test cases before code is written and have code run a test harness during code implementation  Using CI and even better CD as it comes with fast feedback and automated component tests to accompany source code when it is submitted to code repository  Completing static analysis of source code prior to dynamic testing, as part of an automated process  Performing non-functional testing starting at component test level, where possible. This is a form of shift-left as these non-functional test types tend to be performed later SDLC when a complete system and a representative test environment are available A shift-left approach might result extra training, effort and/or costs earlier process but is expected to save efforts and/or costs later process. For shift-left approach it is important that stakeholders are convinced and bought into this concept.\n",
      "----------------------------------------\n",
      "Section Title: 2.2\n",
      "Section Content: Test Levels and Test Types Test levels are groups of test activities that are organized and managed together. Each test level is an instance of test process, performed relation to software at a given stage of development, from individual components to complete systems or, where applicable, systems of systems. Test levels are related to other activities within SDLC. sequential SDLC models, test levels are often defined such that exit criteria of one level are part of entry criteria for next level. some iterative models, this may not apply. Development activities may span through multiple test levels. Test levels may overlap time. Test types are groups of test activities related to specific quality characteristics and most of those test activities can be performed at every test level.\n",
      "----------------------------------------\n",
      "Section Title: 2.2.2\n",
      "Section Content: Test Types A lot of test types exist and can be applied projects. this syllabus, following four test types are addressed: Functional testing evaluates functions that a component system should perform. functions are “what” test object should do. main objective of functional testing is checking functional completeness, functional correctness and functional appropriateness. Non-functional testing evaluates attributes other than functional characteristics of a component system. Non-functional testing is testing of “how well system behaves”. main objective of non- functional testing is checking non-functional software quality characteristics. ISO/IEC 25010 standard provides following classification of non-functional software quality characteristics:  Performance efficiency  Compatibility  Usability  Reliability  Security  Maintainability  Portability It is sometimes appropriate for non-functional testing to start early life cycle . Many non-functional tests are derived from functional tests as   they use same functional tests, but check that while performing function, a non-functional constraint is satisfied . late discovery of non-functional defects can pose a serious threat to success of a project. Non-functional testing sometimes needs a very specific test environment, such as a usability lab for usability testing. Black-box testing  is specification-based and derives tests from documentation external to test object. main objective of black-box testing is checking system's behavior against its specifications. White-box testing  is structure-based and derives tests from system's implementation internal structure . main objective of white-box testing is to cover underlying structure by tests to acceptable level. All four above mentioned test types can be applied to all test levels, although focus will be different at each level. Different test techniques can be used to derive test conditions and test cases for all mentioned test types.\n",
      "----------------------------------------\n",
      "Section Title: 2.3\n",
      "Section Content: Maintenance Testing There are different categories of maintenance, it can be corrective, adaptive to changes environment improve performance maintainability , so maintenance can involve planned releases/deployments and unplanned releases/deployments . Impact analysis may be done before a change is made, to help decide if change should be made, based on potential consequences other areas of system. Testing changes to a system production includes both evaluating success of implementation of change and checking for possible regressions parts of system that remain unchanged . scope of maintenance testing typically depends on:  degree of risk of change  size of existing system  size of change triggers for maintenance and maintenance testing can be classified as follows:  Modifications, such as planned enhancements , corrective changes hot fixes.  Upgrades migrations of operational environment, such as from one platform to another, which can require tests associated with new environment as well as of changed software, tests of data conversion when data from another application is migrated into system being maintained.  Retirement, such as when an application reaches end of its life. When a system is retired, this can require testing of data archiving if long data-retention periods are required. Testing of restore and retrieval procedures after archiving may also be needed event that certain data is required during archiving period.   3. Static Testing – 80 minutes Keywords anomaly, dynamic testing, formal review, informal review, inspection, review, static analysis, static testing, technical review, walkthrough Learning Objectives for Chapter 3: 3.1 Static Testing Basics FL-\n",
      "----------------------------------------\n",
      "Section Title: 3.1\n",
      "Section Content: 2  Explain value of static testing FL-\n",
      "----------------------------------------\n",
      "Section Title: 3.2\n",
      "Section Content: 1  Identify benefits of early and frequent stakeholder feedback FL-\n",
      "----------------------------------------\n",
      "Section Title: 3.2\n",
      "Section Content: 3  Recall which responsibilities are assigned to principal roles when performing reviews FL-\n",
      "----------------------------------------\n",
      "Section Title: 3.2\n",
      "Section Content: 5  Recall factors that contribute to a successful review\n",
      "----------------------------------------\n",
      "Section Title: 3.1.1\n",
      "Section Content: Work Products Examinable by Static Testing Almost any work product can be examined using static testing. Examples include requirement specification documents, source code, test plans, test cases, product backlog items, test charters, project documentation, contracts and models. Any work product that can be read and understood can be subject of a review. However, for static analysis, work products need a structure against which they can be checked . Work products that are not appropriate for static testing include those that are difficult to interpret by human beings and that should not be analyzed by tools .\n",
      "----------------------------------------\n",
      "Section Title: 3.1.3\n",
      "Section Content: Differences between Static Testing and Dynamic Testing Static testing and dynamic testing practices complement each other. They have similar objectives, such as supporting detection of defects work products , but there are also some differences, such as:  Static and dynamic testing  can both lead to detection of defects, however there are some defect types that can only be found by either static dynamic testing.  Static testing finds defects directly, while dynamic testing causes failures from which associated defects are determined through subsequent analysis  Static testing may more easily detect defects that lay on paths through code that are rarely executed hard to reach using dynamic testing  Static testing can be applied to non-executable work products, while dynamic testing can only be applied to executable work products  Static testing can be used to measure quality characteristics that are not dependent on executing code , while dynamic testing can be used to measure quality characteristics that are dependent on executing code  Typical defects that are easier and/or cheaper to find through static testing include:  Defects requirements   Design defects   Certain types of coding defects   Deviations from standards   Incorrect interface specifications   Specific types of security vulnerabilities   Gaps inaccuracies test basis coverage\n",
      "----------------------------------------\n",
      "Section Title: 3.2.1\n",
      "Section Content: Benefits of Early and Frequent Stakeholder Feedback Early and frequent feedback allows for early communication of potential quality problems. If there is little stakeholder involvement during SDLC, product being developed might not meet stakeholder’s original current vision. A failure to deliver what stakeholder wants can result costly rework, missed deadlines, blame games, and might even lead to complete project failure.   Frequent stakeholder feedback throughout SDLC can prevent misunderstandings about requirements and ensure that changes to requirements are understood and implemented earlier. This helps development team to improve their understanding of what they are building. It allows them to focus on those features that deliver most value to stakeholders and that have most positive impact on identified risks.\n",
      "----------------------------------------\n",
      "Section Title: 3.2.3\n",
      "Section Content: Roles and Responsibilities Reviews Reviews involve various stakeholders, who may take on several roles. principal roles and their responsibilities are:  Manager – decides what is to be reviewed and provides resources, such as staff and time for review  Author – creates and fixes work product under review    Moderator  – ensures effective running of review meetings, including mediation, time management, and a safe review environment which everyone can speak freely  Scribe  – collates anomalies from reviewers and records review information, such as decisions and new anomalies found during review meeting  Reviewer – performs reviews. A reviewer may be someone working on project, a subject matter expert, any other stakeholder  Review leader – takes overall responsibility for review such as deciding who will be involved, and organizing when and where review will take place Other, more detailed roles are possible, as described ISO/IEC 20246 standard.\n",
      "----------------------------------------\n",
      "Section Title: 3.2.5\n",
      "Section Content: Success Factors for Reviews There are several factors that determine success of reviews, which include:    Defining clear objectives and measurable exit criteria. Evaluation of participants should never be an objective  Choosing appropriate review type to achieve given objectives, and to suit type of work product, review participants, project needs and context  Conducting reviews on small chunks, so that reviewers do not lose concentration during an individual review and/or review meeting   Providing feedback from reviews to stakeholders and authors so they can improve product and their activities   Providing adequate time to participants to prepare for review  Support from management for review process  Making reviews part of organization’s culture, to promote learning and process improvement  Providing adequate training for all participants so they know how to fulfil their role  Facilitating meetings   4. Test Analysis and Design – 390 minutes Keywords acceptance criteria, acceptance test-driven development, black-box test technique, boundary value analysis, branch coverage, checklist-based testing, collaboration-based test approach, coverage, coverage item, decision table testing, equivalence partitioning, error guessing, experience-based test technique, exploratory testing, state transition testing, statement coverage, test technique, white-box test technique  4.1 Test Techniques Overview FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.2\n",
      "Section Content: 1  Use equivalence partitioning to derive test cases FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.2\n",
      "Section Content: 3  Use decision table testing to derive test cases FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.3\n",
      "Section Content: 1  Explain statement testing FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.3\n",
      "Section Content: 3  Explain value of white-box testing 4.4 Experience-based Test Techniques FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.4\n",
      "Section Content: 2  Explain exploratory testing FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.5\n",
      "Section Content: Collaboration-based Test Approaches FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.5\n",
      "Section Content: 2  Classify different options for writing acceptance criteria FL-\n",
      "----------------------------------------\n",
      "Section Title: 4.1\n",
      "Section Content: Test Techniques Overview Test techniques support tester test analysis  and test design . Test techniques help to develop a relatively small, but sufficient, set of test cases a systematic way. Test techniques also help tester to define test conditions, identify coverage items, and identify test data during test analysis and design. Further information on test techniques and their corresponding measures can be found ISO/IEC/IEEE 29119-4 standard, and . this syllabus, test techniques are classified as black-box, white-box, and experience-based. Black-box test techniques  are based on an analysis of specified behavior of test object without reference to its internal structure. Therefore, test cases are independent of how software is implemented. Consequently, if implementation changes, but required behavior stays same, then test cases are still useful. White-box test techniques  are based on an analysis of test object’s internal structure and processing. As test cases are dependent on how software is designed, they can only be created after design implementation of test object. Experience-based test techniques effectively use knowledge and experience of testers for design and implementation of test cases. effectiveness of these techniques depends heavily on tester’s skills. Experience-based test techniques can detect defects that may be missed using black- box and white-box test techniques. Hence, experience-based test techniques are complementary to black-box and white-box test techniques.\n",
      "----------------------------------------\n",
      "Section Title: 4.2.1\n",
      "Section Content: Equivalence Partitioning Equivalence Partitioning  divides data into partitions  based on expectation that all elements of a given partition are to be processed same way by test object. theory behind this technique is that if a test case, that tests one value from an equivalence partition, detects a defect, this defect should also be detected by test cases that test any other value from same partition. Therefore, one test for each partition is sufficient. Equivalence partitions can be identified for any data element related to test object, including inputs, outputs, configuration items, internal values, time-related values, and interface parameters. partitions may be continuous discrete, ordered unordered, finite infinite. partitions must not overlap and must be non-empty sets. For simple test objects EP can be easy, but practice, understanding how test object will treat different values is often complicated. Therefore, partitioning should be done with care.   A partition containing valid values is called a valid partition. A partition containing invalid values is called an invalid partition. definitions of valid and invalid values may vary among teams and organizations. For example, valid values may be interpreted as those that should be processed by test object as those for which specification defines their processing. Invalid values may be interpreted as those that should be ignored rejected by test object as those for which no processing is defined test object specification. EP, coverage items are equivalence partitions. To achieve 100% coverage with this technique, test cases must exercise all identified partitions  by covering each partition at least once. Coverage is measured as number of partitions exercised by at least one test case, divided by total number of identified partitions, and is expressed as a percentage. Many test objects include multiple sets of partitions , which means that a test case will cover partitions from different sets of partitions. simplest coverage criterion case of multiple sets of partitions is called Each Choice coverage . Each Choice coverage requires test cases to exercise each partition from each set of partitions at least once. Each Choice coverage does not take into account combinations of partitions.\n",
      "----------------------------------------\n",
      "Section Title: 4.2.3\n",
      "Section Content: Decision Table Testing Decision tables are used for testing implementation of system requirements that specify how different combinations of conditions result different outcomes. Decision tables are an effective way of recording complex logic, such as business rules. When creating decision tables, conditions and resulting actions of system are defined. These form rows of table. Each column corresponds to a decision rule that defines a unique combination of conditions, along with associated actions. limited-entry decision tables all values of conditions and actions  are shown as Boolean values . Alternatively, extended-entry decision tables some all conditions and actions may also take on multiple values . notation for conditions is as follows: “T”  means that condition is satisfied. “F”  means that condition is not satisfied. “–” means that value of condition is irrelevant for action outcome. “N/A” means that condition is infeasible for a given rule. For actions: “X” means that action should occur. Blank means that action should not occur. Other notations may also be used. A full decision table has enough columns to cover every combination of conditions. table can be simplified by deleting columns containing infeasible combinations of conditions. table can also be minimized by merging columns, which some conditions do not affect outcome, into a single column. Decision table minimization algorithms are out of scope of this syllabus. decision table testing, coverage items are columns containing feasible combinations of conditions. To achieve 100% coverage with this technique, test cases must exercise all these columns. Coverage is measured as number of exercised columns, divided by total number of feasible columns, and is expressed as a percentage. strength of decision table testing is that it provides a systematic approach to identify all combinations of conditions, some of which might otherwise be overlooked. It also helps to find any gaps contradictions requirements. If there are many conditions, exercising all decision rules may be time consuming, since number of rules grows exponentially with number of conditions. such a case, to reduce number of rules that need to be exercised, a minimized decision table a risk- based approach may be used.\n",
      "----------------------------------------\n",
      "Section Title: 4.3\n",
      "Section Content: White-Box Test Techniques Because of their popularity and simplicity, this section focuses on two code-related white-box test techniques:  Statement testing  Branch testing There are more rigorous techniques that are used some safety-critical, mission-critical, high-integrity environments to achieve more thorough code coverage. There are also white-box test techniques used higher test levels , using coverage not related to code . These techniques are not discussed this syllabus.\n",
      "----------------------------------------\n",
      "Section Title: 4.3.2\n",
      "Section Content: Branch Testing and Branch Coverage A branch is a transfer of control between two nodes control flow graph, which shows possible sequences which source code statements are executed test object. Each transfer of control can be either unconditional  conditional . branch testing coverage items are branches and aim is to design test cases to exercise branches code until an acceptable level of coverage is achieved. Coverage is measured as number of branches exercised by test cases divided by total number of branches, and is expressed as a percentage. When 100% branch coverage is achieved, all branches code, unconditional and conditional, are exercised by test cases. Conditional branches typically correspond to a true false outcome from an “if...then” decision, an outcome from a switch/case statement, a decision to exit continue a loop. However, exercising a branch with a test case will not detect defects all cases. For example, it may not detect defects requiring execution of a specific path a code. Branch coverage subsumes statement coverage. This means that any set of test cases achieving 100% branch coverage also achieves 100% statement coverage .\n",
      "----------------------------------------\n",
      "Section Title: 4.4\n",
      "Section Content: Experience-based Test Techniques Commonly used experience-based test techniques discussed following sections are:  Error guessing  Exploratory testing  Checklist-based testing\n",
      "----------------------------------------\n",
      "Section Title: 4.4.2\n",
      "Section Content: Exploratory Testing exploratory testing, tests are simultaneously designed, executed, and evaluated while tester learns about test object. testing is used to learn more about test object, to explore it more deeply with focused tests, and to create tests for untested areas. Exploratory testing is sometimes conducted using session-based testing to structure testing. a session-based approach, exploratory testing is conducted within a defined time-box. tester uses a test charter containing test objectives to guide testing. test session is usually followed by a debriefing that involves a discussion between tester and stakeholders interested test results of test session. this approach test objectives may be treated as high-level test conditions. Coverage items are identified and exercised during test session. tester may use test session sheets to document steps followed and discoveries made. Exploratory testing is useful when there are few inadequate specifications there is significant time pressure on testing. Exploratory testing is also useful to complement other more formal test techniques. Exploratory testing will be more effective if tester is experienced, has domain knowledge and has a high degree of essential skills, like analytical skills, curiosity and creativeness . Exploratory testing can incorporate use of other test techniques . More information about exploratory testing can be found .\n",
      "----------------------------------------\n",
      "Section Title: 4.5\n",
      "Section Content: Collaboration-based Test Approaches Each of above-mentioned techniques  has a particular objective with respect to defect detection. Collaboration-based approaches, on other hand, focus also on defect avoidance by collaboration and communication.\n",
      "----------------------------------------\n",
      "Section Title: 4.5.2\n",
      "Section Content: Acceptance Criteria Acceptance criteria for a user story are conditions that an implementation of user story must meet to be accepted by stakeholders. From this perspective, acceptance criteria may be viewed as test conditions that should be exercised by tests. Acceptance criteria are usually a result of Conversation . Acceptance criteria are used to:  Define scope of user story  Reach consensus among stakeholders  Describe both positive and negative scenarios  Serve as a basis for user story acceptance testing     Allow accurate planning and estimation There are several ways to write acceptance criteria for a user story. two most common formats are:  Scenario-oriented   Rule-oriented  Most acceptance criteria can be documented one of these two formats. However, team may use another, custom format, as long as acceptance criteria are well-defined and unambiguous.\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: 1  Exemplify purpose and content of a test plan FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: 3  Compare and contrast entry criteria and exit criteria FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: 5  Apply test case prioritization FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: 7  Summarize testing quadrants and their relationships with test levels and test types 5.2 Risk Management FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.2\n",
      "Section Content: 2  Distinguish between project risks and product risks FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.2\n",
      "Section Content: 4  Explain what measures can be taken response to analyzed product risks 5.3 Test Monitoring, Test Control and Test Completion FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.3\n",
      "Section Content: 2  Summarize purposes, content, and audiences for test reports FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.4\n",
      "Section Content: 1  Summarize how configuration management supports testing 5.5 Defect Management FL-\n",
      "----------------------------------------\n",
      "Section Title: 5.1\n",
      "Section Content: Test Planning\n",
      "----------------------------------------\n",
      "Section Title: 5.1.2\n",
      "Section Content: Tester's Contribution to Iteration and Release Planning iterative SDLCs, typically two kinds of planning occur: release planning and iteration planning. Release planning looks ahead to release of a product, defines and re-defines product backlog, and may involve refining larger user stories into a set of smaller user stories. It also serves as basis for test approach and test plan across all iterations. Testers involved release planning participate writing testable user stories and acceptance criteria , participate project and quality risk analyses , estimate test effort associated with user stories , determine test approach, and plan testing for release. Iteration planning looks ahead to end of a single iteration and is concerned with iteration backlog. Testers involved iteration planning participate detailed risk analysis of user stories, determine testability of user stories, break down user stories into tasks , estimate test effort for all testing tasks, and identify and refine functional and non-functional aspects of test object.\n",
      "----------------------------------------\n",
      "Section Title: 5.1.4\n",
      "Section Content: Estimation Techniques Test effort estimation involves predicting amount of test-related work needed to meet objectives of a test project. It is important to make it clear to stakeholders that estimate is based on a number of assumptions and is always subject to estimation error. Estimation for small tasks is usually more accurate than for large ones. Therefore, when estimating a large task, it can be decomposed into a set of smaller tasks which then turn can be estimated. this syllabus, following four estimation techniques are described. Estimation based on ratios. this metrics-based technique, figures are collected from previous projects within organization, which makes it possible to derive “standard” ratios for similar projects. ratios of an organization’s own projects  are generally best source to use estimation process. These standard ratios can then be used to estimate test effort for new project. For example, if previous project development-to-test effort ratio was 3:2, and current project development effort is expected to be 600 person-days, test effort can be estimated to be 400 person-days. Extrapolation. this metrics-based technique, measurements are made as early as possible current project to gather data. Having enough observations, effort required for remaining work can be approximated by extrapolating this data . This method is very suitable iterative SDLCs. For example, team may extrapolate test effort forthcoming iteration as averaged effort from last three iterations. Wideband Delphi. this iterative, expert-based technique, experts make experience-based estimations. Each expert, isolation, estimates effort. results are collected and if there are deviations that are out of range of agreed upon boundaries, experts discuss their current estimates. Each expert is then asked to make a new estimation based on that feedback, again isolation. This process is repeated until a consensus is reached. Planning Poker is a variant of Wideband Delphi, commonly used Agile   software development. Planning Poker, estimates are usually made using cards with numbers that represent effort size. Three-point estimation. this expert-based technique, three estimations are made by experts: most optimistic estimation , most likely estimation  and most pessimistic estimation . final estimate  is their weighted arithmetic mean. most popular version of this technique, estimate is calculated as E =  / 6. advantage of this technique is that it allows experts to calculate measurement error: SD =  / 6. For example, if estimates  are: a=6, m=9 and b=18, then final estimation is 10±2 person-hours , because E =  / 6 = 10 and SD =  / 6 = 2. See  for these and many other test estimation techniques.\n",
      "----------------------------------------\n",
      "Section Title: 5.1.6\n",
      "Section Content: Test Pyramid test pyramid is a model showing that different tests may have different granularity. test pyramid model supports team test automation and test effort allocation by showing that different goals are supported by different levels of test automation. pyramid layers represent groups of tests. higher layer, lower test granularity, test isolation and test execution time. Tests bottom layer are small, isolated, fast, and check a small piece of functionality, so usually a lot of them are needed to achieve a reasonable coverage. top layer represents complex, high-level, end-to-end tests. These high-level tests are generally slower than tests from lower layers, and they typically check a large piece of functionality, so usually just a few of them are needed to achieve a reasonable coverage. number and naming of layers may differ. For example, original test pyramid model  defines three layers: “unit tests”, “service tests” and “UI tests”. Another popular model defines unit    tests, integration  tests, and end-to-end tests. Other test levels  can also be used.\n",
      "----------------------------------------\n",
      "Section Title: 5.2\n",
      "Section Content: Risk Management Organizations face many internal and external factors that make it uncertain whether and when they will achieve their objectives . Risk management allows organizations to increase likelihood of achieving objectives, improve quality of their products and increase stakeholders’ confidence and trust. main risk management activities are:  Risk analysis   Risk control  test approach, which test activities are selected, prioritized, and managed based on risk analysis and risk control, is called risk-based testing.\n",
      "----------------------------------------\n",
      "Section Title: 5.2.2\n",
      "Section Content: Project Risks and Product Risks software testing one is generally concerned with two types of risks: project risks and product risks. Project risks are related to management and control of project. Project risks include:  Organizational issues   People issues   Technical issues   Supplier issues  Project risks, when they occur, may have an impact on project schedule, budget scope, which affects project's ability to achieve its objectives. Product risks are related to product quality characteristics . Examples of product risks include: missing wrong functionality, incorrect calculations, runtime errors, poor architecture, inefficient algorithms, inadequate response time, poor user experience, security vulnerabilities. Product risks, when they occur, may result various negative consequences, including:  User dissatisfaction  Loss of revenue, trust, reputation  Damage to third parties  High maintenance costs, overload of helpdesk  Criminal penalties  extreme cases, physical damage, injuries even death\n",
      "----------------------------------------\n",
      "Section Title: 5.2.4\n",
      "Section Content: Product Risk Control Product risk control comprises all measures that are taken response to identified and assessed product risks. Product risk control consists of risk mitigation and risk monitoring. Risk mitigation involves implementing actions proposed risk assessment to reduce risk level. aim of risk monitoring is to ensure that mitigation actions are effective, to obtain further information to improve risk assessment, and to identify emerging risks. With respect to product risk control, once a risk has been analyzed, several response options to risk are possible, e.g., risk mitigation by testing, risk acceptance, risk transfer, contingency plan . Actions that can be taken to mitigate product risks by testing are as follows:  Select testers with right level of experience and skills, suitable for a given risk type  Apply an appropriate level of independence of testing  Conduct reviews and perform static analysis  Apply appropriate test techniques and coverage levels  Apply appropriate test types addressing affected quality characteristics  Perform dynamic testing, including regression testing\n",
      "----------------------------------------\n",
      "Section Title: 5.3.1\n",
      "Section Content: Metrics used Testing Test metrics are gathered to show progress against planned schedule and budget, current quality of test object, and effectiveness of test activities with respect to objectives an iteration goal. Test monitoring gathers a variety of metrics to support test control and test completion. Common test metrics include:  Project progress metrics   Test progress metrics   Product quality metrics   Defect metrics   Risk metrics   Coverage metrics   Cost metrics\n",
      "----------------------------------------\n",
      "Section Title: 5.3.3\n",
      "Section Content: Communicating Status of Testing best means of communicating test status varies, depending on test management concerns, organizational test strategies, regulatory standards, or, case of self-organizing teams , on team itself. options include:  Verbal communication with team members and other stakeholders  Dashboards   Electronic communication channels   Online documentation  Formal test reports  One more of these options can be used. More formal communication may be more appropriate for distributed teams where direct face-to-face communication is not always possible due to geographical distance time differences. Typically, different stakeholders are interested different types of information, so communication should be tailored accordingly.\n",
      "----------------------------------------\n",
      "Section Title: 5.5\n",
      "Section Content: Defect Management Since one of major test objectives is to find defects, an established defect management process is essential. Although we refer to \"defects\" here, reported anomalies may turn out to be real defects something else  - this is resolved during process of dealing with defect reports. Anomalies may be reported during any phase of SDLC and form depends on SDLC. At a minimum, defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. workflow typically comprises activities to log reported anomalies, analyze and classify them, decide on a suitable response such as to fix keep it as it is and finally to close defect report. process must be followed by all involved stakeholders. It is advisable to handle defects from static testing  a similar way. Typical defect reports have following objectives:  Provide those responsible for handling and resolving reported defects with sufficient information to resolve issue  Provide a means of tracking quality of work product  Provide ideas for improvement of development and test process A defect report logged during dynamic testing typically includes:  Unique identifier  Title with a short summary of anomaly being reported  Date when anomaly was observed, issuing organization, and author, including their role  Identification of test object and test environment  Context of defect  v4.0 Page 55 of 74 2023-04-21   Description of failure to enable reproduction and resolution including steps that detected anomaly, and any relevant test logs, database dumps, screenshots, recordings  Expected results and actual results  Severity of defect  on interests of stakeholders requirements  Priority to fix  Status of defect   References  Some of this data may be automatically included when using defect management tools . Document templates for a defect report and example defect reports can be found ISO/IEC/IEEE 29119-3 standard, which refers to defect reports as incident reports. v4.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a regular expression pattern to match section titles\n",
    "#section_pattern = r'\\d+\\.\\d+\\.\\d+\\.'\n",
    "\n",
    "# using combined reg. exp to extract 1.1.1. and 1.2.\n",
    "section_pattern_3d = r'\\d+\\.\\d+\\.\\d+\\.'  # Pattern for \"1.1.1.\"\n",
    "section_pattern_2d = r'\\d+\\.\\d+\\.'    # Pattern for \"1.2.\"\n",
    "combined_pattern = f\"({section_pattern_3d}|{section_pattern_2d})\"#\n",
    "\n",
    "## Using re.finditer to find all section titles and their starting positions\n",
    "section_matches = re.finditer(combined_pattern, extracted_text)#\n",
    "\n",
    "## Create lists to store sections\n",
    "sections = []#\n",
    "\n",
    "## Iterate through section matches\n",
    "for match in section_matches:\n",
    "    start_pos = match.start()\n",
    "    end_pos = (\n",
    "        match.end()\n",
    "        if match.end() < len(extracted_text)\n",
    "        else len(extracted_text)\n",
    "    )\n",
    "    section_title = match.group().strip()\n",
    "    \n",
    "    # Remove the last dot from the section title\n",
    "    section_title = section_title[:-1]  # Remove the last dot\n",
    "    \n",
    "    try:\n",
    "        # Find the corresponding section content based on section title position\n",
    "        next_match = next(section_matches)\n",
    "        content_start = end_pos\n",
    "        content_end = (\n",
    "            next_match.start()\n",
    "            if content_start < len(extracted_text)\n",
    "            else len(extracted_text)\n",
    "        )\n",
    "        section_content = extracted_text[content_start:content_end].strip()\n",
    "    except StopIteration:\n",
    "        # Handle the case when there are no more matches\n",
    "        section_content = extracted_text[end_pos:].strip()\n",
    "    \n",
    "    sections.append((section_title, section_content))#\n",
    "\n",
    "## Print the extracted sections\n",
    "if sections:\n",
    "    for section in sections:\n",
    "        print(\"Section Title:\", section[0])\n",
    "        print(\"Section Content:\", section[1])\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No sections found in the text, you did something wrong check once more\")#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Base Modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.1. What is Testing?', '1.1.1. Test Objectives', '1.1.2. Testing and Debugging', '1.2. Why is Testing Necessary?', '1.2.1. Testing’s Contributions to Success', '1.2.2. Testing and Quality Assurance (QA)', '1.2.3. Errors, Defects, Failures, and Root Causes', '1.3. Testing Principles', '1.4. Test Activities, Testware and Test Roles', '1.4.1. Test Activities and Tasks', '1.4.2. Test Process in Context', '1.4.3. Testware', '1.4.4. Traceability between the Test Basis and Testware', '1.4.5. Roles in Testing', '1.5. Essential Skills and Good Practices in Testing', '1.5.1. Generic Skills Required for Testing', '1.5.2. Whole Team Approach', '1.5.3. Independence of Testing', '2.1. Testing in the Context of a Software Development Lifecycle', '2.1.1. Impact of the Software Development Lifecycle on Testing', '2.1.2. Software Development Lifecycle and Good Testing Practices', '2.1.3. Testing as a Driver for Software Development', '2.1.4. DevOps and Testing', '2.1.5. Shift-Left Approach', '2.1.6. Retrospectives and Process Improvement', '2.2. Test Levels and Test Types', '2.2.1. Test Levels', '2.2.2. Test Types', '2.2.3. Confirmation Testing and Regression Testing', '2.3. Maintenance Testing', '3.1. Static Testing Basics', '3.1.1. Work Products Examinable by Static Testing', '3.1.2. Value of Static Testing', '3.1.3. Differences between Static Testing and Dynamic Testing', '3.2.1. Benefits of Early and Frequent Stakeholder Feedback', '3.2.2. Review Process Activities', '3.2.3. Roles and Responsibilities in Reviews', '3.2.4. Review Types', '3.2.5. Success Factors for Reviews', '4.1. Test Techniques Overview', '4.2. Black-Box Test Techniques', '4.2.1. Equivalence Partitioning', '4.2.2. Boundary Value Analysis', '4.2.3. Decision Table Testing', '4.2.4. State Transition Testing', '4.3. White-Box Test Techniques', '4.3.1. Statement Testing and Statement Coverage', '4.3.2. Branch Testing and Branch Coverage', '4.3.3. The Value of White-box Testing', '4.4. Experience-based Test Techniques', '4.4.1. Error Guessing', '4.4.2. Exploratory Testing', '4.4.3. Checklist-Based Testing', '4.5. Collaboration-based Test Approaches', '4.5.1. Collaborative User Story Writing', '4.5.2. Acceptance Criteria', '4.5.3. Acceptance Test-driven Development (ATDD)', '5.1.1. Purpose and Content of a Test Plan', \"5.1.2. Tester's Contribution to Iteration and Release Planning\", '5.1.3. Entry Criteria and Exit Criteria', '5.1.4. Estimation Techniques', '5.1.5. Test Case Prioritization', '5.1.6. Test Pyramid', '5.1.7. Testing Quadrants', '5.2. Risk Management', '5.2.1. Risk Definition and Risk Attributes', '5.2.2. Project Risks and Product Risks', '5.2.3. Product Risk Analysis', '5.2.4. Product Risk Control', '5.3. Test Monitoring, Test Control and Test Completion', '5.3.1. Metrics used in Testing', '5.3.2. Purpose, Content and Audience for Test Reports', '5.3.3. Communicating the Status of Testing', '5.4. Configuration Management', '5.5. Defect Management', '6.1. Tool Support for Testing', '6.2. Benefits and Risks of Test Automation']\n"
     ]
    }
   ],
   "source": [
    "# make a dictionary of key, which section_title and value, which is summary of each section title\n",
    "# Sample list of section titles\n",
    "section_titles = [\n",
    "    \"1.1. What is Testing?\",\n",
    "    \"1.1.1. Test Objectives\",\n",
    "    \"1.1.2. Testing and Debugging\",\n",
    "    \"1.2. Why is Testing Necessary?\",\n",
    "    \"1.2.1. Testing’s Contributions to Success\",\n",
    "    \"1.2.2. Testing and Quality Assurance (QA)\",\n",
    "    \"1.2.3. Errors, Defects, Failures, and Root Causes\",\n",
    "    \"1.3. Testing Principles\",\n",
    "    \"1.4. Test Activities, Testware and Test Roles\",\n",
    "    \"1.4.1. Test Activities and Tasks\",\n",
    "    \"1.4.2. Test Process in Context\",\n",
    "    \"1.4.3. Testware\",\n",
    "    \"1.4.4. Traceability between the Test Basis and Testware\",\n",
    "    \"1.4.5. Roles in Testing\",\n",
    "    \"1.5. Essential Skills and Good Practices in Testing\",\n",
    "    \"1.5.1. Generic Skills Required for Testing\",\n",
    "    \"1.5.2. Whole Team Approach\",\n",
    "    \"1.5.3. Independence of Testing\",\n",
    "    \"2.1. Testing in the Context of a Software Development Lifecycle\",\n",
    "    \"2.1.1. Impact of the Software Development Lifecycle on Testing\",\n",
    "    \"2.1.2. Software Development Lifecycle and Good Testing Practices\",\n",
    "    \"2.1.3. Testing as a Driver for Software Development\",\n",
    "    \"2.1.4. DevOps and Testing\",\n",
    "    \"2.1.5. Shift-Left Approach\",\n",
    "    \"2.1.6. Retrospectives and Process Improvement\",\n",
    "    \"2.2. Test Levels and Test Types\",\n",
    "    \"2.2.1. Test Levels\",\n",
    "    \"2.2.2. Test Types\",\n",
    "    \"2.2.3. Confirmation Testing and Regression Testing\",\n",
    "    \"2.3. Maintenance Testing\",\n",
    "    \"3.1. Static Testing Basics\",\n",
    "    \"3.1.1. Work Products Examinable by Static Testing\",\n",
    "    \"3.1.2. Value of Static Testing\",\n",
    "    \"3.1.3. Differences between Static Testing and Dynamic Testing\",\n",
    "    \"3.2.1. Benefits of Early and Frequent Stakeholder Feedback\",\n",
    "    \"3.2.2. Review Process Activities\",\n",
    "    \"3.2.3. Roles and Responsibilities in Reviews\",\n",
    "    \"3.2.4. Review Types\",\n",
    "    \"3.2.5. Success Factors for Reviews\",\n",
    "    \"4.1. Test Techniques Overview\",\n",
    "    \"4.2. Black-Box Test Techniques\",\n",
    "    \"4.2.1. Equivalence Partitioning\",\n",
    "    \"4.2.2. Boundary Value Analysis\",\n",
    "    \"4.2.3. Decision Table Testing\",\n",
    "    \"4.2.4. State Transition Testing\",\n",
    "    \"4.3. White-Box Test Techniques\",\n",
    "    \"4.3.1. Statement Testing and Statement Coverage\",\n",
    "    \"4.3.2. Branch Testing and Branch Coverage\",\n",
    "    \"4.3.3. The Value of White-box Testing\",\n",
    "    \"4.4. Experience-based Test Techniques\",\n",
    "    \"4.4.1. Error Guessing\",\n",
    "    \"4.4.2. Exploratory Testing\",\n",
    "    \"4.4.3. Checklist-Based Testing\",\n",
    "    \"4.5. Collaboration-based Test Approaches\",\n",
    "    \"4.5.1. Collaborative User Story Writing\",\n",
    "    \"4.5.2. Acceptance Criteria\",\n",
    "    \"4.5.3. Acceptance Test-driven Development (ATDD)\",\n",
    "    \"5.1.1. Purpose and Content of a Test Plan\",\n",
    "    \"5.1.2. Tester's Contribution to Iteration and Release Planning\",\n",
    "    \"5.1.3. Entry Criteria and Exit Criteria\",\n",
    "    \"5.1.4. Estimation Techniques\",\n",
    "    \"5.1.5. Test Case Prioritization\",\n",
    "    \"5.1.6. Test Pyramid\",\n",
    "    \"5.1.7. Testing Quadrants\",\n",
    "    \"5.2. Risk Management\",\n",
    "    \"5.2.1. Risk Definition and Risk Attributes\",\n",
    "    \"5.2.2. Project Risks and Product Risks\",\n",
    "    \"5.2.3. Product Risk Analysis\",\n",
    "    \"5.2.4. Product Risk Control\",\n",
    "    \"5.3. Test Monitoring, Test Control and Test Completion\",\n",
    "    \"5.3.1. Metrics used in Testing\",\n",
    "    \"5.3.2. Purpose, Content and Audience for Test Reports\",\n",
    "    \"5.3.3. Communicating the Status of Testing\",\n",
    "    \"5.4. Configuration Management\",\n",
    "    \"5.5. Defect Management\",\n",
    "    \"6.1. Tool Support for Testing\",\n",
    "    \"6.2. Benefits and Risks of Test Automation\",\n",
    "    # Add more section titles here\n",
    "]\n",
    "\n",
    "# Create an empty dictionary with section titles as keys\n",
    "#full_names = {title: \"\" for title in section_titles}\n",
    "\n",
    "# Print the dictionary to verify the structure\n",
    "print(section_titles)\n",
    "#section_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elena\\anaconda3\\envs\\qgmc\\Lib\\site-packages\\transformers\\generation\\utils.py:1268: UserWarning: Input length of decoder_input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: ['software', 'software', 'software testing', 'software testing is', 'software testing is', 'software testing is a', 'software testing is a set', 'software testing is a set of', 'software testing is a set of activities', 'software testing is a set of activities to', 'software testing is a set of activities to discover', 'software testing is a set of activities to discover defects', 'software testing is a set of activities to discover defects and', 'software testing is a set of activities to discover defects and evaluate', 'software testing is a set of activities to discover defects and evaluate quality', 'software testing is a set of activities to discover defects and evaluate quality of', 'software testing is a set of activities to discover defects and evaluate quality of software', 'software testing is a set of activities to discover defects and evaluate quality of software art', 'software testing is a set of activities to discover defects and evaluate quality of software arti', 'software testing is a set of activities to discover defects and evaluate quality of software artifact', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts.', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these art', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these arte', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects -', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test', 'software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test', \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test '\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test's\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'st\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static'\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests,\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not,\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not,\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing tester\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required –\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required –\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of s\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of sa\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\", \"software testing is a set of activities to discover defects and evaluate quality of software artifacts. these artefact is known as test objects - which are known to be test object based on the test'static' testing involves execution of tests, while static testing does not, allowing testers to have specialized knowledge and analytical skills if required – ensuring required coverage of saline test results proving that test result is complete and works as expected despite the fact that testing focuses entirely on\"]\n"
     ]
    }
   ],
   "source": [
    "#keyword generator\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Read the text from the StringIO file (replace with your own text)\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(\"summarize: \" + extracted_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate keywords\n",
    "num_keywords = 200  # Adjustable!!!!\n",
    "keywords = []\n",
    "\n",
    "for _ in range(num_keywords):\n",
    "    output = model.generate(inputs[\"input_ids\"], max_length=len(keywords) + 1, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    keyword = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    keywords.append(keyword)\n",
    "\n",
    "# Print the generated keywords\n",
    "print(\"Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try as soon as possible\n",
    "#paraphrasing text --> takes too long\n",
    "\n",
    "#from transformers import T5ForConditionalGeneration, T5Tokenizer#\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "#model_name = \"t5-large\"\n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "#tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# \n",
    "## Tokenize the text\n",
    "#inputs = tokenizer(\"paraphrase: \" + extracted_text, return_tensors=\"pt\", max_length=512, truncation=True)#\n",
    "## Generate paraphrased sentences\n",
    "#num_paraphrases = 155  # Adjust as needed\n",
    "#paraphrases = []#\n",
    "#for _ in range(num_paraphrases):\n",
    "#    output = model.generate(inputs[\"input_ids\"], max_length=512, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "#    paraphrase = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#    paraphrases.append(paraphrase)#\n",
    "## Print the generated paraphrases\n",
    "#for i, paraphrase in enumerate(paraphrases):\n",
    "#    print(f\"Paraphrase {i + 1}: {paraphrase}\")##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation of summary\n",
    "##Check if there are sections available before accessing them\n",
    "#if len(sections) >= 2:\n",
    "#    # Load the pre-trained T5 model and tokenizer\n",
    "#    model_name = \"t5-large\"\n",
    "#    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "#    tokenizer = T5Tokenizer.from_pretrained(model_name)#\n",
    "\n",
    "#    for section_index, (section_title, section_content) in enumerate(sections):\n",
    "#        # Tokenize the input section\n",
    "#        input_ids = tokenizer.encode(\"summarize: \" + section_content, return_tensors=\"pt\", max_length=1024, truncation=True)#\n",
    "\n",
    "#        # Generate the summary\n",
    "#        summary_ids = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "#        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)#\n",
    "\n",
    "#        # Print the summary for each section\n",
    "#        print(f\"Summary for Section {section_index + 1} - Title: {section_title}\")\n",
    "#        print(\"Summary:\", summary)\n",
    "#        print(\"-\" * 40)\n",
    "#else:\n",
    "#    print(\"Not enough sections found in the list.\")#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Section 1 - Title: 1.1\n",
      "Summary: software testing is a set of activities to discover defects and evaluate quality of software artifacts. a common misconception about testing is that it only consists of executing tests. testing is not only a technical activity. it also needs to be properly planned, managed, estimated, monitored and controlled.\n",
      "----------------------------------------\n",
      "Summary for Section 2 - Title: 1.1.2\n",
      "Summary: testing can trigger failures that are caused by defects software can directly find defects test object. debugging is concerned with finding causes of this failure, analyzing these causes, and eliminating them. when static testing identifies a defect, debugging is concerned with removing it.\n",
      "----------------------------------------\n",
      "Summary for Section 3 - Title: 1.2.1\n",
      "Summary: testing provides a cost-effective means of detecting defects. testing indirectly contributes to higher quality test objects. testing may also be required to meet contractual legal requirements.\n",
      "----------------------------------------\n",
      "Summary for Section 4 - Title: 1.2.3\n",
      "Summary: human beings make errors for various reasons, such as time pressure, complexity of work products, processes, infrastructure interactions, simply because they are tired lack adequate training. errors and defects are not only cause of failures. failures can also be caused by environmental conditions, such as when radiation electromagnetic field cause defects firmware.\n",
      "----------------------------------------\n",
      "Summary for Section 5 - Title: 1.4\n",
      "Summary: testing is context dependent, but, at a high level, there are common sets of test activities without which testing is less likely to achieve test objectives. these sets of test activities form a test process. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation.\n",
      "----------------------------------------\n",
      "Summary for Section 6 - Title: 5.1\n",
      "Summary: test monitoring involves ongoing checking of all test activities and comparison of actual progress against plan. test control involves taking actions necessary to meet objectives of testing.\n",
      "----------------------------------------\n",
      "Summary for Section 7 - Title: 1.4.2\n",
      "Summary: test activities are integral part of development processes carried out within an organization. way testing is carried out will depend on a number of contextual factors. these factors will have an impact on many test-related issues.\n",
      "----------------------------------------\n",
      "Summary for Section 8 - Title: 1.4.1\n",
      "Summary: test planning work products include: test plan, test schedule, risk register. test monitoring and control work products include: test progress reports. test execution work products include: test logs, and defect reports.\n",
      "----------------------------------------\n",
      "Summary for Section 9 - Title: 1.4.5\n",
      "Summary: test management role takes overall responsibility for test process, test team and leadership of test activities. testing role is mainly focused on activities of test analysis, test design, test implementation and test execution. different people may take on roles of testing and test management at different times.\n",
      "----------------------------------------\n",
      "Summary for Section 10 - Title: 1.5.1\n",
      "Summary: testing knowledge Thoroughness, carefulness, curiosity, attention to details, being methodical Good communication skills, active listening, being a team player Communication skills crucial. some people may perceive testing as a destructive activity, even though it contributes greatly to project success and product quality.\n",
      "----------------------------------------\n",
      "Summary for Section 11 - Title: 1.5.3\n",
      "Summary: independent testers are likely to recognize different kinds of failures and defects compared to developers because of their different backgrounds, technical perspectives, and biases. independent testers may be isolated from development team, which may lead to a lack of collaboration, communication problems, an adversarial relationship with development team. independent testers may be seen as a bottleneck be blamed for delays release.\n",
      "----------------------------------------\n",
      "Summary for Section 12 - Title: 2.1\n",
      "Summary: good testing practices that apply to all software development lifecycles. fl-testing focuses on identifying and identifying bugs early in the software development lifecycle.\n",
      "----------------------------------------\n",
      "Summary for Section 13 - Title: 2.1\n",
      "Summary: Devops might have an impact on testing FL- 4 summarize how devops might have an impact on testing FL- 5 summarize how devops might have an impact on testing FL- 6 summarize how devops might have an impact on testing FL- 7 summarize how devops might have an impact on testing FL- 8 summarize how devops might have an impact on testing FL- 8 summarize how devops might have an impact on testing FL- 8 summarize how de\n",
      "----------------------------------------\n",
      "Summary for Section 14 - Title: 2.1\n",
      "Summary: retrospectives can be used as a mechanism for process improvement. retrospectives can be used to identify areas for process improvement. retrospectives can be used to identify areas for process improvement.\n",
      "----------------------------------------\n",
      "Summary for Section 15 - Title: 2.2\n",
      "Summary: 2 distinguish different test types fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl.\n",
      "----------------------------------------\n",
      "Summary for Section 16 - Title: 2.3\n",
      "Summary: maintenance testing and its triggers. summarize maintenance testing and its triggers. summarize maintenance testing and its triggers. summarize maintenance testing and its triggers.\n",
      "----------------------------------------\n",
      "Summary for Section 17 - Title: 2.1.1\n",
      "Summary: choice of SDLC impacts on: Scope and timing of test activities Level of detail of test documentation Choice of test techniques and test approach Extent of test automation Role and responsibilities of a tester. dynamic testing cannot be performed early SDLC.\n",
      "----------------------------------------\n",
      "Summary for Section 18 - Title: 2.1.3\n",
      "Summary: TDD, ATDD and BDD are similar development approaches, where tests are defined as a means of directing development. each of these approaches implements principle of early testing and follows a shift-left approach. tests may persist as automated tests to ensure code quality future adaptions / refactoring.\n",
      "----------------------------------------\n",
      "Summary for Section 19 - Title: 2.1.5\n",
      "Summary: the principle of early testing is sometimes referred to as shift-left. shift-left normally suggests that testing should be done earlier SDLC. but it does not mean that testing later SDLC should be neglected.\n",
      "----------------------------------------\n",
      "Summary for Section 20 - Title: 2.2\n",
      "Summary: each test level is an instance of test process, performed relation to software at a given stage of development. sequential SDLC models, test levels are often defined such that exit criteria of one level are part of entry criteria for next level. test types are groups of test activities related to specific quality characteristics.\n",
      "----------------------------------------\n",
      "Summary for Section 21 - Title: 2.2.2\n",
      "Summary: functional testing evaluates functions that a component system should perform. non-functional testing evaluates attributes other than functional characteristics of a component system. black-box testing is specification-based and derives tests from documentation external to test object. white-box testing is structure-based and derives tests from system's implementation internal structure.\n",
      "----------------------------------------\n",
      "Summary for Section 22 - Title: 2.3\n",
      "Summary: maintenance can involve planned releases/deployments and unplanned releases/deployments. impact analysis may be done before a change is made. testing changes to a system production includes both evaluating success of implementation of change and checking for possible regressions parts of system that remain unchanged.\n",
      "----------------------------------------\n",
      "Summary for Section 23 - Title: 3.1\n",
      "Summary: explain value of static testing. explain value of static testing. explain value of static testing. explain value of static testing. explain value of dynamic testing.\n",
      "----------------------------------------\n",
      "Summary for Section 24 - Title: 3.2\n",
      "Summary: identifying benefits of early and frequent stakeholder feedback. identifying benefits of early and frequent stakeholder feedback. identifying benefits of frequent stakeholder feedback.\n",
      "----------------------------------------\n",
      "Summary for Section 25 - Title: 3.2\n",
      "Summary: responsibilities are assigned to principal roles when performing reviews. reviewers should be aware of which responsibilities are assigned to principal roles when performing reviews. reviewers should be aware of which responsibilities are assigned to principal roles when performing reviews.\n",
      "----------------------------------------\n",
      "Summary for Section 26 - Title: 3.2\n",
      "Summary: 5 review factors that contribute to a successful review. a reviewer's ability to remember a reviewer's name is one of the most important factors.\n",
      "----------------------------------------\n",
      "Summary for Section 27 - Title: 3.1.1\n",
      "Summary: Almost any work product that can be read and understood can be subject of a review. work products that are not appropriate for static testing include those that are difficult to interpret by human beings.\n",
      "----------------------------------------\n",
      "Summary for Section 28 - Title: 3.1.3\n",
      "Summary: static and dynamic testing can both lead to detection of defects work products. however there are some defect types that can only be found by either static dynamic testing. static testing may more easily detect defects that lay on paths through code that are rarely executed hard to reach using dynamic testing.\n",
      "----------------------------------------\n",
      "Summary for Section 29 - Title: 3.2.1\n",
      "Summary: early and frequent stakeholder feedback allows for early communication of potential quality problems. a failure to deliver what stakeholder wants can result costly rework, missed deadlines, blame games, and might even lead to complete project failure.\n",
      "----------------------------------------\n",
      "Summary for Section 30 - Title: 3.2.3\n",
      "Summary: reviews involve various stakeholders, who may take on several roles. a reviewer may be someone working on project, a subject matter expert, any other stakeholder. a review leader – takes overall responsibility for review.\n",
      "----------------------------------------\n",
      "Summary for Section 31 - Title: 3.2.5\n",
      "Summary: reviews should have clear objectives and measurable exit criteria. reviews should be conducted on small chunks, so reviewers do not lose concentration. reviews should be part of organization’s culture, to promote learning and process improvement.\n",
      "----------------------------------------\n",
      "Summary for Section 32 - Title: 4.2\n",
      "Summary: 1 Use equivalence partitioning to derive test cases. 1 use equivalence partitioning to derive test cases.\n",
      "----------------------------------------\n",
      "Summary for Section 33 - Title: 4.2\n",
      "Summary: 3 use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases.\n",
      "----------------------------------------\n",
      "Summary for Section 34 - Title: 4.3\n",
      "Summary: explains statement testing. explains statement testing. explains statement testing. explains statement testing. explains statement testing. explains statement testing.\n",
      "----------------------------------------\n",
      "Summary for Section 35 - Title: 4.3\n",
      "Summary: explain value of white-box testing 4.4 experience-based test techniques 4.4 white-box testing. explain value of white-box testing. explain value of white-box testing.\n",
      "----------------------------------------\n",
      "Summary for Section 36 - Title: 4.4\n",
      "Summary: exploratory testing is a form of exploratory testing. it involves a series of tests to find out if a hypothesis is true or false. the results are compared with those of a control group.\n",
      "----------------------------------------\n",
      "Summary for Section 37 - Title: 4.5\n",
      "Summary: collaboration-based test approaches - cbtas. collaboration-based test approaches - cbtas. cbtas.\n",
      "----------------------------------------\n",
      "Summary for Section 38 - Title: 4.5\n",
      "Summary: acceptance criteria can be written in a number of different ways. acceptance criteria can be written in a number of different ways. acceptance criteria can be written in a number of different ways. acceptance criteria can be written in a number of different ways.\n",
      "----------------------------------------\n",
      "Summary for Section 39 - Title: 4.1\n",
      "Summary: test techniques help to develop a relatively small, but sufficient, set of test cases a systematic way. they also help tester define test conditions, identify coverage items, and identify test data during test analysis and design. test techniques are classified as black-box, white-box, and experience-based.\n",
      "----------------------------------------\n",
      "Summary for Section 40 - Title: 4.2.1\n",
      "Summary: equivalence partitioning divides data into partitions based on expectation that all elements of a given partition are to be processed same way by test object. partitions may be continuous discrete, ordered unordered, finite infinite. to achieve 100% coverage with this technique, test cases must exercise all identified partitions by covering each partition at least once.\n",
      "----------------------------------------\n",
      "Summary for Section 41 - Title: 4.2.3\n",
      "Summary: decision tables are an effective way of recording complex logic, such as business rules. a full decision table has enough columns to cover every combination of conditions. table can be simplified by deleting columns containing infeasible combinations.\n",
      "----------------------------------------\n",
      "Summary for Section 42 - Title: 4.3\n",
      "Summary: this section focuses on two code-related white-box test techniques: statement testing Branch testing. there are also more rigorous techniques that are used some safety-critical, mission-critical, high-integrity environments. these techniques are not discussed this syllabus.\n",
      "----------------------------------------\n",
      "Summary for Section 43 - Title: 4.3.2\n",
      "Summary: branch testing and branch coverage aim is to design test cases to exercise branches code until an acceptable level of coverage is achieved. coverage measured as number of branches exercised by test cases divided by total number of branches. when 100% branch coverage is achieved, all branches code, unconditional and conditional are exercised by test cases.\n",
      "----------------------------------------\n",
      "Summary for Section 44 - Title: 4.4\n",
      "Summary: Error guessing Exploratory testing Checklist-based testing Checklist-based testing Checklist-based testing Error guessing Exploratory testing Checklist-based testing.\n",
      "----------------------------------------\n",
      "Summary for Section 45 - Title: 4.4.2\n",
      "Summary: testing is used to learn more about test object, to explore it more deeply with focused tests, and to create tests for untested areas. exploratory testing will be more effective if tester is experienced, has domain knowledge and has a high degree of essential skills.\n",
      "----------------------------------------\n",
      "Summary for Section 46 - Title: 4.5\n",
      "Summary: each of above-mentioned techniques has a particular objective with respect to defect detection. collaboration-based approaches focus also on defect avoidance by collaboration and communication.\n",
      "----------------------------------------\n",
      "Summary for Section 47 - Title: 4.5.2\n",
      "Summary: acceptance criteria are conditions that an implementation of user story must meet to be accepted by stakeholders. acceptance criteria may be viewed as test conditions that should be exercised by tests. there are several ways to write acceptance criteria for a user story.\n",
      "----------------------------------------\n",
      "Summary for Section 48 - Title: 5.1\n",
      "Summary: 1 Exemplify purpose and content of a test plan FL-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-fl-f\n",
      "----------------------------------------\n",
      "Summary for Section 49 - Title: 5.1\n",
      "Summary: compare and contrast entry criteria and exit criteria. compare and contrast entry criteria and exit criteria. compare and contrast entry criteria and exit criteria. compare and contrast entry criteria and exit criteria.\n",
      "----------------------------------------\n",
      "Summary for Section 50 - Title: 5.1\n",
      "Summary: 5 apply test case prioritization. FL- 5 apply test case prioritization. FL- 5 apply test case prioritization.\n",
      "----------------------------------------\n",
      "Summary for Section 51 - Title: 5.1\n",
      "Summary: testing quadrants and their relationships with test levels and test types. risk management is a key part of a test manager's job. a test manager's job is to manage the risk of an incident.\n",
      "----------------------------------------\n",
      "Summary for Section 52 - Title: 5.2\n",
      "Summary: 2 distinguish between project risks and product risks. product risks are more likely to be a problem than a project risk. product risks more likely to be a problem than a project risk.\n",
      "----------------------------------------\n",
      "Summary for Section 53 - Title: 5.2\n",
      "Summary: 5.3 test monitoring, test control and test completion 5.3 test monitoring, test control and test completion 5.3 test monitoring, test monitoring, test control and test completion 5.3 test monitoring, test monitoring, test control and test completion 5.3 test monitoring, test monitoring, test control and test completion 5.3 test monitoring, test monitoring, test monitoring and test completion 5.4 test monitoring, test monitoring, test control and test completion 5.3 test monitoring, test monitoring, test monitoring, test control and test completion 5.4 test monitoring, test monitoring, test control and test\n",
      "----------------------------------------\n",
      "Summary for Section 54 - Title: 5.3\n",
      "Summary: 2 summarize purposes, content, and audiences for test reports. test reports can be used for a variety of purposes, including assessing the effectiveness of a product or service.\n",
      "----------------------------------------\n",
      "Summary for Section 55 - Title: 5.4\n",
      "Summary: configuration management supports testing 5.5 defect management 5.5 configuration management supports testing 5.5 defect management 5.5 configuration management supports defect management 5.5 defect management 5.5 configuration management supports testing.\n",
      "----------------------------------------\n",
      "Summary for Section 56 - Title: 5.1\n",
      "Summary: test planning.................\n",
      "----------------------------------------\n",
      "Summary for Section 57 - Title: 5.1.2\n",
      "Summary: release planning looks ahead to release of a product, defines and re-defines product backlog. it also serves as basis for test approach and test plan across all iterations. iteration planning looks ahead to end of a single iteration and is concerned with iteration backlog.\n",
      "----------------------------------------\n",
      "Summary for Section 58 - Title: 5.1.4\n",
      "Summary: test effort estimation involves predicting amount of test-related work needed to meet objectives of a test project. it is important to make it clear to stakeholders that estimate is based on a number of assumptions and is always subject to estimation error. following four estimation techniques are described in this syllabus.\n",
      "----------------------------------------\n",
      "Summary for Section 59 - Title: 5.1.6\n",
      "Summary: test pyramid model shows that different tests may have different granularity. test pyramid model supports team test automation and test effort allocation. pyramid layers represent groups of tests. higher layer, lower test granularity, test isolation and test execution time.\n",
      "----------------------------------------\n",
      "Summary for Section 60 - Title: 5.2\n",
      "Summary: organizations face many internal and external factors that make it uncertain whether or when they will achieve their objectives. risk management allows organizations to increase likelihood of achieving objectives, improve quality of their products and increase stakeholders’ confidence and trust. main risk management activities are: risk analysis Risk control test approach, which test activities are selected, prioritized, and managed based on risk control.\n",
      "----------------------------------------\n",
      "Summary for Section 61 - Title: 5.2.2\n",
      "Summary: software testing one is generally concerned with two types of risks: project risks and product risks. project risks are related to management and control of project. product risks include: missing wrong functionality, incorrect calculations, runtime errors, poor architecture, inefficient algorithms.\n",
      "----------------------------------------\n",
      "Summary for Section 62 - Title: 5.2.4\n",
      "Summary: product risk control consists of risk mitigation and risk monitoring. several response options to risk are possible, e.g., risk acceptance, risk transfer, contingency plan. testing can be used to mitigate product risks by testing.\n",
      "----------------------------------------\n",
      "Summary for Section 63 - Title: 5.3.1\n",
      "Summary: test monitoring gathers a variety of metrics to support test control and test completion. common test metrics include: project progress metrics Test progress metrics Product quality metrics Defect metrics Risk metrics Coverage metrics cost metrics. test metrics are gathered to show progress against planned schedule and budget.\n",
      "----------------------------------------\n",
      "Summary for Section 64 - Title: 5.3.3\n",
      "Summary: best means of communicating test status varies, depending on test management concerns, organizational test strategies, regulatory standards, or, case of self-organizing teams, on team itself. verbal communication with team members and other stakeholders Dashboards Electronic communication channels Online documentation Formal test reports One more option can be used.\n",
      "----------------------------------------\n",
      "Summary for Section 65 - Title: 5.5\n",
      "Summary: defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# generation of summary and adding of summary to the dictionary as value to the key\n",
    "# Initialize an empty dictionary to store section content and summaries\n",
    "sections_dict = {}\n",
    "\n",
    "# Check if there are sections available before accessing them\n",
    "if len(sections) >= 2:\n",
    "    # Load the pre-trained T5 model and tokenizer\n",
    "    model_name = \"t5-large\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    for section_index, (section_title, section_content) in enumerate(sections):\n",
    "        # Tokenize the input section\n",
    "        input_ids = tokenizer.encode(\"summarize: \" + section_content, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate the summary\n",
    "        summary_ids = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Store the summary in sections_dict using the section title as the key\n",
    "        sections_dict[section_title] = summary\n",
    "\n",
    "        # Print the summary for each section\n",
    "        print(f\"Summary for Section {section_index + 1} - Title: {section_title}\")\n",
    "        print(\"Summary:\", summary)\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"Not enough sections found in the list.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 : software testing is a set of activities to discover defects and evaluate quality of software artifacts. a common misconception about testing is that it only consists of executing tests. testing is not only a technical activity. it also needs to be properly planned, managed, estimated, monitored and controlled.\n",
      "1.1.2 : testing can trigger failures that are caused by defects software can directly find defects test object. debugging is concerned with finding causes of this failure, analyzing these causes, and eliminating them. when static testing identifies a defect, debugging is concerned with removing it.\n",
      "1.2.1 : testing provides a cost-effective means of detecting defects. testing indirectly contributes to higher quality test objects. testing may also be required to meet contractual legal requirements.\n",
      "1.2.3 : human beings make errors for various reasons, such as time pressure, complexity of work products, processes, infrastructure interactions, simply because they are tired lack adequate training. errors and defects are not only cause of failures. failures can also be caused by environmental conditions, such as when radiation electromagnetic field cause defects firmware.\n",
      "1.4 : testing is context dependent, but, at a high level, there are common sets of test activities without which testing is less likely to achieve test objectives. these sets of test activities form a test process. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation.\n",
      "5.1 : test planning.................\n",
      "1.4.2 : test activities are integral part of development processes carried out within an organization. way testing is carried out will depend on a number of contextual factors. these factors will have an impact on many test-related issues.\n",
      "1.4.1 : test planning work products include: test plan, test schedule, risk register. test monitoring and control work products include: test progress reports. test execution work products include: test logs, and defect reports.\n",
      "1.4.5 : test management role takes overall responsibility for test process, test team and leadership of test activities. testing role is mainly focused on activities of test analysis, test design, test implementation and test execution. different people may take on roles of testing and test management at different times.\n",
      "1.5.1 : testing knowledge Thoroughness, carefulness, curiosity, attention to details, being methodical Good communication skills, active listening, being a team player Communication skills crucial. some people may perceive testing as a destructive activity, even though it contributes greatly to project success and product quality.\n",
      "1.5.3 : independent testers are likely to recognize different kinds of failures and defects compared to developers because of their different backgrounds, technical perspectives, and biases. independent testers may be isolated from development team, which may lead to a lack of collaboration, communication problems, an adversarial relationship with development team. independent testers may be seen as a bottleneck be blamed for delays release.\n",
      "2.1 : retrospectives can be used as a mechanism for process improvement. retrospectives can be used to identify areas for process improvement. retrospectives can be used to identify areas for process improvement.\n",
      "2.2 : each test level is an instance of test process, performed relation to software at a given stage of development. sequential SDLC models, test levels are often defined such that exit criteria of one level are part of entry criteria for next level. test types are groups of test activities related to specific quality characteristics.\n",
      "2.3 : maintenance can involve planned releases/deployments and unplanned releases/deployments. impact analysis may be done before a change is made. testing changes to a system production includes both evaluating success of implementation of change and checking for possible regressions parts of system that remain unchanged.\n",
      "2.1.1 : choice of SDLC impacts on: Scope and timing of test activities Level of detail of test documentation Choice of test techniques and test approach Extent of test automation Role and responsibilities of a tester. dynamic testing cannot be performed early SDLC.\n",
      "2.1.3 : TDD, ATDD and BDD are similar development approaches, where tests are defined as a means of directing development. each of these approaches implements principle of early testing and follows a shift-left approach. tests may persist as automated tests to ensure code quality future adaptions / refactoring.\n",
      "2.1.5 : the principle of early testing is sometimes referred to as shift-left. shift-left normally suggests that testing should be done earlier SDLC. but it does not mean that testing later SDLC should be neglected.\n",
      "2.2.2 : functional testing evaluates functions that a component system should perform. non-functional testing evaluates attributes other than functional characteristics of a component system. black-box testing is specification-based and derives tests from documentation external to test object. white-box testing is structure-based and derives tests from system's implementation internal structure.\n",
      "3.1 : explain value of static testing. explain value of static testing. explain value of static testing. explain value of static testing. explain value of dynamic testing.\n",
      "3.2 : 5 review factors that contribute to a successful review. a reviewer's ability to remember a reviewer's name is one of the most important factors.\n",
      "3.1.1 : Almost any work product that can be read and understood can be subject of a review. work products that are not appropriate for static testing include those that are difficult to interpret by human beings.\n",
      "3.1.3 : static and dynamic testing can both lead to detection of defects work products. however there are some defect types that can only be found by either static dynamic testing. static testing may more easily detect defects that lay on paths through code that are rarely executed hard to reach using dynamic testing.\n",
      "3.2.1 : early and frequent stakeholder feedback allows for early communication of potential quality problems. a failure to deliver what stakeholder wants can result costly rework, missed deadlines, blame games, and might even lead to complete project failure.\n",
      "3.2.3 : reviews involve various stakeholders, who may take on several roles. a reviewer may be someone working on project, a subject matter expert, any other stakeholder. a review leader – takes overall responsibility for review.\n",
      "3.2.5 : reviews should have clear objectives and measurable exit criteria. reviews should be conducted on small chunks, so reviewers do not lose concentration. reviews should be part of organization’s culture, to promote learning and process improvement.\n",
      "4.2 : 3 use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases.\n",
      "4.3 : this section focuses on two code-related white-box test techniques: statement testing Branch testing. there are also more rigorous techniques that are used some safety-critical, mission-critical, high-integrity environments. these techniques are not discussed this syllabus.\n",
      "4.4 : Error guessing Exploratory testing Checklist-based testing Checklist-based testing Checklist-based testing Error guessing Exploratory testing Checklist-based testing.\n",
      "4.5 : each of above-mentioned techniques has a particular objective with respect to defect detection. collaboration-based approaches focus also on defect avoidance by collaboration and communication.\n",
      "4.1 : test techniques help to develop a relatively small, but sufficient, set of test cases a systematic way. they also help tester define test conditions, identify coverage items, and identify test data during test analysis and design. test techniques are classified as black-box, white-box, and experience-based.\n",
      "4.2.1 : equivalence partitioning divides data into partitions based on expectation that all elements of a given partition are to be processed same way by test object. partitions may be continuous discrete, ordered unordered, finite infinite. to achieve 100% coverage with this technique, test cases must exercise all identified partitions by covering each partition at least once.\n",
      "4.2.3 : decision tables are an effective way of recording complex logic, such as business rules. a full decision table has enough columns to cover every combination of conditions. table can be simplified by deleting columns containing infeasible combinations.\n",
      "4.3.2 : branch testing and branch coverage aim is to design test cases to exercise branches code until an acceptable level of coverage is achieved. coverage measured as number of branches exercised by test cases divided by total number of branches. when 100% branch coverage is achieved, all branches code, unconditional and conditional are exercised by test cases.\n",
      "4.4.2 : testing is used to learn more about test object, to explore it more deeply with focused tests, and to create tests for untested areas. exploratory testing will be more effective if tester is experienced, has domain knowledge and has a high degree of essential skills.\n",
      "4.5.2 : acceptance criteria are conditions that an implementation of user story must meet to be accepted by stakeholders. acceptance criteria may be viewed as test conditions that should be exercised by tests. there are several ways to write acceptance criteria for a user story.\n",
      "5.2 : organizations face many internal and external factors that make it uncertain whether or when they will achieve their objectives. risk management allows organizations to increase likelihood of achieving objectives, improve quality of their products and increase stakeholders’ confidence and trust. main risk management activities are: risk analysis Risk control test approach, which test activities are selected, prioritized, and managed based on risk control.\n",
      "5.3 : 2 summarize purposes, content, and audiences for test reports. test reports can be used for a variety of purposes, including assessing the effectiveness of a product or service.\n",
      "5.4 : configuration management supports testing 5.5 defect management 5.5 configuration management supports testing 5.5 defect management 5.5 configuration management supports defect management 5.5 defect management 5.5 configuration management supports testing.\n",
      "5.1.2 : release planning looks ahead to release of a product, defines and re-defines product backlog. it also serves as basis for test approach and test plan across all iterations. iteration planning looks ahead to end of a single iteration and is concerned with iteration backlog.\n",
      "5.1.4 : test effort estimation involves predicting amount of test-related work needed to meet objectives of a test project. it is important to make it clear to stakeholders that estimate is based on a number of assumptions and is always subject to estimation error. following four estimation techniques are described in this syllabus.\n",
      "5.1.6 : test pyramid model shows that different tests may have different granularity. test pyramid model supports team test automation and test effort allocation. pyramid layers represent groups of tests. higher layer, lower test granularity, test isolation and test execution time.\n",
      "5.2.2 : software testing one is generally concerned with two types of risks: project risks and product risks. project risks are related to management and control of project. product risks include: missing wrong functionality, incorrect calculations, runtime errors, poor architecture, inefficient algorithms.\n",
      "5.2.4 : product risk control consists of risk mitigation and risk monitoring. several response options to risk are possible, e.g., risk acceptance, risk transfer, contingency plan. testing can be used to mitigate product risks by testing.\n",
      "5.3.1 : test monitoring gathers a variety of metrics to support test control and test completion. common test metrics include: project progress metrics Test progress metrics Product quality metrics Defect metrics Risk metrics Coverage metrics cost metrics. test metrics are gathered to show progress against planned schedule and budget.\n",
      "5.3.3 : best means of communicating test status varies, depending on test management concerns, organizational test strategies, regulatory standards, or, case of self-organizing teams, on team itself. verbal communication with team members and other stakeholders Dashboards Electronic communication channels Online documentation Formal test reports One more option can be used.\n",
      "5.5 : defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dict is filled w values\n",
    "[print(key,':',value) for key, value in sections_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1 : testing knowledge Thoroughness, carefulness, curiosity, attention to details, being methodical Good communication skills, active listening, being a team player Communication skills crucial. some people may perceive testing as a destructive activity, even though it contributes greatly to project success and product quality.\n",
      "3.2.1 : early and frequent stakeholder feedback allows for early communication of potential quality problems. a failure to deliver what stakeholder wants can result costly rework, missed deadlines, blame games, and might even lead to complete project failure.\n",
      "1.1. What is Testing? : software testing is a set of activities to discover defects and evaluate quality of software artifacts. a common misconception about testing is that it only consists of executing tests. testing is not only a technical activity. it also needs to be properly planned, managed, estimated, monitored and controlled.\n",
      "1.1.1. Test Objectives : i was not able to generate summary for this section\n",
      "1.1.2. Testing and Debugging : testing can trigger failures that are caused by defects software can directly find defects test object. debugging is concerned with finding causes of this failure, analyzing these causes, and eliminating them. when static testing identifies a defect, debugging is concerned with removing it.\n",
      "1.2. Why is Testing Necessary? : i was not able to generate summary for this section\n",
      "1.2.1. Testing’s Contributions to Success : testing provides a cost-effective means of detecting defects. testing indirectly contributes to higher quality test objects. testing may also be required to meet contractual legal requirements.\n",
      "1.2.2. Testing and Quality Assurance (QA) : each test level is an instance of test process, performed relation to software at a given stage of development. sequential SDLC models, test levels are often defined such that exit criteria of one level are part of entry criteria for next level. test types are groups of test activities related to specific quality characteristics.\n",
      "1.2.3. Errors, Defects, Failures, and Root Causes : human beings make errors for various reasons, such as time pressure, complexity of work products, processes, infrastructure interactions, simply because they are tired lack adequate training. errors and defects are not only cause of failures. failures can also be caused by environmental conditions, such as when radiation electromagnetic field cause defects firmware.\n",
      "1.3. Testing Principles : i was not able to generate summary for this section\n",
      "1.4. Test Activities, Testware and Test Roles : testing is context dependent, but, at a high level, there are common sets of test activities without which testing is less likely to achieve test objectives. these sets of test activities form a test process. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation. which test activities are included this test process, how they are implemented, and when they occur is normally decided as part of test planning for specific situation.\n",
      "1.4.1. Test Activities and Tasks : test planning work products include: test plan, test schedule, risk register. test monitoring and control work products include: test progress reports. test execution work products include: test logs, and defect reports.\n",
      "1.4.2. Test Process in Context : test activities are integral part of development processes carried out within an organization. way testing is carried out will depend on a number of contextual factors. these factors will have an impact on many test-related issues.\n",
      "1.4.3. Testware : this section focuses on two code-related white-box test techniques: statement testing Branch testing. there are also more rigorous techniques that are used some safety-critical, mission-critical, high-integrity environments. these techniques are not discussed this syllabus.\n",
      "1.4.4. Traceability between the Test Basis and Testware : Error guessing Exploratory testing Checklist-based testing Checklist-based testing Checklist-based testing Error guessing Exploratory testing Checklist-based testing.\n",
      "1.4.5. Roles in Testing : test management role takes overall responsibility for test process, test team and leadership of test activities. testing role is mainly focused on activities of test analysis, test design, test implementation and test execution. different people may take on roles of testing and test management at different times.\n",
      "1.5. Essential Skills and Good Practices in Testing : i was not able to generate summary for this section\n",
      "1.5.1. Generic Skills Required for Testing : test planning.................\n",
      "1.5.2. Whole Team Approach : organizations face many internal and external factors that make it uncertain whether or when they will achieve their objectives. risk management allows organizations to increase likelihood of achieving objectives, improve quality of their products and increase stakeholders’ confidence and trust. main risk management activities are: risk analysis Risk control test approach, which test activities are selected, prioritized, and managed based on risk control.\n",
      "1.5.3. Independence of Testing : independent testers are likely to recognize different kinds of failures and defects compared to developers because of their different backgrounds, technical perspectives, and biases. independent testers may be isolated from development team, which may lead to a lack of collaboration, communication problems, an adversarial relationship with development team. independent testers may be seen as a bottleneck be blamed for delays release.\n",
      "2.1. Testing in the Context of a Software Development Lifecycle : retrospectives can be used as a mechanism for process improvement. retrospectives can be used to identify areas for process improvement. retrospectives can be used to identify areas for process improvement.\n",
      "2.1.1. Impact of the Software Development Lifecycle on Testing : choice of SDLC impacts on: Scope and timing of test activities Level of detail of test documentation Choice of test techniques and test approach Extent of test automation Role and responsibilities of a tester. dynamic testing cannot be performed early SDLC.\n",
      "2.1.2. Software Development Lifecycle and Good Testing Practices : i was not able to generate summary for this section\n",
      "2.1.3. Testing as a Driver for Software Development : TDD, ATDD and BDD are similar development approaches, where tests are defined as a means of directing development. each of these approaches implements principle of early testing and follows a shift-left approach. tests may persist as automated tests to ensure code quality future adaptions / refactoring.\n",
      "2.1.4. DevOps and Testing : i was not able to generate summary for this section\n",
      "2.1.5. Shift-Left Approach : the principle of early testing is sometimes referred to as shift-left. shift-left normally suggests that testing should be done earlier SDLC. but it does not mean that testing later SDLC should be neglected.\n",
      "2.1.6. Retrospectives and Process Improvement : i was not able to generate summary for this section\n",
      "2.2. Test Levels and Test Types : i was not able to generate summary for this section\n",
      "2.2.1. Test Levels : i was not able to generate summary for this section\n",
      "2.2.2. Test Types : functional testing evaluates functions that a component system should perform. non-functional testing evaluates attributes other than functional characteristics of a component system. black-box testing is specification-based and derives tests from documentation external to test object. white-box testing is structure-based and derives tests from system's implementation internal structure.\n",
      "2.2.3. Confirmation Testing and Regression Testing : maintenance can involve planned releases/deployments and unplanned releases/deployments. impact analysis may be done before a change is made. testing changes to a system production includes both evaluating success of implementation of change and checking for possible regressions parts of system that remain unchanged.\n",
      "2.3. Maintenance Testing : i was not able to generate summary for this section\n",
      "3.1. Static Testing Basics : explain value of static testing. explain value of static testing. explain value of static testing. explain value of static testing. explain value of dynamic testing.\n",
      "3.1.1. Work Products Examinable by Static Testing : Almost any work product that can be read and understood can be subject of a review. work products that are not appropriate for static testing include those that are difficult to interpret by human beings.\n",
      "3.1.2. Value of Static Testing : i was not able to generate summary for this section\n",
      "3.1.3. Differences between Static Testing and Dynamic Testing : static and dynamic testing can both lead to detection of defects work products. however there are some defect types that can only be found by either static dynamic testing. static testing may more easily detect defects that lay on paths through code that are rarely executed hard to reach using dynamic testing.\n",
      "3.2.1. Benefits of Early and Frequent Stakeholder Feedback : 5 review factors that contribute to a successful review. a reviewer's ability to remember a reviewer's name is one of the most important factors.\n",
      "3.2.2. Review Process Activities : i was not able to generate summary for this section\n",
      "3.2.3. Roles and Responsibilities in Reviews : reviews involve various stakeholders, who may take on several roles. a reviewer may be someone working on project, a subject matter expert, any other stakeholder. a review leader – takes overall responsibility for review.\n",
      "3.2.4. Review Types : i was not able to generate summary for this section\n",
      "3.2.5. Success Factors for Reviews : reviews should have clear objectives and measurable exit criteria. reviews should be conducted on small chunks, so reviewers do not lose concentration. reviews should be part of organization’s culture, to promote learning and process improvement.\n",
      "4.1. Test Techniques Overview : test techniques help to develop a relatively small, but sufficient, set of test cases a systematic way. they also help tester define test conditions, identify coverage items, and identify test data during test analysis and design. test techniques are classified as black-box, white-box, and experience-based.\n",
      "4.2. Black-Box Test Techniques : 3 use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases. use decision table testing to derive test cases.\n",
      "4.2.1. Equivalence Partitioning : equivalence partitioning divides data into partitions based on expectation that all elements of a given partition are to be processed same way by test object. partitions may be continuous discrete, ordered unordered, finite infinite. to achieve 100% coverage with this technique, test cases must exercise all identified partitions by covering each partition at least once.\n",
      "4.2.2. Boundary Value Analysis : i was not able to generate summary for this section\n",
      "4.2.3. Decision Table Testing : decision tables are an effective way of recording complex logic, such as business rules. a full decision table has enough columns to cover every combination of conditions. table can be simplified by deleting columns containing infeasible combinations.\n",
      "4.2.4. State Transition Testing : i was not able to generate summary for this section\n",
      "4.3. White-Box Test Techniques : i was not able to generate summary for this section\n",
      "4.3.1. Statement Testing and Statement Coverage : i was not able to generate summary for this section\n",
      "4.3.2. Branch Testing and Branch Coverage : branch testing and branch coverage aim is to design test cases to exercise branches code until an acceptable level of coverage is achieved. coverage measured as number of branches exercised by test cases divided by total number of branches. when 100% branch coverage is achieved, all branches code, unconditional and conditional are exercised by test cases.\n",
      "4.3.3. The Value of White-box Testing : i was not able to generate summary for this section\n",
      "4.4. Experience-based Test Techniques : i was not able to generate summary for this section\n",
      "4.4.1. Error Guessing : i was not able to generate summary for this section\n",
      "4.4.2. Exploratory Testing : testing is used to learn more about test object, to explore it more deeply with focused tests, and to create tests for untested areas. exploratory testing will be more effective if tester is experienced, has domain knowledge and has a high degree of essential skills.\n",
      "4.4.3. Checklist-Based Testing : i was not able to generate summary for this section\n",
      "4.5. Collaboration-based Test Approaches : each of above-mentioned techniques has a particular objective with respect to defect detection. collaboration-based approaches focus also on defect avoidance by collaboration and communication.\n",
      "4.5.1. Collaborative User Story Writing : i was not able to generate summary for this section\n",
      "4.5.2. Acceptance Criteria : acceptance criteria are conditions that an implementation of user story must meet to be accepted by stakeholders. acceptance criteria may be viewed as test conditions that should be exercised by tests. there are several ways to write acceptance criteria for a user story.\n",
      "4.5.3. Acceptance Test-driven Development (ATDD) : 2 summarize purposes, content, and audiences for test reports. test reports can be used for a variety of purposes, including assessing the effectiveness of a product or service.\n",
      "5.1.1. Purpose and Content of a Test Plan : i was not able to generate summary for this section\n",
      "5.1.2. Tester's Contribution to Iteration and Release Planning : release planning looks ahead to release of a product, defines and re-defines product backlog. it also serves as basis for test approach and test plan across all iterations. iteration planning looks ahead to end of a single iteration and is concerned with iteration backlog.\n",
      "5.1.3. Entry Criteria and Exit Criteria : i was not able to generate summary for this section\n",
      "5.1.4. Estimation Techniques : test effort estimation involves predicting amount of test-related work needed to meet objectives of a test project. it is important to make it clear to stakeholders that estimate is based on a number of assumptions and is always subject to estimation error. following four estimation techniques are described in this syllabus.\n",
      "5.1.5. Test Case Prioritization : i was not able to generate summary for this section\n",
      "5.1.6. Test Pyramid : test pyramid model shows that different tests may have different granularity. test pyramid model supports team test automation and test effort allocation. pyramid layers represent groups of tests. higher layer, lower test granularity, test isolation and test execution time.\n",
      "5.1.7. Testing Quadrants : i was not able to generate summary for this section\n",
      "5.2. Risk Management : i was not able to generate summary for this section\n",
      "5.2.1. Risk Definition and Risk Attributes : i was not able to generate summary for this section\n",
      "5.2.2. Project Risks and Product Risks : software testing one is generally concerned with two types of risks: project risks and product risks. project risks are related to management and control of project. product risks include: missing wrong functionality, incorrect calculations, runtime errors, poor architecture, inefficient algorithms.\n",
      "5.2.3. Product Risk Analysis : i was not able to generate summary for this section\n",
      "5.2.4. Product Risk Control : product risk control consists of risk mitigation and risk monitoring. several response options to risk are possible, e.g., risk acceptance, risk transfer, contingency plan. testing can be used to mitigate product risks by testing.\n",
      "5.3. Test Monitoring, Test Control and Test Completion : i was not able to generate summary for this section\n",
      "5.3.1. Metrics used in Testing : test monitoring gathers a variety of metrics to support test control and test completion. common test metrics include: project progress metrics Test progress metrics Product quality metrics Defect metrics Risk metrics Coverage metrics cost metrics. test metrics are gathered to show progress against planned schedule and budget.\n",
      "5.3.2. Purpose, Content and Audience for Test Reports : i was not able to generate summary for this section\n",
      "5.3.3. Communicating the Status of Testing : best means of communicating test status varies, depending on test management concerns, organizational test strategies, regulatory standards, or, case of self-organizing teams, on team itself. verbal communication with team members and other stakeholders Dashboards Electronic communication channels Online documentation Formal test reports One more option can be used.\n",
      "5.4. Configuration Management : configuration management supports testing 5.5 defect management 5.5 configuration management supports testing 5.5 defect management 5.5 configuration management supports defect management 5.5 defect management 5.5 configuration management supports testing.\n",
      "5.5. Defect Management : defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\n",
      "6.1. Tool Support for Testing : i was not able to generate summary for this section\n",
      "6.2. Benefits and Risks of Test Automation : i was not able to generate summary for this section\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updating keys of resulting dictionary with full names, so it can be passed to gradio\n",
    "\n",
    "for s in section_titles:\n",
    "    found = False\n",
    "    for key in list(sections_dict.keys()):\n",
    "        if re.search(key, s):\n",
    "            sections_dict[s] = sections_dict[key]\n",
    "            sections_dict.pop(key)\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        sections_dict[s] = \"i was not able to generate summary for this section\"\n",
    "\n",
    "[print(key,':',value) for key, value in sections_dict.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sections_dict))\n",
    "print(sections_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: software testing is the process of evaluating software to identify defects. Keywords: Software testing, process, defects, defect detection, and defect identification.\n"
     ]
    }
   ],
   "source": [
    "# summary + keywords = T5 questions\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Sample summary and keywords (replace with your own data)\n",
    "summary = \"Software testing is the process of evaluating software to identify defects.\"\n",
    "keywords = [\"Software testing\", \"process\", \"defects\"]\n",
    "\n",
    "# Prepare input for question generation\n",
    "input_text = f\"Summary: {summary} Keywords: {', '.join(keywords)}\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate questions\n",
    "output = model.generate(inputs[\"input_ids\"], max_length=512, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "\n",
    "# Decode and print the generated questions\n",
    "generated_questions = [tokenizer.decode(question, skip_special_tokens=True) for question in output]\n",
    "for i, question in enumerate(generated_questions, 1):\n",
    "    print(f\"Question {i}: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions generation\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the pre-trained model and tokenizer for question generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PrimeQA/mt5-base-tydi-question-generator\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"PrimeQA/mt5-base-tydi-question-generator\")\n",
    "\n",
    "# Function to generate a question for a given summary\n",
    "def generate_question(summary, max_length=64):\n",
    "    # Tokenize the input text and generate the question\n",
    "    features = tokenizer([summary], return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    output = model.generate(input_ids=features['input_ids'], \n",
    "                            attention_mask=features['attention_mask'],\n",
    "                            max_length=max_length,\n",
    "                            num_return_sequences=1)\n",
    "    \n",
    "    return tokenizer.decode(output[0])\n",
    "\n",
    "# Example usage:\n",
    "summary = \"defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\"\n",
    "question = generate_question(summary)\n",
    "print(\"Generated Question:\", question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment!!!\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the pre-trained BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"  # You can choose a different model size if needed\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate an answer for a given question and context\n",
    "def generate_answer(question, context, max_length=64):\n",
    "    # Prepare the input text by combining the question and context\n",
    "    input_text = f\"question: {question} context: {context}\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate the answer\n",
    "    answer_ids = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True, num_return_sequences=1)\n",
    "\n",
    "    # Decode the generated answer\n",
    "    answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage:\n",
    "#context = \"defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\"\n",
    "#question = \"What is the most common defect management process?\"\n",
    "\n",
    "# Generate the answer\n",
    "generated_answer = generate_answer(question, context)\n",
    "print(\"Generated Answer:\", generated_answer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the pre-trained BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate an answer for a given question and context\n",
    "def generate_answer(question, context, max_length=64):\n",
    "    # Prepare the input text by combining the question and context\n",
    "    input_text = f\"question: {question} context: {context}\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate the answer\n",
    "    answer_ids = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True, num_return_sequences=1)\n",
    "\n",
    "    # Decode the generated answer\n",
    "    answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage:\n",
    "#context = \"defect management process includes a workflow for handling individual anomalies from their discovery to their closure and rules for their classification. process must be followed by all involved stakeholders. a defect report logged during dynamic testing typically includes: Unique identifier Title with a short summary of anomaly being reported.\"\n",
    "context = \"testing provides a cost-effective means of detecting defects.\"\n",
    "question = \"What provides a cost-effective means of detecting defects?\"\n",
    "\n",
    "# Generate the answer\n",
    "generated_answer = generate_answer(question, context)\n",
    "print(\"Generated Answer:\", generated_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords extraction - missing so far, leads to HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out. A lot of hours are required. \n",
    "# Talk to teachers\n",
    "\n",
    "# Load the pre-trained KeyBERT model\n",
    "#model = KeyBERT(\"distilbert-base-nli-mean-tokens\")\n",
    "\n",
    "# Input text (use sections[0][1] as the content of the first section)\n",
    "#section_content = sections[0][1]\n",
    "\n",
    "# Extract keywords\n",
    "#try:\n",
    "#    keywords = model.extract_keywords(section_content, keyphrase_ngram_range=(1, 2), stop_words='english', use_mmr=True, top_n=10, resume_download=True)\n",
    "    \n",
    "    # Print the extracted keywords\n",
    "#    for keyword in keywords:\n",
    "#        print(keyword)\n",
    "#except Exception as e:\n",
    "#    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling based on rules\n",
    "sentences = sent_tokenize(summary) \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Function to generate a fixed number of questions from sentences using trigrams\n",
    "def generate_questions(text, num_questions=20):\n",
    "    questions = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Function to generate a fixed number of questions from sentences using trigrams\n",
    "def generate_questions(text, num_questions=30):\n",
    "    questions = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Define question templates with different prefixes\n",
    "    question_templates = [\"What\", \"What is\", \"What can\", \"What does\"]\n",
    "    \n",
    "    for sentence in text:\n",
    "        # Tokenize each sentence into words\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        # Generate n-grams (trigrams) from the words\n",
    "        n_grams = list(ngrams(words, 3))\n",
    "\n",
    "        # Construct questions using the trigrams and different question templates\n",
    "        for n_gram in n_grams:\n",
    "            if (\n",
    "                n_gram[-1].lower() not in stop_words \n",
    "                and n_gram[-1].lower() != n_gram[-2].lower()\n",
    "                and \"can\" not in n_gram\n",
    "            ):\n",
    "                for template in question_templates:\n",
    "                    question = f\"{template} {n_gram[0]} {n_gram[1]} {n_gram[2]}?\"\n",
    "                    questions.append(question)\n",
    "\n",
    "            # Stop generating questions if we reach the desired number\n",
    "            if len(questions) >= num_questions:\n",
    "                return questions\n",
    "\n",
    "    return questions[:num_questions]  # Return only the specified number of questions\n",
    "\n",
    "# Generate 20 questions from the sentences using trigrams and different prefixes\n",
    "questions = generate_questions(sentences, num_questions=30)\n",
    "\n",
    "# Print the generated questions\n",
    "for i, question in enumerate(questions, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distractors: finding causes of this failure, analyzing these causes, and eliminating them\n"
     ]
    }
   ],
   "source": [
    "#looks like correct answers!!!!!!\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the model for question-answering\n",
    "qa_model = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "qa_generator = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_model)\n",
    "\n",
    "# Define a question\n",
    "question = \"Debugging is concerned with?\"\n",
    "\n",
    "# Define a context or document\n",
    "context = \"testing can trigger failures that are caused by defects software can directly find defects test object. debugging is concerned with finding causes of this failure, analyzing these causes, and eliminating them. when static testing identifies a defect, debugging is concerned with removing it.\"\n",
    "\n",
    "# Use the model to generate distractors\n",
    "distractors = qa_generator(question=question, context=context)\n",
    "\n",
    "# The distractors are in the 'answer' field\n",
    "print(\"Distractors:\", distractors['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9808d340ff6f41dab20401e2c0cf5aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f367bd79c74f4e239b7bab67738b672c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91f5c130cf84a4ebc6ba9d5660c8b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47af0b131ac043fb93f1ce8a1a77489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Elena\\github\\Quiz_Generator_Markov_Chain\\extraction.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Define your training dataset (questions, correct answers, and distractors)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Tokenize and preprocess the dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./distractor_model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39myour_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elena/github/Quiz_Generator_Markov_Chain/extraction.ipynb#Y101sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32m<string>:114\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Elena\\anaconda3\\envs\\qgmc\\Lib\\site-packages\\transformers\\training_args.py:1405\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m==\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m   1400\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1402\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1405\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1406\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1407\u001b[0m     \u001b[39mand\u001b[39;00m (get_xla_device_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1408\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1409\u001b[0m ):\n\u001b[0;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1413\u001b[0m     )\n\u001b[0;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1416\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1423\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Elena\\anaconda3\\envs\\qgmc\\Lib\\site-packages\\transformers\\training_args.py:1852\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m \u001b[39mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1850\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m requires_backends(\u001b[39mself\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1852\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_devices\n",
      "File \u001b[1;32mc:\\Users\\Elena\\anaconda3\\envs\\qgmc\\Lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, attr, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfget(obj)\n\u001b[0;32m     55\u001b[0m     \u001b[39msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\Elena\\anaconda3\\envs\\qgmc\\Lib\\site-packages\\transformers\\training_args.py:1767\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available(min_version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0.20.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     AcceleratorState\u001b[39m.\u001b[39m_reset_state(reset_partial_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1771\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMultipleChoice, BertTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Load a pre-trained BERT model and tokenizer\n",
    "model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define your training dataset (questions, correct answers, and distractors)\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "\n",
    "# Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distractor_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=your_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Load the fine-tuned model\n",
    "fine_tuned_model = BertForMultipleChoice.from_pretrained(\"./distractor_model\")\n",
    "\n",
    "# Generate distractors\n",
    "context = \"What is the capital of France?\"\n",
    "question = [\"Paris\", \"London\", \"Berlin\", \"Madrid\"]\n",
    "input_ids = tokenizer.encode(context, question, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "outputs = fine_tuned_model(input_ids)\n",
    "logits = outputs.logits\n",
    "distractor_probabilities = logits.softmax(dim=1)\n",
    "distractors = [question[i] for i in distractor_probabilities.argsort()[0, :]]\n",
    "\n",
    "print(\"Distractors:\", distractors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "#model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Provide a passage and a question\n",
    "#passage = extracted_text\n",
    "#question = \"Which of the following statements describe a valid test objective?\"\n",
    "\n",
    "#Which of the following statements describe a valid test objective?\n",
    "#What does not work as expected?\n",
    "\n",
    "# Tokenize the passage and question\n",
    "#inputs = tokenizer(question, passage, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Get the answer from the model\n",
    "#start_scores, end_scores = model(**inputs, return_dict = False)\n",
    "#start_idx = torch.argmax(start_scores)\n",
    "#end_idx = torch.argmax(end_scores)\n",
    "\n",
    "# Decode the answer from the tokenized output\n",
    "#answer_tokens = inputs[\"input_ids\"][0][start_idx:end_idx + 1]\n",
    "#answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "#print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "# from io import StringIO\n",
    "\n",
    "# # Load the pre-trained model and tokenizer\n",
    "# model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# # Create a StringIO object with your text\n",
    "# text_io = StringIO()\n",
    "# text_io.write(\"Your text goes here.\")\n",
    "# text_io.seek(0)  # Reset the StringIO object to the beginning\n",
    "\n",
    "# # Read the text from the StringIO object and convert it to a regular string\n",
    "# text = text_io.read()\n",
    "\n",
    "# # Provide a question\n",
    "# question = \"What is the answer to my question?\"\n",
    "\n",
    "# # Tokenize the text and question\n",
    "# inputs = tokenizer(question, text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# # Get the answer from the model\n",
    "# start_scores, end_scores = model(**inputs)\n",
    "# start_idx = torch.argmax(start_scores)\n",
    "# end_idx = torch.argmax(end_scores)\n",
    "\n",
    "# # Decode the answer from the tokenized output\n",
    "# answer_tokens = inputs[\"input_ids\"][0][start_idx:end_idx + 1]\n",
    "# answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "# print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Question Generation using Seq2Seq (T5)\n",
    "\n",
    "# Load the pre-trained Seq2Seq model for question generation\n",
    "# question_generation_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "# question_generation_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "# \n",
    "#ISTQB document (replace with your actual content)\n",
    "# istqb_document = \"\"\"\n",
    "# 1.1. What is Testing? \n",
    "# \n",
    "# Software systems are an integral part of our daily life. Most people have had experience with software \n",
    "# that did not work as expected. Software that does not work correctly can lead to many problems, \n",
    "# including loss of money, time or business reputation, and, in extreme cases, even injury or death. \n",
    "# Software testing assesses software quality and helps reducing the risk of software failure in operation. \n",
    "# \n",
    "# Software testing is a set of activities to discover defects and evaluate the quality of software artifacts. \n",
    "# These artifacts, when being tested, are known as test objects. A common misconception about testing is \n",
    "# that it only consists of executing tests (i.e., running the software and checking the test results). However, \n",
    "# software testing also includes other activities and must be aligned with the software development lifecycle \n",
    "# (see chapter 2). \n",
    "# \n",
    "# Another common misconception about testing is that testing focuses entirely on verifying the test object. \n",
    "# Whilst testing involves verification, i.e., checking whether the system meets specified requirements, it also \n",
    "# involves validation, which means checking whether the system meets users’ and other stakeholders’ \n",
    "# needs in its operational environment. \n",
    "# \"\"\"\n",
    "# \n",
    "#Generate questions from the ISTQB document\n",
    "# def generate_questions(document, max_length=64, num_questions=1):\n",
    "    # inputs = question_generation_tokenizer.encode(\"generate questions: \" + document, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    # questions = question_generation_model.generate(inputs, max_length=max_length, num_return_sequences=num_questions)\n",
    "    # return [question_generation_tokenizer.decode(question, skip_special_tokens=True) for question in questions]\n",
    "# \n",
    "# generated_questions = generate_questions(istqb_document)\n",
    "# \n",
    "#Print generated questions\n",
    "# for question in generated_questions:\n",
    "    # print(\"Question:\", question)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is template for Quize layout, needs to be re-worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51210"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define free port in case default ports are not available\n",
    "\n",
    "sock = socket.socket()\n",
    "sock.bind(('', 0))\n",
    "sock.getsockname()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:51210\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:51210/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_titles = list(sections_dict.keys())\n",
    "section_values = list(sections_dict.values())\n",
    "\n",
    "def add_summary(inp):\n",
    "    return sections_dict.get(inp)\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as quiz:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Welcome to Quiz Generator v 0.1 😎\n",
    "    Follow me: 1. Select toggle 2. Generate / Select topic from the dropdown list to proceed\n",
    "    \"\"\")\n",
    "    group = gr.Radio([(\"Whole Document\", \"whole document\"), (\"Section\", \"section\")], label=\"Generate per: \", interactive = True, value = \"section\")\n",
    "    inp = gr.Dropdown(section_titles, label=\"Sections List:\")\n",
    "    out = gr.Textbox(label=\"Section's Summary:\")\n",
    "    gr.ClearButton(inp)\n",
    "    gr.Button(label = \"Generate\")\n",
    "    inp.change(add_summary, inp, out)\n",
    "\n",
    "\n",
    "quiz.launch(share=False, server_port = 51210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7936\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7936/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gra\n",
    "def user_greeting(name):\n",
    "    return \"Hi! \" + name + \" Welcome to your first Gradio application!😎\"\n",
    "    \n",
    "#define gradio interface and other parameters\n",
    "app =  gra.Interface(fn = user_greeting, inputs=\"text\", outputs=\"text\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizer example\n",
    "import gradio as gr\n",
    "\n",
    "def step_1(input):\n",
    "    # Step 1 logic\n",
    "    return input * 2\n",
    "\n",
    "def step_2(input):\n",
    "    # Step 2 logic\n",
    "    return input + 5\n",
    "\n",
    "# Create a block to group the functions\n",
    "block = gr.Block(name=\"Main Block\")\n",
    "block.add_function(step_1, inputs=gr.inputs.Number(), outputs=gr.outputs.Number(), name=\"Step 1\")\n",
    "block.add_function(step_2, inputs=gr.inputs.Number(), outputs=gr.outputs.Number(), name=\"Step 2\")\n",
    "\n",
    "iface = gr.Interface(blocks=[block], theme=gr.themes.Soft())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON converter from CSVlogger() to JSON, this is when the previous step w questions selection is finished via Flag button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to both files\n",
    "csv_file = 'flagged/log.csv'\n",
    "json_file = 'flagged/questions_answers.json'\n",
    "\n",
    "# empty list to store the JSON data\n",
    "json_data = []\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file, 'r') as csvfile:\n",
    "    # Create a CSV reader object\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    \n",
    "    # Iterate through each row in the CSV file\n",
    "    for row in csvreader:\n",
    "        # Append each row as a dictionary to the JSON data list\n",
    "        json_data.append(row)\n",
    "\n",
    "# Open the JSON file for writing and save the JSON data\n",
    "with open(json_file, 'w') as jsonfile:\n",
    "    json.dump(json_data, jsonfile, indent=4)\n",
    "\n",
    "print(f\"CSV data has been converted to JSON successfully and saved as {json_file}. The file contains final result of Quiz generator. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft metrics\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Reference questions (human-generated)\n",
    "reference_questions = [\n",
    "    \"What is the test objective?\",\n",
    "    \"How do objectives vary?\",\n",
    "    \"What does the context include?\",\n",
    "    # Add more reference questions here\n",
    "]\n",
    "\n",
    "# Automatically generated questions\n",
    "generated_questions = [\n",
    "    \"What is test objectives?\",\n",
    "    \"What is objectives vary?\",\n",
    "    \"How do objectives depend?\",\n",
    "    # Add more generated questions here\n",
    "]\n",
    "\n",
    "# Initialize the NLTK BLEU scorer\n",
    "bleu_scorer = nltk.translate.bleu_score.SmoothingFunction()\n",
    "\n",
    "# Calculate BLEU score (a measure of similarity)\n",
    "bleu_scores = [nltk.translate.bleu_score.sentence_bleu([r.split()], g.split(), smoothing_function=bleu_scorer.method1) for r, g in zip(reference_questions, generated_questions)]\n",
    "\n",
    "# Calculate accuracy rate (percentage of questions that match reference questions)\n",
    "accuracy_rate = sum(score == 1.0 for score in bleu_scores) / len(bleu_scores) * 100\n",
    "\n",
    "print(\"Accuracy Rate: {:.2f}%\".format(accuracy_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from selenium import webdriver\n",
    "\n",
    "#driver=webdriver.Chrome()\n",
    "\n",
    "#driver.get(\"https://www.facebook.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show selenium\n",
    "#!pip install selenium==4.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract api key\n",
    "\n",
    "#from pyChatGPT import ChatGPT\n",
    "#from selenium.webdriver.common.by import By\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.common.action_chains import ActionChains\n",
    "#from selenium.webdriver.support.ui import WebDriverWait##\n",
    "\n",
    "#session_token = \"eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..RSoIbYuWt0dZzv_n.yzUd3McMevS948NpJcruJnsILZCqj30VJnxYzcJRnQ38WO9xCyF1LazX-6kARlOnQccDdoakpHjCQ_1NsMO-8MMLm1RKVFdWG3QmH5CCfFAFwZlGiVo-Fj04fVnxFZCvw3j4ouaqA2XwELxW0m9Q_fhCqy8ZLaiF4YpJCmjubt4A9HAJZ0pbrNknQq-OL62DJXJuOL92t_pE-jZpgMIZA3jTZHdvZUzZqfcqM26KKikwJg_WD5wAmLAqz_whTt2p6mNei2Yt6reJQ_uP_5Cwr6Ae9uEF3rX-h0ylmz_di8Ntexgk5nlN2dU4gHEWoNUo0Nf8tqXQMHfoQn6LS3AnFIcDEAAA5s7QTmJZ4hkyCAUk1TOXRG3afrEJD1snnXvrJkv7skXMQfDYhneBE8lUnTQpTJzRxW3KUfXbx89vRXCcboP-LvhTZ_q3adKGiQT5ZhJ6Gb5pCrxFVS34Y7996VfseEbf7duaSW58UNp8mG95YyQtQM1JwaegR9TdE37L3-oNVpoJtS2CzbH6UyS4Ddk6z6IDT-3-5EMLOzO2Bz16CV87DsB---SCsnOll62LXaRHYrdc7Y43u7JMCWgQtLeO0Zm-8H25HkfYhm5YvqBW7pUTeOo43cWZPFDTIcDulunZh68S065c3GzvokIVoAkMieZBzwZQ-KAFjisxntaO69cYVJ_OVjX7aJvXHvsCZcX0jcHwlkooIqn_dbaXgl7718We_QGgLVz6hsDvUlsT3FWfKOP77PSWY20Vvd3Vn3LMzBkxIhLIENpPLHx6kHa_BIBlLdUDJaZKTGCLKvm7GGzgv7kAaQe4bIC-uXGjZDifyP__Wj5M3xxkwY7rAF-voYEvGGoArczz5sQuX2qWBLyQ7FpvgC2lZwarkz9ZWoLBWMgv2jf7Ypm7cBuXnLhzK1TV9tGMinrkWXqjNA9cFLqU3oQ-212hVorUOBj2gG8MO5Z6vIi1GGtrUGN4zvKyDikL1WrBLFZPOPnp2pNX63i2F-6PjqMI9u1X1ZKMqN-viz8JOuFmW6KMayCUWGrKtKXn0_wk8SkB8bzOmZ4w6WbZavlsS23v8NOJkwm2sZOoovKEsHNOQEbnZGGckGZwXNKHnkK4nLJrW-00MfBs3Lq597UbDpGKGqPHh8kOCjGnaACg27CCWckmglgnNwsU6NNv360jIKgFAuT5mJFFr1h8fUFWB0T7V3QbdXOGV9J4g0NP2cIGE-tXOiQquI84kpxjjOVOE_jPAVNEVF0hrBC6Eg4xMYas0mVQ2K-fmZrRtmNKi1UMq2iQALbrPm0UA0LToAqURFhAdUdyYoXj4hGVbvmKBGN8P-0fjEi4lYKBnPsBiWkejTnogTJc_5T2RePoHkopy6_9q3lCD2JcNHkkUlJbCYfmAC7NJNsM-3N-SJ0Glb7KmYx8sY3MqRJHvLPLeo7I5QxAgKeKurgRr3lxxNJbcliL28A5hauqEjUMJnWf6BqhpplcQXLQYlsLn4u9DLuMXXdhbNUp-CvGM0SrydLpy1Y819YaZI7ds88bNB5Hq4e35AqRBo_uDuU2MY5infiyv4-2DvoWcJVl6Dcmag_KwXaGvZewm7lPbG8dxDNPfWmxMBsqDRk62rbzLe3o-EphkTkyEfTreWOMrQSTkrEwdGMzG8sXiV8hHcfbAT_qL4vzNIrs0gxsKqt0O0ecGUG1wbW6PXhArlA0Z_ot-NK7g7aP3ntgdsdaIrqw6FCnKzQnXT35oVD0InGO4EbZnIcg4YyTepjWs1LrUjtTVagWPagr3c-kICpJfjw4jERhdsvQFS1V_QFG_SjT00XW52FvU5r5IeMLjz0r7Khphq5B8XveUAvl65X36mvS-npVHGdfrCBsCIxSXpKVT8o_acGzM9vFpVtdALy32dQap92Lqv-YtQfyMCkyfYXaH4nlEYpMfxNLzD_M98nD35PTr3ovA85JtYMP7fWzV7QiQzx5sqgtsXlbBQeMTA0httZZj8qZ7VtWKGv0BbWkPTQRlh-9JbPYJS0KB791Djdw-nfdRS1sSi7972WykK91W6iCrRff_BCWXzn83-YCk1_F4rn420cDLVlB3hDvIO-SiQmCuhH9xCnX9a0PKGPT82YvCYVuO3Ets0mYHyLd4GLpqvF0KHjqGnIOAzuzU7QfECz6JNCkm1yLa8QVY978gyi68pxJAVVVAVs546FwP2pLjv3RQkt5cfzGpkP4wMt-tXVJR7SCy-Sntqfpn5L4heisOjo6EHkpgP4OTyv-kUPa5HOxkIAVrmG7g2Qwvn-SjfkEG_jZHqFkl4unsECiSKN1fZMaTTIC9qOJ8YFGPsBijhR-toUd5EmtYQJ_rW8aosszMkQmPy1MRKv0Iwab6QYm1ncWyqLzfJMTFtYRRDnyclfqr1oEwS-TbBFRJZADN8I677a7CNiq_JIphlx5w8kB7ADtk--zAHmCVlycAza6EgArS4WvgRJ18QYNjN1-e-3v1ISrxSNjXRK8PAIGqInHGJ7EpkmXDmS5I4HlbDakdtPeAiLTLuaXvctbbSWg5vSgLLIBVwskpcLBhCpotHuhou_ZLTU6q40bfee8u0Gt99mTswb5BkS9DCJlpGNAr99GVSYpvhyPSbQfnScN4EnBK-aoySeoaqnTVdLCqTlhgJqLKlVyNf6-nASXvBiEQ0pjcdk3AxQ_j_7aCGj4Eo0hhSndlhZoXaU22y_DV6CY8CxDqJrbwU2NZDKvJZjZmVza6RH4FAVHgnlwsgKCb-I7Ccpw93EhrOmgpObGD3fEIhr0TKTxVeqxkjWK9wz672kndN__FQEnOA9Q664rCQcro349u0yOs50XtNZZ6nnuV3WfQZ1pkPxlmMyfgp0T.FCUbJELvyDNKws3nIQugCg\"\n",
    "##session_token = \"eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..Tp3P5x2i7af5GTfN.y6_A8C625dFSW8oSdmTLRQvvjYS8QmcPFKEDpLl-PHD1KngeOZFs78Jmpcrx_AgAxNcK4aWi_EHRiRGHUcUx4fnpFH0artO90rhECxVFoVJ4iouZ0477aTbDpfC19-y7G9xnCdlmb3CHTbz1l7ifsq3N9HwThAuybG_uYzAkYH74HKtG28REuxEea5EfTSS-1gracdfxuFtGWb1DvXJ_xpczUvbI_7vrHeuD-wWyrnH9a1NU484r1YntPLG9hhwHmbQ8YbdQyDv-Jl7LqHM1GGSFx8Q0ebW1Y3nxYyQnZ13zEYSosudoQQ4pd80WD3a2VXbdDpSWlFIjDt5V9pXISzc85KUha45JLAEr0EPK5eJaaWRdHIgEYrg6vRWbMaGQ4kz7YWDgd_VzOyHYQeU11UMeFuqdlafQWBo-dv2FOb-GbDKy85vtwLYvIoTgRH3e7ixNWVzbnjWtR_bSBpMEBjQHJG0E7KWHFkamPoav1SyUy-SiOVJKBPbRgxnFC25LWfiJGmXgRV1L7wIYorMxJ3lJKjXH7in8cEl64dn2l7FJ5EH9eeZg1nIeIsSO5lSATkG1ueLY8cuQeEJPL6LZzVuVJV7v-K2C5vrgft0yoU9-LEyXry9bU5WUZf1PKOSr8VS37MRZwMlWmbBrLkQaqHSAB2l3HS5T9kO2ZafyGc6d8luoVvIYxeIXlPrI6j6k3PaPPclh9ACi8pIay17TmVfSbBVGgTZp2VbP37Yfri5tG0dYkZEjXDUkd-NDdxVfe1ChQLwLeN6NUHu-IgTOUK3sqPNU9HYptdz1yD3GfpJY5qOKtGt4D-OoECahIeSzxNYlo5JY4rXviSeGeW2PLvq3pkD4MN5jrgzjCZ9getdAua8yEGvT5_A-uzN8w9gFw8kdhgK3BwOhdfU1cY_OUDoDTIZ12MJbkAH9BzcMXU6P9CoNshyQM8dE1-D_WNxySwVcTSwfOuaZ9MQIhLWa8geqvhVqNDjLzYfKjaydyr6wPwDsBLh9dTqQmmp88aD3VJ-Is6aqRjUIUlSOTsA8eNL5vy-cNZufRX4OrXB9p_Az0PfFNvjSptzoMGmH-0YXiyP4yENYtNSTagawc_PlB66IuUlOmCuyXmVXlzRKTEiAbwNkVrfbBB2ezw6g4cQ6ROROEuCXfBCKh5GjQ-IJgxQRjf6OOaczo-G_YYUnZhuZK2NgEPeXfS18QT_dAKdJLB4PySxitP-MKjOGoWOWbm858Uod1NwQQUMmO7JYAzqxrfNxxFkEA60XTxM-QkZnssgsdjFy0uGEXuwBaoYuYX6_WX9k71ixZ47nNfhRVfTPvXb_8GWVuf_QmwKLYg6ZEcGgGyDiIjhdypr2bretXyR5AfYj1Cludvmc5frm2IXGEJTQIHUkx5sW70ycXtOWNqHfE5sXlt9zyM12FywccPoxUZjZM4YdSleaL-smbApxa-AKjxzTWIgPJHpd-nxputQJdRYjAHLCqPVCycNse5q1y5oVJUCkaDgd4maMA0kBRJf3ftQG1UnG_W2Ao_sf-Qqrflzu80xiv30AjTmoHwGih8u4rB-iMS6Arj2Bbcl3EO24svdqsVCCS-smAasHsDP2pVPCw2HWAXmNNv5IDTI4TlNYhabCnm1eG50rmOXWy_2Qhp9sI1trOrxFqyEmkMyK_iypLFIL-DlrpJ8KZc5KPW6s_prVv7rGRcvEvf_AZVfoJ9UWLxg0KtUH3xoFAFhpqpW1NO3CdjzeBbEbs9xKU7zLFeQwbZU3oZCzjJ3HAKc1enlU48D64aRRw2ZaTnlLHw5tJDSpchBUJX5jyAo9WXVhvjLCe3Coj-OfwqsUyPkkCal33h7O8twSIIFe7THN0rPux-Fjxk1s11GfB9QvppgibwV7L7m6ODTelMofI17eeMGxJcBCePZzVfSVIp3SbTsQhkkU-UErI27TdO3j0_r4d4ceBKSF2kGxRFVCqoKQ2O6ifv_vMdiOlDlCFHgiSs933MuAF5OrWavrGp59gWamUfJXMsX_CqeP8B8Fu-gI3nWR-qX5Xyu7gpphdkn60Dsnw_I174OY9p0RbS01kGiRGCA5wzv5OQaJYcvIOzLr9O9Pa_nWK6jIx4u7REN6Z6-B4Q6dK7Pc1nWPuUQNS1rPkxVYHq2gUDE7kLch5JvCLUImRFceTpiw1QeScTi_p3GHQXIzvrjHv0PlZ5c7fs2VTwM9wUcFEX24C-lJhUnKnPeyI3gK15hQSHe0EClUzrdf_159KKY6VgE4ig3lwAQYVU4zD_ZJTrs3clRRVNufg-XEDFEJ_MxCme-tjskTxUUglTDRKwD4Ij8Ok31yQiAOcflsF-CG6AY3HyVObVLqp3jCS9kPRzQ4gJRuhd4Zhh3QpmzVk4Q0iCjom4jfzVEUWAhtl8399LG6b3kNnbBWX_ON_1aj58JlU-QYeGHuZ7olbrKVkphljS9-lUjTMp5DJmG3D_L4yIVP25VDVceM4K1TGW4m_FaGjuKsmhLHgP4IMBRYgvHAeLoHqfwXORBnQ1M0mGAHsFt1i7kTOBVwJx1v8slmuFGdYgIJtRi7qPjOPvqaBmFg7_PT-tLC1R_8D0zZNBCkZAHYq7JQM09HV6qNj7s_zShfxN2crakn6J8VPDashRiYAysOq3V-ZB1Efai3bkWl90ae1WaWZtCH7ZVc3Z7ie3anyMSxYfLzGlaRm_dOgA0_SUws90cYbhWkzHBunGmUMCbf50PwC-InQ6-6Y1LIPEkH591wITeiqgI7SYcx30c12kA06-iRQ7yPZzD-bmWiEXd1_KQgb85vMf3wR3E-haRiVBYHVF_CHc-JM28GuVFmKrDilWt7VyEy5XwpVaZw0p4l0ukVUgkv.V0DZCdRFRZKFkglRGB0WIg\"\n",
    "#api = ChatGPT(session_token)#\n",
    "\n",
    "##textbox_xpath = '//*[@id=\"radix-:rs:\"]/div[2]/div/div[4]/button'\n",
    "##script = 'alert(\"Hello, from JavaScript!\");'\n",
    "##script = f'document.evaluate(\\'{textbox_xpath}\\', document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue.click();'\n",
    "##api.driver.execute_script(script)\n",
    "##button = WebDriverWait(driver, 10).until(\n",
    "##    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"radix-:rs:\"]/div[2]/div/div[4]/button'))\n",
    "##)#\n",
    "\n",
    "## Click the button\n",
    "##button.click()#\n",
    "#\n",
    "\n",
    "## Click the button\n",
    "##button.click()\n",
    "#resp = api.send_message('Write an essay on Generative AI')#\n",
    "\n",
    "## Locate and scroll to the \"Okay, let's go\" button\n",
    "#button = api.driver.find_element(By.XPATH, '//*[@id=\"radix-:rl:\"]/div[2]/div/div[4]/button')\n",
    "##api.driver.execute_script(\"arguments[0].scrollIntoView();\", button)#\n",
    "\n",
    "## Click the button\n",
    "#button.click()#\n",
    "#\n",
    "#\n",
    "\n",
    "#resp = api.send_message(' AI')\n",
    "##button1 = api.driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[1]/div[2]/div/main/div[1]/div[2]/form/div/div[2]/div/button')\n",
    "##button.click()\n",
    "#api.driver.quit()#\n",
    "\n",
    "## Close the browser when done\n",
    "##api.driver.quit()#\n",
    "#\n",
    "\n",
    "##print(resp['message'])\n",
    "##api.refresh_auth()  # refresh the authorization token\n",
    "##api.reset_conversation()  # reset the conversation#\n",
    "\n",
    "##button_xpath = '//*[@id=\"radix-:rs:\"]/div[2]/div/div[4]/button/div'\n",
    "##button_element = driver.find_element(By.XPATH, button_xpath)\n",
    "##button_element.click()#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
