1.1 what is testing 
  software systems are an integral part of our daily life most people have had experience with software 
  that did not work as expected software that does not work correctly can lead to many problems 
  including loss of money time or business reputation and in extreme cases even injury or death 
  software testing assesses software quality and helps reducing the risk of software failure in operation 
  software testing is a set of activities to discover defects and evaluate the quality of software artifacts 
  these artifacts when being tested are known as test objects a common misconception about testing is 
  that it only consists of executing tests i.e. running the software and checking the test results however 
  software testing also includes other activities and must be aligned with the software development lifecycle 
  see chapter 2 
  another common misconception about testing is that testing focuses entirely on verifying the test object 
  whilst testing involves verification i.e. checking whether the system meets specified requirements it also 
  involves validation which means checking whether the system meets users and other stakeholders 
  needs in its operational environment 
  testing may be dynamic or static dynamic testing involves the execution of software while static testing 
  does not static testing includes reviews see chapter 3 and static analysis dynamic testing uses 
  different types of test techniques and test approaches to derive test cases see chapter 4 
  testing is not only a technical activity it also needs to be properly planned managed estimated 
  monitored and controlled see chapter 5 
  testers use tools see chapter 6 but it is important to remember that testing is largely an intellectual 
  activity requiring the testers to have specialized knowledge use analytical skills and apply critical 
  thinking and systems thinking myers 2011 roman 2018 
  the iso iec ieee 29119 1 standard provides further information about software testing concepts 
  1.1.1    test objectives 
  the typical test objectives are 
    evaluating work products such as requirements user stories designs and code  
    triggering failures and finding defects 
    ensuring required coverage of a test object 
    reducing the level of risk of inadequate software quality 
    verifying whether specified requirements have been fulfilled 
    verifying that a test object complies with contractual legal and regulatory requirements 
    providing information to stakeholders to allow them to make informed decisions 
    building confidence in the quality of the test object 
    validating whether the test object is complete and works as expected by the stakeholders 
  objectives of testing can vary depending upon the context which includes the work product being tested 
  the test level risks the software development lifecycle sdlc being followed and factors related to the 
  business context e.g. corporate structure competitive considerations or time to market 
  v4.0 
  page 15 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  1.1.2    testing and debugging 
  testing and debugging are separate activities testing can trigger failures that are caused by defects in 
  the software dynamic testing or can directly find defects in the test object static testing  
  when dynamic testing see chapter 4 triggers a failure debugging is concerned with finding causes of 
  this failure defects analyzing these causes and eliminating them the typical debugging process in this 
  case involves  
    reproduction of a failure 
    diagnosis finding the root cause 
    fixing the cause 
  subsequent confirmation testing checks whether the fixes resolved the problem preferably confirmation 
  testing is done by the same person who performed the initial test subsequent regression testing can also 
  be performed to check whether the fixes are causing failures in other parts of the test object see section 
  2.2.3 for more information on confirmation testing and regression testing  
  when static testing identifies a defect debugging is concerned with removing it there is no need for 
  reproduction or diagnosis since static testing directly finds defects and can not cause failures see 
  chapter 3 
  1.2 why is testing necessary 
  testing as a form of quality control helps in achieving the agreed upon goals within the set scope time 
  quality and budget constraints testing ’s contribution to success should not be restricted to the test team 
  activities any stakeholder can use their testing skills to bring the project closer to success testing 
  components systems and associated documentation helps to identify defects in software  
  1.2.1    testing ’s contributions to success 
  testing provides a cost effective means of detecting defects these defects can then be removed by 
  debugging a non testing activity so testing indirectly contributes to higher quality test objects 
  testing provides a means of directly evaluating the quality of a test object at various stages in the sdlc 
  these measures are used as part of a larger project management activity contributing to decisions to 
  move to the next stage of the sdlc such as the release decision 
  testing provides users with indirect representation on the development project testers ensure that their 
  understanding of users needs are considered throughout the development lifecycle the alternative is to 
  involve a representative set of users as part of the development project which is not usually possible due 
  to the high costs and lack of availability of suitable users 
  testing may also be required to meet contractual or legal requirements or to comply with regulatory 
  standards 
  1.2.2    testing and quality assurance qa 
  while people often use the terms testing and quality assurance qa interchangeably testing and qa 
  are not the same testing is a form of quality control qc  
  v4.0 
  page 16 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  qc is a product oriented corrective approach that focuses on those activities supporting the achievement 
  of appropriate levels of quality testing is a major form of quality control while others include formal 
  methods model checking and proof of correctness simulation and prototyping 
  qa is a process oriented preventive approach that focuses on the implementation and improvement of 
  processes it works on the basis that if a good process is followed correctly then it will generate a good 
  product qa applies to both the development and testing processes and is the responsibility of everyone 
  on a project 
  test results are used by qa and qc in qc they are used to fix defects while in qa they provide 
  feedback on how well the development and test processes are performing 
  1.2.3    errors defects failures and root causes 
  human beings make errors mistakes which produce defects faults bugs which in turn may result in 
  failures humans make errors for various reasons such as time pressure complexity of work products 
  processes infrastructure or interactions or simply because they are tired or lack adequate training  
  defects can be found in documentation such as a requirements specification or a test script in source 
  code or in a supporting artifact such as a build file defects in artifacts produced earlier in the sdlc if 
  undetected often lead to defective artifacts later in the lifecycle if a defect in code is executed the 
  system may fail to do what it should do or do something it should n’t causing a failure some defects will 
  always result in a failure if executed while others will only result in a failure in specific circumstances and 
  some may never result in a failure 
  errors and defects are not the only cause of failures failures can also be caused by environmental 
  conditions such as when radiation or electromagnetic field cause defects in firmware 
  a root cause is a fundamental reason for the occurrence of a problem e.g. a situation that leads to an 
  error root causes are identified through root cause analysis which is typically performed when a failure 
  occurs or a defect is identified it is believed that further similar failures or defects can be prevented or 
  their frequency reduced by addressing the root cause such as by removing it 
  1.3 testing principles 
  a number of testing principles offering general guidelines applicable to all testing have been suggested 
  over the years this syllabus describes seven such principles  
  1 testing shows the presence not the absence of defects testing can show that defects are present 
  in the test object but can not prove that there are no defects buxton 1970 testing reduces the 
  probability of defects remaining undiscovered in the test object but even if no defects are found testing 
  can not prove test object correctness 
  2 exhaustive testing is impossible testing everything is not feasible except in trivial cases manna 
  1978 rather than attempting to test exhaustively test techniques see chapter 4 test case prioritization 
  see section 5.1.5 and risk based testing see section 5.2 should be used to focus test efforts 
  3 early testing saves time and money defects that are removed early in the process will not cause 
  subsequent defects in derived work products the cost of quality will be reduced since fewer failures will 
  occur later in the sdlc boehm 1981 to find defects early both static testing see chapter 3 and 
  dynamic testing see chapter 4 should be started as early as possible 
  4 defects cluster together a small number of system components usually contain most of the defects 
  discovered or are responsible for most of the operational failures enders 1975 this phenomenon is an 
  v4.0 
  page 17 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  illustration of the pareto principle predicted defect clusters and actual defect clusters observed during 
  testing or in operation are an important input for risk based testing see section 5.2 
  5 tests wear out if the same tests are repeated many times they become increasingly ineffective in 
  detecting new defects beizer 1990 to overcome this effect existing tests and test data may need to be 
  modified and new tests may need to be written however in some cases repeating the same tests can 
  have a beneficial outcome e.g. in automated regression testing see section 2.2.3 
  6 testing is context dependent there is no single universally applicable approach to testing testing is 
  done differently in different contexts kaner 2011 
  7 absence of defects fallacy it is a fallacy i.e. a misconception to expect that software verification 
  will ensure the success of a system thoroughly testing all the specified requirements and fixing all the 
  defects found could still produce a system that does not fulfill the users needs and expectations that 
  does not help in achieving the customer ’s business goals and that is inferior compared to other 
  competing systems in addition to verification validation should also be carried out boehm 1981 
  1.4 test activities testware and test roles 
  testing is context dependent but at a high level there are common sets of test activities without which 
  testing is less likely to achieve test objectives these sets of test activities form a test process the test 
  process can be tailored to a given situation based on various factors which test activities are included in 
  this test process how they are implemented and when they occur is normally decided as part of the test 
  planning for the specific situation see section 5.1 
  the following sections describe the general aspects of this test process in terms of test activities and 
  tasks the impact of context testware traceability between the test basis and testware and testing roles 
  the iso iec ieee 29119 2 standard provides further information about test processes 
  1.4.1    test activities and tasks  
  a test process usually consists of the main groups of activities described below although many of these 
  activities may appear to follow a logical sequence they are often implemented iteratively or in parallel 
  these testing activities usually need to be tailored to the system and the project 
  test planning consists of defining the test objectives and then selecting an approach that best achieves 
  the objectives within the constraints imposed by the overall context test planning is further explained in 
  section 5.1 
  test monitoring and control test monitoring involves the ongoing checking of all test activities and the 
  comparison of actual progress against the plan test control involves taking the actions necessary to 
  meet the objectives of testing test monitoring and control are further explained in section 5.3 
  test analysis includes analyzing the test basis to identify testable features and to define and prioritize 
  associated test conditions together with the related risks and risk levels see section 5.2 the test basis 
  and the test objects are also evaluated to identify defects they may contain and to assess their testability 
  test analysis is often supported by the use of test techniques see chapter 4 test analysis answers the 
  question what to test in terms of measurable coverage criteria  
  test design includes elaborating the test conditions into test cases and other testware e.g. test 
  charters this activity often involves the identification of coverage items which serve as a guide to 
  specify test case inputs test techniques see chapter 4 can be used to support this activity test design 
  v4.0 
  page 18 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  also includes defining the test data requirements designing the test environment and identifying any 
  other required infrastructure and tools test design answers the question how to test 
  test implementation includes creating or acquiring the testware necessary for test execution e.g. test 
  data test cases can be organized into test procedures and are often assembled into test suites manual 
  and automated test scripts are created test procedures are prioritized and arranged within a test 
  execution schedule for efficient test execution see section 5.1.5 the test environment is built and 
  verified to be set up correctly 
  test execution includes running the tests in accordance with the test execution schedule test runs 
  test execution may be manual or automated test execution can take many forms including continuous 
  testing or pair testing sessions actual test results are compared with the expected results the test 
  results are logged anomalies are analyzed to identify their likely causes this analysis allows us to report 
  the anomalies based on the failures observed see section 5.5 
  test completion activities usually occur at project milestones e.g. release end of iteration test level 
  completion for any unresolved defects change requests or product backlog items created any testware 
  that may be useful in the future is identified and archived or handed over to the appropriate teams the 
  test environment is shut down to an agreed state the test activities are analyzed to identify lessons 
  learned and improvements for future iterations releases or projects see section 2.1.6 a test completion 
  report is created and communicated to the stakeholders 
  1.4.2    test process in context 
  testing is not performed in isolation test activities are an integral part of the development processes 
  carried out within an organization testing is also funded by stakeholders and its final goal is to help fulfill 
  the stakeholders business needs therefore the way the testing is carried out will depend on a number 
  of contextual factors including 
    stakeholders needs expectations requirements willingness to cooperate etc 
    team members skills knowledge level of experience availability training needs etc 
    business domain criticality of the test object identified risks market needs specific legal 
  regulations etc 
    technical factors type of software product architecture technology used etc 
    project constraints scope time budget resources etc 
    organizational factors organizational structure existing policies practices used etc 
    software development lifecycle engineering practices development methods etc 
    tools availability usability compliance etc 
  these factors will have an impact on many test related issues including test strategy test techniques 
  used degree of test automation required level of coverage level of detail of test documentation 
  reporting etc 
  1.4.3    testware  
  testware is created as output work products from the test activities described in section 1.4.1 there is a 
  significant variation in how different organizations produce shape name organize and manage their 
  v4.0 
  page 19 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  work products proper configuration management see section 5.4 ensures consistency and integrity of 
  work products the following list of work products is not exhaustive 
    test planning work products include test plan test schedule risk register and entry and exit 
  criteria see section 5.1 risk register is a list of risks together with risk likelihood risk impact and 
  information about risk mitigation see section 5.2 test schedule risk register and entry and exit 
  criteria are often a part of the test plan 
    test monitoring and control work products include test progress reports see section 5.3.2 
  documentation of control directives see section 5.3 and risk information see section 5.2  
    test analysis work products include prioritized test conditions e.g. acceptance criteria see 
  section 4.5.2 and defect reports regarding defects in the test basis if not fixed directly 
    test design work products include prioritized test cases test charters coverage items test 
  data requirements and test environment requirements 
    test implementation work products include test procedures automated test scripts test 
  suites test data test execution schedule and test environment elements examples of test 
  environment elements include stubs drivers simulators and service virtualizations 
    test execution work products include test logs and defect reports see section 5.5 
    test completion work products include test completion report see section 5.3.2 action items 
  for improvement of subsequent projects or iterations documented lessons learned and change 
  requests e.g. as product backlog items 
  1.4.4    traceability between the test basis and testware 
  in order to implement effective test monitoring and control it is important to establish and maintain 
  traceability throughout the test process between the test basis elements testware associated with these 
  elements e.g. test conditions risks test cases test results and detected defects 
  accurate traceability supports coverage evaluation so it is very useful if measurable coverage criteria are 
  defined in the test basis the coverage criteria can function as key performance indicators to drive the 
  activities that show to what extent the test objectives have been achieved see section 1.1.1 for 
  example 
    traceability of test cases to requirements can verify that the requirements are covered by test 
  cases 
    traceability of test results to risks can be used to evaluate the level of residual risk in a test 
  object  
  in addition to evaluating coverage good traceability makes it possible to determine the impact of 
  changes facilitates test audits and helps meet it governance criteria good traceability also makes test 
  progress and completion reports more easily understandable by including the status of test basis 
  elements this can also assist in communicating the technical aspects of testing to stakeholders in an 
  understandable manner traceability provides information to assess product quality process capability 
  and project progress against business goals  
  v4.0 
  page 20 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  1.4.5    roles in testing 
  in this syllabus two principal roles in testing are covered a test management role and a testing role the 
  activities and tasks assigned to these two roles depend on factors such as the project and product 
  context the skills of the people in the roles and the organization 
  the test management role takes overall responsibility for the test process test team and leadership of the 
  test activities the test management role is mainly focused on the activities of test planning test 
  monitoring and control and test completion the way in which the test management role is carried out 
  varies depending on the context for example in agile software development some of the test 
  management tasks may be handled by the agile team tasks that span multiple teams or the entire 
  organization may be performed by test managers outside of the development team 
  the testing role takes overall responsibility for the engineering technical aspect of testing the testing 
  role is mainly focused on the activities of test analysis test design test implementation and test 
  execution 
  different people may take on these roles at different times for example the test management role can 
  be performed by a team leader by a test manager by a development manager etc it is also possible for 
  one person to take on the roles of testing and test management at the same time 
  1.5 essential skills and good practices in testing 
  skill is the ability to do something well that comes from one ’s knowledge practice and aptitude good 
  testers should possess some essential skills to do their job well good testers should be effective team 
  players and should be able to perform testing on different levels of test independence 
  1.5.1    generic skills required for testing 
  while being generic the following skills are particularly relevant for testers 
    testing knowledge to increase effectiveness of testing e.g. by using test techniques 
    thoroughness carefulness curiosity attention to details being methodical to identify defects 
  especially the ones that are difficult to find 
    good communication skills active listening being a team player to interact effectively with all 
  stakeholders to convey information to others to be understood and to report and discuss 
  defects 
    analytical thinking critical thinking creativity to increase effectiveness of testing 
    technical knowledge to increase efficiency of testing e.g. by using appropriate test tools 
    domain knowledge to be able to understand and to communicate with end users business 
  representatives 
  testers are often the bearers of bad news it is a common human trait to    blame the bearer of bad news 
  this    makes    communication    skills    crucial    for    testers    communicating    test    results    may    be    perceived    as 
  criticism of the product and of its author confirmation bias can make it difficult to accept information that 
  disagrees    with    currently    held    beliefs    some    people    may    perceive    testing    as    a    destructive    activity    even 
  though it contributes greatly to project success and product quality to try to improve this view information 
  about defects and failures should be communicated in a constructive way 
  v4.0 
  page 21 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  1.5.2    whole team approach 
  one of the important skills for a tester is the ability to work effectively in a team context and to contribute 
  positively to the team goals the whole team approach a practice coming from extreme programming 
  see section 2.1 builds upon this skill  
  in the whole team approach any team member with the necessary knowledge and skills can perform any 
  task and everyone is responsible for quality the team members share the same workspace physical or 
  virtual as co location facilitates communication and interaction the whole team approach improves 
  team dynamics enhances communication and collaboration within the team and creates synergy by 
  allowing the various skill sets within the team to be leveraged for the benefit of the project 
  testers work closely with other team members to ensure that the desired quality levels are achieved this 
  includes collaborating with business representatives to help them create suitable acceptance tests and 
  working with developers to agree on the test strategy and decide on test automation approaches testers 
  can thus transfer testing knowledge to other team members and influence the development of the 
  product 
  depending on the context the whole team approach may not always be appropriate for instance in 
  some situations such as safety critical a high level of test independence may be needed 
  1.5.3 
  independence of testing 
  a certain degree of independence makes the tester more effective at finding defects due to differences 
  between the author ’s and the tester ’s cognitive biases cf salman 1995 independence is not however 
  a replacement for familiarity e.g. developers can efficiently find many defects in their own code 
  work products can be tested by their author no independence by the author 's peers from the same 
  team some independence by testers from outside the author 's team but within the organization high 
  independence or by testers from outside the organization very high independence for most projects it 
  is usually best to carry out testing with multiple levels of independence e.g. developers performing 
  component and component integration testing test team performing system and system integration 
  testing and business representatives performing acceptance testing 
  the main benefit of independence of testing is that independent testers are likely to recognize different 
  kinds of failures and defects compared to developers because of their different backgrounds technical 
  perspectives and biases moreover an independent tester can verify challenge or disprove 
  assumptions made by stakeholders during specification and implementation of the system  
  however there are also some drawbacks independent testers may be isolated from the development 
  team which may lead to a lack of collaboration communication problems or an adversarial relationship 
  with the development team developers may lose a sense of responsibility for quality independent 
  testers may be seen as a bottleneck or be blamed for delays in release 
  v4.0 
  page 22 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  2 testing throughout the software development lifecycle 
  130 minutes 
  keywords 
  acceptance testing black box testing component integration testing component testing confirmation 
  testing functional testing integration testing maintenance testing non functional testing regression 
  testing shift left system integration testing system testing test level test object test type white box 
  testing 
  learning objectives for chapter 2 
  2.1    testing in the context of a software development lifecycle 
  fl-2.1.1 
  k2 explain the impact of the chosen software development lifecycle on testing 
  fl-2.1.2 
  k1 recall good testing practices that apply to all software development lifecycles 
  fl-2.1.3 
  k1 recall the examples of test first approaches to development 
  fl-2.1.4 
  k2 summarize how devops might have an impact on testing  
  fl-2.1.5 
  k2 explain the shift left approach 
  fl-2.1.6 
  k2 explain how retrospectives can be used as a mechanism for process improvement 
  2.2 test levels and test types 
  fl-2.2.1 
  k2 distinguish the different test levels 
  fl-2.2.2 
  k2 distinguish the different test types 
  fl-2.2.3 
  k2 distinguish confirmation testing from regression testing 
  2.3 maintenance testing 
  fl-2.3.1 
  k2 summarize maintenance testing and its triggers 
  v4.0 
  page 23 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  2.1 testing in the context of a software development lifecycle 
  a software development lifecycle sdlc model is an abstract high level representation of the software 
  development process a sdlc model defines how different development phases and types of activities 
  performed within this process relate to each other both logically and chronologically examples of sdlc 
  models include sequential development models e.g. waterfall model v model iterative development 
  models e.g. spiral model prototyping and incremental development models e.g. unified process 
  some activities within software development processes can also be described by more detailed software 
  development methods and agile practices examples include acceptance test driven development 
  atdd behavior driven development bdd domain driven design ddd extreme programming xp 
  feature driven development fdd kanban lean it scrum and test driven development tdd 
  2.1.1 
  impact of the software development lifecycle on testing 
  testing must be adapted to the sdlc to succeed the choice of the sdlc impacts on the 
    scope and timing of test activities e.g. test levels and test types 
    level of detail of test documentation 
    choice of test techniques and test approach 
    extent of test automation 
    role and responsibilities of a tester 
  in sequential development models in the initial phases testers typically participate in requirement 
  reviews test analysis and test design the executable code is usually created in the later phases so 
  typically dynamic testing can not be performed early in the sdlc 
  in some iterative and incremental development models it is assumed that each iteration delivers a 
  working prototype or product increment this implies that in each iteration both static and dynamic testing 
  may be performed at all test levels frequent delivery of increments requires fast feedback and extensive 
  regression testing 
  agile software development assumes that change may occur throughout the project therefore 
  lightweight work product documentation and extensive test automation to make regression testing easier 
  are favored in agile projects also most of the manual testing tends to be done using experience based 
  test techniques see section 4.4 that do not require extensive prior test analysis and design 
  2.1.2    software development lifecycle and good testing practices 
  good testing practices independent of the chosen sdlc model include the following 
    for every software development activity there is a corresponding test activity so that all 
  development activities are subject to quality control 
    different test levels see chapter 2.2.1 have specific and different test objectives which allows 
  for testing to be appropriately comprehensive while avoiding redundancy 
    test analysis and design for a given test level begins during the corresponding development 
  phase of the sdlc so that testing can adhere to the principle of early testing see section 1.3 
  v4.0 
  page 24 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    testers are involved in reviewing work products as soon as drafts of this documentation are 
  available so that this earlier testing and defect detection can support the shift left strategy see 
  section 2.1.5 
  2.1.3    testing as a driver for software development 
  tdd atdd and bdd are similar development approaches where tests are defined as a means of 
  directing development each of these approaches implements the principle of early testing see section 
  1.3 and follows a shift left approach see section 2.1.5 since the tests are defined before the code is 
  written they support an iterative development model these approaches are characterized as follows 
  test driven development tdd 
    directs the coding through test cases instead of extensive software design beck 2003 
    tests are written first then the code is written to satisfy the tests and then the tests and code are 
  refactored 
  acceptance test driven development atdd see section 4.5.3 
    derives tests from acceptance criteria as part of the system design process gärtner 2011 
    tests are written before the part of the application is developed to satisfy the tests  
  behavior driven development bdd 
    expresses the desired behavior of an application with test cases written in a simple form of 
  natural language which is easy to understand by stakeholders usually using the 
  given when then format chelimsky 2010 
    test cases are then automatically translated into executable tests 
  for all the above approaches tests may persist as automated tests to ensure the code quality in future 
  adaptions refactoring 
  2.1.4    devops and testing 
  devops is an organizational approach aiming to create synergy by getting development including 
  testing and operations to work together to achieve a set of common goals devops requires a cultural 
  shift within an organization to bridge the gaps between development including testing and operations 
  while treating their functions with equal value devops promotes team autonomy fast feedback 
  integrated toolchains and technical practices like continuous integration ci and continuous delivery 
  cd this enables the teams to build test and release high quality code faster through a devops 
  delivery pipeline kim 2016 
  from the testing perspective some of the benefits of devops are 
    fast feedback on the code quality and whether changes adversely affect existing code 
    ci promotes a shift left approach in testing see section 2.1.5 by encouraging developers to 
  submit high quality code accompanied by component tests and static analysis 
    promotes automated processes like ci cd that facilitate establishing stable test environments 
 
  increases the view on non functional quality characteristics e.g. performance reliability 
  v4.0 
  page 25 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    automation through a delivery pipeline reduces the need for repetitive manual testing 
    the risk in regression is minimized due to the scale and range of automated regression tests 
  devops is not without its risks and challenges which include 
    the devops delivery pipeline must be defined and established  
    ci cd tools must be introduced and maintained 
    test automation requires additional resources and may be difficult to establish and maintain 
  although devops comes with a high level of automated testing manual testing especially from the 
  user 's perspective will still be needed 
  2.1.5    shift left approach 
  the principle of early testing see section 1.3 is sometimes referred to as shift left because it is an 
  approach where testing is performed earlier in the sdlc shift left normally suggests that testing should 
  be done earlier e.g. not waiting for code to be implemented or for components to be integrated but it 
  does not mean that testing later in the sdlc should be neglected 
  there are some good practices that illustrate how to achieve a shift left in testing which include 
    reviewing the specification from the perspective of testing these review activities on 
  specifications often find potential defects such as ambiguities incompleteness and 
  inconsistencies  
    writing test cases before the code is written and have the code run in a test harness during code 
  implementation 
    using ci and even better cd as it comes with fast feedback and automated component tests to 
  accompany source code when it is submitted to the code repository 
    completing static analysis of source code prior to dynamic testing or as part of an automated 
  process 
    performing non functional testing starting at the component test level where possible this is a 
  form of shift left as these non functional test types tend to be performed later in the sdlc when a 
  complete system and a representative test environment are available 
  a shift left approach might result in extra training effort and/or costs earlier in the process but is expected 
  to save efforts and/or costs later in the process 
  for the shift left approach it is important that stakeholders are convinced and bought into this concept 
  2.1.6    retrospectives and process improvement 
  retrospectives also known as post project meetings and project retrospectives are often held at the 
  end of a project or an iteration at a release milestone or can be held when needed the timing and 
  organization of the retrospectives depend on the particular sdlc model being followed in these 
  meetings the participants not only testers but also e.g. developers architects product owner business 
  analysts discuss 
    what was successful and should be retained 
  v4.0 
  page 26 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    what was not successful and could be improved 
    how to incorporate the improvements and retain the successes in the future 
  the results should be recorded and are normally part of the test completion report see section 5.3.2 
  retrospectives are critical for the successful implementation of continuous improvement and it is 
  important that any recommended improvements are followed up 
  typical benefits for testing include 
 
  increased test effectiveness efficiency e.g. by implementing suggestions for process 
  improvement 
 
  increased quality of testware e.g. by jointly reviewing the test processes 
    team bonding and learning e.g. as a result of the opportunity to raise issues and propose 
  improvement points 
 
  improved quality of the test basis e.g. as deficiencies in the extent and quality of the 
  requirements could be addressed and solved 
    better cooperation between development and testing e.g. as collaboration is reviewed and 
  optimized regularly 
  2.2 test levels and test types 
  test levels are groups of test activities that are organized and managed together each test level is an 
  instance of the test process performed in relation to software at a given stage of development from 
  individual components to complete systems or where applicable systems of systems  
  test levels are related to other activities within the sdlc in sequential sdlc models the test levels are 
  often defined such that the exit criteria of one level are part of the entry criteria for the next level in some 
  iterative models this may not apply development activities may span through multiple test levels test 
  levels may overlap in time 
  test types are groups of test activities related to specific quality characteristics and most of those test 
  activities can be performed at every test level 
  2.2.1    test levels 
  in this syllabus the following five test levels are described 
    component testing also known as unit testing focuses on testing components in isolation it 
  often requires specific support such as test harnesses or unit test frameworks component 
  testing is normally performed by developers in their development environments 
    component integration testing also known as unit integration testing focuses on testing the 
  interfaces and interactions between components component integration testing is heavily 
  dependent on the integration strategy approaches like bottom up top down or big bang 
    system testing focuses on the overall behavior and capabilities of an entire system or product 
  often including functional testing of end to end tasks and the non functional testing of quality 
  characteristics for some non functional quality characteristics it is preferable to test them on a 
  complete system in a representative test environment e.g. usability using simulations of sub- 
  v4.0 
  page 27 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  systems is also possible system testing may be performed by an independent test team and is 
  related to specifications for the system 
    system integration testing focuses on testing the interfaces of the system under test and other 
  systems and external services system integration testing requires suitable test environments 
  preferably similar to the operational environment 
    acceptance testing focuses on validation and on demonstrating readiness for deployment 
  which means that the system fulfills the user ’s business needs ideally acceptance testing should 
  be performed by the intended users the main forms of acceptance testing are user acceptance 
  testing uat operational acceptance testing contractual and regulatory acceptance testing 
  alpha testing and beta testing 
  test levels are distinguished by the following non exhaustive list of attributes to avoid overlapping of test 
  activities 
    test object  
    test objectives 
    test basis 
    defects and failures 
    approach and responsibilities 
  2.2.2    test types 
  a lot of test types exist and can be applied in projects in this syllabus the following four test types are 
  addressed 
  functional testing evaluates the functions that a component or system should perform the functions 
  are what the test object should do the main objective of functional testing is checking the functional 
  completeness functional correctness and functional appropriateness 
  non functional testing evaluates attributes other than functional characteristics of a component or 
  system non functional testing is the testing of how well the system behaves the main objective of non- 
  functional testing is checking the non functional software quality characteristics the iso iec 25010 
  standard provides the following classification of the non functional software quality characteristics 
    performance efficiency 
    compatibility 
    usability 
    reliability 
    security 
    maintainability 
    portability 
  it is sometimes appropriate for non functional testing to start early in the life cycle e.g. as part of reviews 
  and component testing or system testing many non functional tests are derived from functional tests as 
  v4.0 
  page 28 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  they use the same functional tests but check that while performing the function a non functional 
  constraint is satisfied e.g. checking that a function performs within a specified time or a function can be 
  ported to a new platform the late discovery of non functional defects can pose a serious threat to the 
  success of a project non functional testing sometimes needs a very specific test environment such as a 
  usability lab for usability testing 
  black box testing see section 4.2 is specification based and derives tests from documentation external 
  to the test object the main objective of black box testing is checking the system 's behavior against its 
  specifications 
  white box testing see section 4.3 is structure based and derives tests from the system 's 
  implementation or internal structure e.g. code architecture work flows and data flows the main 
  objective of white box testing is to cover the underlying structure by the tests to the acceptable level 
  all the four above mentioned test types can be applied to all test levels although the focus will be 
  different at each level different test techniques can be used to derive test conditions and test cases for 
  all the mentioned test types  
  2.2.3    confirmation testing and regression testing 
  changes are typically made to a component or system to either enhance it by adding a new feature or to 
  fix it by removing a defect testing should then also include confirmation testing and regression testing 
  confirmation testing confirms that an original defect has been successfully fixed depending on the risk 
  one can test the fixed version of the software in several ways including 
    executing all test cases that previously have failed due to the defect or also by 
    adding new tests to cover any changes that were needed to fix the defect 
  however when time or money is short when fixing defects confirmation testing might be restricted to 
  simply exercising the steps that should reproduce the failure caused by the defect and checking that the 
  failure does not occur 
  regression testing confirms that no adverse consequences have been caused by a change including a 
  fix that has already been confirmation tested these adverse consequences could affect the same 
  component where the change was made other components in the same system or even other 
  connected systems regression testing may not be restricted to the test object itself but can also be 
  related to the environment it is advisable first to perform an impact analysis to optimize the extent of the 
  regression testing impact analysis shows which parts of the software could be affected 
  regression test suites are run many times and generally the number of regression test cases will 
  increase with each iteration or release so regression testing is a strong candidate for automation 
  automation of these tests should start early in the project where ci is used such as in devops see 
  section 2.1.4 it is good practice to also include automated regression tests depending on the situation 
  this may include regression tests on different levels 
  confirmation testing and/or regression testing for the test object are needed on all test levels if defects 
  are fixed and/or changes are made on these test levels 
  v4.0 
  page 29 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  2.3 maintenance testing 
  there are different categories of maintenance it can be corrective adaptive to changes in the 
  environment or improve performance or maintainability see iso iec 14764 for details so maintenance 
  can involve planned releases deployments and unplanned releases deployments hot fixes impact 
  analysis may be done before a change is made to help decide if the change should be made based on 
  the potential consequences in other areas of the system testing the changes to a system in production 
  includes both evaluating the success of the implementation of the change and the checking for possible 
  regressions in parts of the system that remain unchanged which is usually most of the system  
  the scope of maintenance testing typically depends on 
    the degree of risk of the change 
    the size of the existing system 
    the size of the change 
  the triggers for maintenance and maintenance testing can be classified as follows 
    modifications such as planned enhancements i.e. release based corrective changes or hot 
  fixes 
    upgrades or migrations of the operational environment such as from one platform to another 
  which can require tests associated with the new environment as well as of the changed software 
  or tests of data conversion when data from another application is migrated into the system being 
  maintained 
    retirement such as when an application reaches the end of its life when a system is retired this 
  can require testing of data archiving if long data retention periods are required testing of restore 
  and retrieval procedures after archiving may also be needed in the event that certain data is 
  required during the archiving period 
  v4.0 
  page 30 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  3 static testing 80 minutes 
  keywords 
  anomaly dynamic testing formal review informal review inspection review static analysis static testing 
  technical review walkthrough 
  learning objectives for chapter 3 
  3.1    static testing basics 
  fl-3.1.1 
  k1 recognize types of products that can be examined by the different static test techniques  
  fl-3.1.2 
  k2 explain the value of static testing  
  fl-3.1.3 
  k2 compare and contrast static and dynamic testing 
  3.2    feedback and review process  
  fl-3.2.1 
  k1 identify the benefits of early and frequent stakeholder feedback 
  fl-3.2.2 
  k2 summarize the activities of the review process  
  fl-3.2.3 
  k1 recall which responsibilities are assigned to the principal roles when performing reviews 
  fl-3.2.4 
  k2 compare and contrast the different review types 
  fl-3.2.5 
  k1 recall the factors that contribute to a successful review 
  v4.0 
  page 31 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  3.1 static testing basics 
  in contrast to dynamic testing in static testing the software under test does not need to be executed 
  code process specification system architecture specification or other work products are evaluated 
  through manual examination e.g. reviews or with the help of a tool e.g. static analysis test objectives 
  include improving quality detecting defects and assessing characteristics like readability completeness 
  correctness testability and consistency static testing can be applied for both verification and validation 
  testers business representatives and developers work together during example mappings collaborative 
  user story writing and backlog refinement sessions to ensure that user stories and related work products 
  meet defined criteria e.g. the definition of ready see section 5.1.3 review techniques can be applied 
  to ensure user stories are complete and understandable and include testable acceptance criteria by 
  asking the right questions testers explore challenge and help improve the proposed user stories  
  static analysis can identify problems prior to dynamic testing while often requiring less effort since no test 
  cases are required and tools see chapter 6 are typically used static analysis is often incorporated into 
  ci frameworks see section 2.1.4 while largely used to detect specific code defects static analysis is 
  also used to evaluate maintainability and security spelling checkers and readability tools are other 
  examples of static analysis tools 
  3.1.1    work products examinable by static testing 
  almost any work product can be examined using static testing examples include requirement 
  specification documents source code test plans test cases product backlog items test charters project 
  documentation contracts and models 
  any work product that can be read and understood can be the subject of a review however for static 
  analysis work products need a structure against which they can be checked e.g. models code or text 
  with a formal syntax  
  work products that are not appropriate for static testing include those that are difficult to interpret by 
  human beings and that should not be analyzed by tools e.g. 3rd party executable code due to legal 
  reasons 
  3.1.2    value of static testing 
  static testing can detect defects in the earliest phases of the sdlc fulfilling the principle of early testing 
  see section 1.3 it can also identify defects which can not be detected by dynamic testing e.g. 
  unreachable code design patterns not implemented as desired defects in non executable work 
  products  
  static testing provides the ability to evaluate the quality of and to build confidence in work products by 
  verifying the documented requirements the stakeholders can also make sure that these requirements 
  describe their actual needs since static testing can be performed early in the sdlc a shared 
  understanding can be created among the involved stakeholders communication will also be improved 
  between the involved stakeholders for this reason it is recommended to involve a wide variety of 
  stakeholders in static testing  
  even though reviews can be costly to implement the overall project costs are usually much lower than 
  when no reviews are performed because less time and effort needs to be spent on fixing defects later in 
  the project  
  v4.0 
  page 32 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  code defects can be detected using static analysis more efficiently than in dynamic testing usually 
  resulting in both fewer code defects and a lower overall development effort 
  3.1.3    differences between static testing and dynamic testing 
  static testing and dynamic testing practices complement each other they have similar objectives such 
  as supporting the detection of defects in work products see section 1.1.1 but there are also some 
  differences such as 
    static and dynamic testing with analysis of failures can both lead to the detection of defects 
  however there are some defect types that can only be found by either static or dynamic testing  
    static testing finds defects directly while dynamic testing causes failures from which the 
  associated defects are determined through subsequent analysis 
    static testing may more easily detect defects that lay on paths through the code that are rarely 
  executed or hard to reach using dynamic testing 
    static testing can be applied to non executable work products while dynamic testing can only be 
  applied to executable work products 
    static testing can be used to measure quality characteristics that are not dependent on executing 
  code e.g. maintainability while dynamic testing can be used to measure quality characteristics  
  that are dependent on executing code e.g. performance efficiency 
  typical defects that are easier and/or cheaper to find through static testing include 
    defects in requirements e.g. inconsistencies ambiguities contradictions omissions 
  inaccuracies duplications 
    design defects e.g. inefficient database structures poor modularization 
    certain types of coding defects e.g. variables with undefined values undeclared variables 
  unreachable or duplicated code excessive code complexity 
    deviations from standards e.g. lack of adherence to naming conventions in coding standards 
 
  incorrect interface specifications e.g. mismatched number type or order of parameters 
    specific types of security vulnerabilities e.g. buffer overflows 
    gaps or inaccuracies in test basis coverage e.g. missing tests for an acceptance criterion 
  3.2 feedback and review process 
  3.2.1    benefits of early and frequent stakeholder feedback 
  early and frequent feedback allows for the early communication of potential quality problems if there is 
  little stakeholder involvement during the sdlc the product being developed might not meet the 
  stakeholder ’s original or current vision a failure to deliver what the stakeholder wants can result in costly 
  rework missed deadlines blame games and might even lead to complete project failure  
  v4.0 
  page 33 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  frequent stakeholder feedback throughout the sdlc can prevent misunderstandings about requirements 
  and ensure that changes to requirements are understood and implemented earlier this helps the 
  development team to improve their understanding of what they are building it allows them to focus on 
  those features that deliver the most value to the stakeholders and that have the most positive impact on 
  identified risks 
  3.2.2    review process activities 
  the iso iec 20246 standard defines a generic review process that provides a structured but flexible 
  framework from which a specific review process may be tailored to a particular situation if the required 
  review is more formal then more of the tasks described for the different activities will be needed  
  the size of many work products makes them too large to be covered by a single review the review 
  process may be invoked a couple of times to complete the review for the entire work product  
  the activities in the review process are 
    planning during the planning phase the scope of the review which comprises the purpose the 
  work product to be reviewed quality characteristics to be evaluated areas to focus on exit 
  criteria supporting information such as standards effort and the timeframes for the review shall 
  be defined 
    review initiation during review initiation the goal is to make sure that everyone and everything 
  involved is prepared to start the review this includes making sure that every participant has 
  access to the work product under review understands their role and responsibilities and receives 
  everything needed to perform the review 
 
  individual review every reviewer performs an individual review to assess the quality of the work 
  product under review and to identify anomalies recommendations and questions by applying 
  one or more review techniques e.g. checklist based reviewing scenario based reviewing the 
  iso iec 20246 standard provides more depth on different review techniques the reviewers log 
  all their identified anomalies recommendations and questions  
    communication and analysis since the anomalies identified during a review are not 
  necessarily defects all these anomalies need to be analyzed and discussed for every anomaly 
  the decision should be made on its status ownership and required actions this is typically done 
  in a review meeting during which the participants also decide what the quality level of reviewed 
  work product is and what follow up actions are required a follow up review may be required to 
  complete actions  
    fixing and reporting for every defect a defect report should be created so that corrective 
  actions can be followed up once the exit criteria are reached the work product can be accepted 
  the review results are reported 
  3.2.3    roles and responsibilities in reviews 
  reviews involve various stakeholders who may take on several roles the principal roles and their 
  responsibilities are 
    manager decides what is to be reviewed and provides resources such as staff and time for the 
  review 
    author creates and fixes the work product under review 
  v4.0 
  page 34 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    moderator also known as the facilitator ensures the effective running of review meetings 
  including mediation time management and a safe review environment in which everyone can 
  speak freely 
    scribe also known as recorder collates anomalies from reviewers and records review 
  information such as decisions and new anomalies found during the review meeting 
    reviewer performs reviews a reviewer may be someone working on the project a subject 
  matter expert or any other stakeholder 
    review leader takes overall responsibility for the review such as deciding who will be involved 
  and organizing when and where the review will take place 
  other more detailed roles are possible as described in the iso iec 20246 standard 
  3.2.4    review types 
  there exist many review types ranging from informal reviews to formal reviews the required level of 
  formality depends on factors such as the sdlc being followed the maturity of the development process 
  the criticality and complexity of the work product being reviewed legal or regulatory requirements and 
  the need for an audit trail the same work product can be reviewed with different review types e.g. first 
  an informal one and later a more formal one 
  selecting the right review type is key to achieving the required review objectives see section 3.2.5 the 
  selection is not only based on the objectives but also on factors such as the project needs available 
  resources work product type and risks business domain and company culture  
  some commonly used review types are 
 
  informal review informal reviews do not follow a defined process and do not require a formal 
  documented output the main objective is detecting anomalies 
    walkthrough a walkthrough which is led by the author can serve many objectives such as 
  evaluating quality and building confidence in the work product educating reviewers gaining 
  consensus generating new ideas motivating and enabling authors to improve and detecting 
  anomalies reviewers might perform an individual review before the walkthrough but this is not 
  required 
    technical review a technical review is performed by technically qualified reviewers and led by 
  a moderator the objectives of a technical review are to gain consensus and make decisions 
  regarding a technical problem but also to detect anomalies evaluate quality and build confidence 
  in the work product generate new ideas and to motivate and enable authors to improve 
 
  inspection as inspections are the most formal type of review they follow the complete generic 
  process see section 3.2.2 the main objective is to find the maximum number of anomalies 
  other objectives are to evaluate quality build confidence in the work product and to motivate and 
  enable authors to improve metrics are collected and used to improve the sdlc including the 
  inspection process in inspections the author can not act as the review leader or scribe 
  3.2.5    success factors for reviews 
  there are several factors that determine the success of reviews which include 
  v4.0 
  page 35 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    defining clear objectives and measurable exit criteria evaluation of participants should never be 
  an objective 
    choosing the appropriate review type to achieve the given objectives and to suit the type of work 
  product the review participants the project needs and context 
    conducting reviews on small chunks so that reviewers do not lose concentration during an 
  individual review and/or the review meeting when held  
    providing feedback from reviews to stakeholders and authors so they can improve the product 
  and their activities see section 3.2.1 
    providing adequate time to participants to prepare for the review 
    support from management for the review process 
    making reviews part of the organization ’s culture to promote learning and process improvement 
    providing adequate training for all participants so they know how to fulfil their role 
    facilitating meetings 
  v4.0 
  page 36 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  4 test analysis and design 390 minutes 
  keywords 
  acceptance criteria acceptance test driven development black box test technique boundary value 
  analysis branch coverage checklist based testing collaboration based test approach coverage 
  coverage item decision table testing equivalence partitioning error guessing experience based test 
  technique exploratory testing state transition testing statement coverage test technique white box test 
  technique 
  learning objectives for chapter 4 
  4.1    test techniques overview 
  fl-4.1.1 
  k2 distinguish black box white box and experience based test techniques 
  4.2    black box test techniques 
  fl-4.2.1 
  k3 use equivalence partitioning to derive test cases 
  fl-4.2.2 
  k3 use boundary value analysis to derive test cases 
  fl-4.2.3 
  k3 use decision table testing to derive test cases 
  fl-4.2.4 
  k3 use state transition testing to derive test cases 
  4.3    white box test techniques 
  fl-4.3.1 
  k2 explain statement testing 
  fl-4.3.2 
  k2 explain branch testing 
  fl-4.3.3 
  k2 explain the value of white box testing 
  4.4    experience based test techniques 
  fl-4.4.1 
  k2 explain error guessing 
  fl-4.4.2 
  k2 explain exploratory testing 
  fl-4.4.3 
  k2 explain checklist based testing 
  4.5 collaboration based test approaches 
  fl-4.5.1 
  k2 explain how to write user stories in collaboration with developers and business 
  representatives 
  fl-4.5.2 
  k2 classify the different options for writing acceptance criteria 
  fl-4.5.3 
  k3 use acceptance test driven development atdd to derive test cases 
  v4.0 
  page 37 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  4.1 test techniques overview 
  test techniques support the tester in test analysis what to test and in test design how to test test 
  techniques help to develop a relatively small but sufficient set of test cases in a systematic way test 
  techniques also help the tester to define test conditions identify coverage items and identify test data 
  during the test analysis and design further information on test techniques and their corresponding 
  measures can be found in the iso iec ieee 29119 4 standard and in beizer 1990 craig 2002 
  copeland 2004 koomen 2006 jorgensen 2014 ammann 2016 forgács 2019 
  in this syllabus test techniques are classified as black box white box and experience based 
  black box test techniques also known as specification based techniques are based on an analysis of 
  the specified behavior of the test object without reference to its internal structure therefore the test 
  cases are independent of how the software is implemented consequently if the implementation 
  changes but the required behavior stays the same then the test cases are still useful  
  white box test techniques also known as structure based techniques are based on an analysis of the 
  test object ’s internal structure and processing as the test cases are dependent on how the software is 
  designed they can only be created after the design or implementation of the test object  
  experience based test techniques effectively use the knowledge and experience of testers for the 
  design and implementation of test cases the effectiveness of these techniques depends heavily on the 
  tester ’s skills experience based test techniques can detect defects that may be missed using the black- 
  box and white box test techniques hence experience based test techniques are complementary to the 
  black box and white box test techniques 
  4.2 black box test techniques 
  commonly used black box test techniques discussed in the following sections are 
    equivalence partitioning 
    boundary value analysis 
    decision table testing 
    state transition testing 
  4.2.1    equivalence partitioning 
  equivalence partitioning ep divides data into partitions known as equivalence partitions based on the 
  expectation that all the elements of a given partition are to be processed in the same way by the test 
  object the theory behind this technique is that if a test case that tests one value from an equivalence 
  partition detects a defect this defect should also be detected by test cases that test any other value from 
  the same partition therefore one test for each partition is sufficient  
  equivalence partitions can be identified for any data element related to the test object including inputs 
  outputs configuration items internal values time related values and interface parameters the partitions 
  may be continuous or discrete ordered or unordered finite or infinite the partitions must not overlap and 
  must be non empty sets 
  for simple test objects ep can be easy but in practice understanding how the test object will treat 
  different values is often complicated therefore partitioning should be done with care 
  v4.0 
  page 38 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  a partition containing valid values is called a valid partition a partition containing invalid values is called 
  an invalid partition the definitions of valid and invalid values may vary among teams and organizations 
  for example valid values may be interpreted as those that should be processed by the test object or as 
  those for which the specification defines their processing invalid values may be interpreted as those that 
  should be ignored or rejected by the test object or as those for which no processing is defined in the test 
  object specification 
  in ep the coverage items are the equivalence partitions to achieve 100 coverage with this technique 
  test cases must exercise all identified partitions including invalid partitions by covering each partition at 
  least once coverage is measured as the number of partitions exercised by at least one test case divided 
  by the total number of identified partitions and is expressed as a percentage 
  many test objects include multiple sets of partitions e.g. test objects with more than one input 
  parameter which means that a test case will cover partitions from different sets of partitions the 
  simplest coverage criterion in the case of multiple sets of partitions is called each choice coverage 
  ammann 2016 each choice coverage requires test cases to exercise each partition from each set of 
  partitions at least once each choice coverage does not take into account combinations of partitions 
  4.2.2    boundary value analysis 
  boundary value analysis bva is a technique based on exercising the boundaries of equivalence 
  partitions therefore bva can only be used for ordered partitions the minimum and maximum values of 
  a partition are its boundary values in the case of bva if two elements belong to the same partition all 
  elements between them must also belong to that partition 
  bva focuses on the boundary values of the partitions because developers are more likely to make errors 
  with these boundary values typical defects found by bva are located where implemented boundaries 
  are misplaced to positions above or below their intended positions or are omitted altogether  
  this syllabus covers two versions of the bva 2 value and 3 value bva they differ in terms of coverage 
  items per boundary that need to be exercised to achieve 100 coverage 
  in 2 value bva craig 2002 myers 2011 for each boundary value there are two coverage items this 
  boundary value and its closest neighbor belonging to the adjacent partition to achieve 100 coverage 
  with 2 value bva test cases must exercise all coverage items i.e. all identified boundary values 
  coverage is measured as the number of boundary values that were exercised divided by the total 
  number of identified boundary values and is expressed as a percentage 
  in 3 value bva koomen 2006 o’regan 2019 for each boundary value there are three coverage items 
  this boundary value and both its neighbors therefore in 3 value bva some of the coverage items may 
  not be boundary values to achieve 100 coverage with 3 value bva test cases must exercise all 
  coverage items i.e. identified boundary values and their neighbors coverage is measured as the 
  number of boundary values and their neighbors exercised divided by the total number of identified 
  boundary values and their neighbors and is expressed as a percentage 
  3 value bva is more rigorous than 2 value bva as it may detect defects overlooked by 2 value bva for 
  example if the decision if x ≤ 10 is incorrectly implemented as if x = 10 no test data derived 
  from the 2 value bva x = 10 x = 11 can detect the defect however x = 9 derived from the 3 value 
  bva is likely to detect it 
  v4.0 
  page 39 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  4.2.3    decision table testing  
  decision tables are used for testing the implementation of system requirements that specify how different 
  combinations of conditions result in different outcomes decision tables are an effective way of recording 
  complex logic such as business rules 
  when creating decision tables the conditions and the resulting actions of the system are defined these 
  form the rows of the table each column corresponds to a decision rule that defines a unique combination 
  of conditions along with the associated actions in limited entry decision tables all the values of the 
  conditions and actions except for irrelevant or infeasible ones see below are shown as boolean values 
  true or false alternatively in extended entry decision tables some or all the conditions and actions may 
  also take on multiple values e.g. ranges of numbers equivalence partitions discrete values 
  the notation for conditions is as follows t true means that the condition is satisfied f false means 
  that the condition is not satisfied means that the value of the condition is irrelevant for the action 
  outcome n a means that the condition is infeasible for a given rule for actions x means that the 
  action should occur blank means that the action should not occur other notations may also be used 
  a full decision table has enough columns to cover every combination of conditions the table can be 
  simplified by deleting columns containing infeasible combinations of conditions the table can also be 
  minimized by merging columns in which some conditions do not affect the outcome into a single column 
  decision table minimization algorithms are out of scope of this syllabus 
  in decision table testing the coverage items are the columns containing feasible combinations of 
  conditions to achieve 100 coverage with this technique test cases must exercise all these columns 
  coverage is measured as the number of exercised columns divided by the total number of feasible 
  columns and is expressed as a percentage 
  the strength of decision table testing is that it provides a systematic approach to identify all the 
  combinations of conditions some of which might otherwise be overlooked it also helps to find any gaps 
  or contradictions in the requirements if there are many conditions exercising all the decision rules may 
  be time consuming since the number of rules grows exponentially with the number of conditions in such 
  a case to reduce the number of rules that need to be exercised a minimized decision table or a risk- 
  based approach may be used 
  4.2.4    state transition testing 
  a state transition diagram models the behavior of a system by showing its possible states and valid state 
  transitions a transition is initiated by an event which may be additionally qualified by a guard condition 
  the transitions are assumed to be instantaneous and may sometimes result in the software taking action 
  the common transition labeling syntax is as follows event guard condition action guard conditions 
  and actions can be omitted if they do not exist or are irrelevant for the tester  
  a state table is a model equivalent to a state transition diagram its rows represent states and its 
  columns represent events together with guard conditions if they exist table entries cells represent 
  transitions and contain the target state as well as the resulting actions if defined in contrast to the state 
  transition diagram the state table explicitly shows invalid transitions which are represented by empty 
  cells 
  a test case based on a state transition diagram or state table is usually represented as a sequence of 
  events which results in a sequence of state changes and actions if needed one test case may and 
  usually will cover several transitions between states  
  there exist many coverage criteria for state transition testing this syllabus discusses three of them 
  v4.0 
  page 40 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  in all states coverage the coverage items are the states to achieve 100 all states coverage test 
  cases must ensure that all the states are visited coverage is measured as the number of visited states 
  divided by the total number of states and is expressed as a percentage 
  in valid transitions coverage also called 0 switch coverage the coverage items are single valid 
  transitions to achieve 100 valid transitions coverage test cases must exercise all the valid transitions 
  coverage is measured as the number of exercised valid transitions divided by the total number of valid 
  transitions and is expressed as a percentage  
  in all transitions coverage the coverage items are all the transitions shown in a state table to achieve 
  100 all transitions coverage test cases must exercise all the valid transitions and attempt to execute 
  invalid transitions testing only one invalid transition in a single test case helps to avoid fault masking 
  i.e. a situation in which one defect prevents the detection of another coverage is measured as the 
  number of valid and invalid transitions exercised or attempted to be covered by executed test cases 
  divided by the total number of valid and invalid transitions and is expressed as a percentage 
  all states coverage is weaker than valid transitions coverage because it can typically be achieved without 
  exercising all the transitions valid transitions coverage is the most widely used coverage criterion 
  achieving full valid transitions coverage guarantees full all states coverage achieving full all transitions 
  coverage guarantees both full all states coverage and full valid transitions coverage and should be a 
  minimum requirement for mission and safety critical software  
  4.3 white box test techniques 
  because of their popularity and simplicity this section focuses on two code related white box test 
  techniques 
    statement testing 
    branch testing 
  there are more rigorous techniques that are used in some safety critical mission critical or high integrity 
  environments to achieve more thorough code coverage there are also white box test techniques used in 
  higher test levels e.g. api testing or using coverage not related to code e.g. neuron coverage in 
  neural network testing these techniques are not discussed in this syllabus 
  4.3.1    statement testing and statement coverage  
  in statement testing the coverage items are executable statements the aim is to design test cases that 
  exercise statements in the code until an acceptable level of coverage is achieved coverage is measured 
  as the number of statements exercised by the test cases divided by the total number of executable 
  statements in the code and is expressed as a percentage 
  when 100 statement coverage is achieved it ensures that all executable statements in the code have 
  been exercised at least once in particular this means that each statement with a defect will be executed 
  which may cause a failure demonstrating the presence of the defect however exercising a statement 
  with a test case will not detect defects in all cases for example it may not detect defects that are data 
  dependent e.g. a division by zero that only fails when a denominator is set to zero also 100 
  statement coverage does not ensure that all the decision logic has been tested as for instance it may not 
  exercise all the branches see chapter 4.3.2 in the code  
  v4.0 
  page 41 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  4.3.2    branch testing and branch coverage  
  a branch is a transfer of control between two nodes in the control flow graph which shows the possible 
  sequences in which source code statements are executed in the test object each transfer of control can 
  be either unconditional i.e. straight line code or conditional i.e. a decision outcome 
  in branch testing the coverage items are branches and the aim is to design test cases to exercise 
  branches in the code until an acceptable level of coverage is achieved coverage is measured as the 
  number of branches exercised by the test cases divided by the total number of branches and is 
  expressed as a percentage 
  when 100 branch coverage is achieved all branches in the code unconditional and conditional are 
  exercised by test cases conditional branches typically correspond to a true or false outcome from an 
  if then decision an outcome from a switch case statement or a decision to exit or continue in a loop 
  however exercising a branch with a test case will not detect defects in all cases for example it may not 
  detect defects requiring the execution of a specific path in a code 
  branch coverage subsumes statement coverage this means that any set of test cases achieving 100 
  branch coverage also achieves 100 statement coverage but not vice versa 
  4.3.3    the value of white box testing  
  a fundamental strength that all white box techniques share is that the entire software implementation is 
  taken into account during testing which facilitates defect detection even when the software specification 
  is vague outdated or incomplete a corresponding weakness is that if the software does not implement 
  one or more requirements white box testing may not detect the resulting defects of omission watson 
  1996 
  white box techniques can be used in static testing e.g. during dry runs of code they are well suited to 
  reviewing code that is not yet ready for execution hetzel 1988 as well as pseudocode and other high- 
  level or top down logic which can be modeled with a control flow graph 
  performing only black box testing does not provide a measure of actual code coverage white box 
  coverage measures provide an objective measurement of coverage and provide the necessary 
  information to allow additional tests to be generated to increase this coverage and subsequently increase 
  confidence in the code 
  4.4 experience based test techniques  
  commonly used experience based test techniques discussed in the following sections are 
    error guessing 
    exploratory testing 
    checklist based testing 
  4.4.1    error guessing 
  error guessing is a technique used to anticipate the occurrence of errors defects and failures based on 
  the tester ’s knowledge including 
    how the application has worked in the past 
  v4.0 
  page 42 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    the types of errors the developers tend to make and the types of defects that result from these 
  errors 
    the types of failures that have occurred in other similar applications 
  in general errors defects and failures may be related to input e.g. correct input not accepted 
  parameters wrong or missing output e.g. wrong format wrong result logic e.g. missing cases wrong 
  operator computation e.g. incorrect operand wrong computation interfaces e.g. parameter 
  mismatch incompatible types or data e.g. incorrect initialization wrong type 
  fault attacks are a methodical approach to the implementation of error guessing this technique requires 
  the tester to create or acquire a list of possible errors defects and failures and to design tests that will 
  identify defects associated with the errors expose the defects or cause the failures these lists can be 
  built based on experience defect and failure data or from common knowledge about why software fails 
  see whittaker 2002 whittaker 2003 andrews 2006 for more information on error guessing and fault 
  attacks 
  4.4.2    exploratory testing 
  in exploratory testing tests are simultaneously designed executed and evaluated while the tester learns 
  about the test object the testing is used to learn more about the test object to explore it more deeply 
  with focused tests and to create tests for untested areas 
  exploratory testing is sometimes conducted using session based testing to structure the testing in a 
  session based approach exploratory testing is conducted within a defined time box the tester uses a 
  test charter containing test objectives to guide the testing the test session is usually followed by a 
  debriefing that involves a discussion between the tester and stakeholders interested in the test results of 
  the test session in this approach test objectives may be treated as high level test conditions coverage 
  items are identified and exercised during the test session the tester may use test session sheets to 
  document the steps followed and the discoveries made 
  exploratory testing is useful when there are few or inadequate specifications or there is significant time 
  pressure on the testing exploratory testing is also useful to complement other more formal test 
  techniques exploratory testing will be more effective if the tester is experienced has domain knowledge 
  and has a high degree of essential skills like analytical skills curiosity and creativeness see section 
  1.5.1 
  exploratory testing can incorporate the use of other test techniques e.g. equivalence partitioning more 
  information about exploratory testing can be found in kaner 1999 whittaker 2009 hendrickson 2013 
  4.4.3    checklist based testing 
  in checklist based testing a tester designs implements and executes tests to cover test conditions from 
  a checklist checklists can be built based on experience knowledge about what is important for the user 
  or an understanding of why and how software fails checklists should not contain items that can be 
  checked automatically items better suited as entry exit criteria or items that are too general brykczynski 
  1999 
  checklist items are often phrased in the form of a question it should be possible to check each item 
  separately and directly these items may refer to requirements graphical interface properties quality 
  characteristics or other forms of test conditions checklists can be created to support various test types 
  including functional and non functional testing e.g. 10 heuristics for usability testing nielsen 1994 
  v4.0 
  page 43 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  some checklist entries may gradually become less effective over time because the developers will learn 
  to avoid making the same errors new entries may also need to be added to reflect newly found high 
  severity defects therefore checklists should be regularly updated based on defect analysis however 
  care should be taken to avoid letting the checklist become too long gawande 2009  
  in the absence of detailed test cases checklist based testing can provide guidelines and some degree of 
  consistency for the testing if the checklists are high level some variability in the actual testing is likely to 
  occur resulting in potentially greater coverage but less repeatability 
  4.5 collaboration based test approaches 
  each of the above mentioned techniques see sections 4.2 4.3 4.4 has a particular objective with 
  respect to defect detection collaboration based approaches on the other hand focus also on defect 
  avoidance by collaboration and communication 
  4.5.1    collaborative user story writing 
  a user story represents a feature that will be valuable to either a user or purchaser of a system or 
  software user stories have three critical aspects jeffries 2000 called together the 3 c ’s 
    card the medium describing a user story e.g. an index card an entry in an electronic board  
    conversation explains how the software will be used can be documented or verbal  
    confirmation the acceptance criteria see section 4.5.2 
  the most common format for a user story is as a role i want goal to be accomplished so that i can 
  resulting business value for the role followed by the acceptance criteria 
  collaborative authorship of the user story can use techniques such as brainstorming and mind mapping 
  the collaboration allows the team to obtain a shared vision of what should be delivered by taking into 
  account three perspectives business development and testing 
  good user stories should be independent negotiable valuable estimable small and testable 
  invest if a stakeholder does not know how to test a user story this may indicate that the user story is 
  not clear enough or that it does not reflect something valuable to them or that the stakeholder just needs 
  help in testing wake 2003 
  4.5.2    acceptance criteria 
  acceptance criteria for a user story are the conditions that an implementation of the user story must meet 
  to be accepted by stakeholders from this perspective acceptance criteria may be viewed as the test 
  conditions that should be exercised by the tests acceptance criteria are usually a result of the 
  conversation see section 4.5.1  
  acceptance criteria are used to 
    define the scope of the user story  
    reach consensus among the stakeholders 
    describe both positive and negative scenarios  
    serve as a basis for the user story acceptance testing see section 4.5.3  
  v4.0 
  page 44 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    allow accurate planning and estimation  
  there are several ways to write acceptance criteria for a user story the two most common formats are 
    scenario oriented e.g. given when then format used in bdd see section 2.1.3  
    rule oriented e.g. bullet point verification list or tabulated form of input output mapping  
  most acceptance criteria can be documented in one of these two formats however the team may use 
  another custom format as long as the acceptance criteria are well defined and unambiguous 
  4.5.3    acceptance test driven development atdd  
  atdd is a test first approach see section 2.1.3 test cases are created prior to implementing the user 
  story the test cases are created by team members with different perspectives e.g. customers 
  developers and testers adzic 2009 test cases may be executed manually or automated  
  the first step is a specification workshop where the user story and if not yet defined its acceptance 
  criteria are analyzed discussed and written by the team members incompleteness ambiguities or 
  defects in the user story are resolved during this process the next step is to create the test cases this 
  can be done by the team as a whole or by the tester individually the test cases are based on the 
  acceptance criteria and can be seen as examples of how the software works this will help the team 
  implement the user story correctly 
  since examples and tests are the same these terms are often used interchangeably during the test 
  design the test techniques described in sections 4.2 4.3 and 4.4 may be applied 
  typically the first test cases are positive confirming the correct behavior without exceptions or error 
  conditions and comprising the sequence of activities executed if everything goes as expected after the 
  positive test cases are done the team should perform negative testing finally the team should cover 
  non functional quality characteristics as well e.g. performance efficiency usability test cases should 
  be expressed in a way that is understandable for the stakeholders typically test cases contain 
  sentences in natural language involving the necessary preconditions if any the inputs and the 
  postconditions  
  the test cases must cover all the characteristics of the user story and should not go beyond the story 
  however the acceptance criteria may detail some of the issues described in the user story in addition 
  no two test cases should describe the same characteristics of the user story  
  when captured in a format supported by a test automation framework the developers can automate the 
  test cases by writing the supporting code as they implement the feature described by a user story the 
  acceptance tests then become executable requirements 
  v4.0 
  page 45 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  5 managing the test activities 335 minutes 
  keywords 
  defect management defect report entry criteria exit criteria product risk project risk risk risk analysis 
  risk assessment risk control risk identification risk level risk management risk mitigation risk 
  monitoring risk based testing test approach test completion report test control test monitoring test 
  plan test planning test progress report test pyramid testing quadrants 
  learning objectives for chapter 5 
  5.1 test planning 
  fl-5.1.1  
  k2 exemplify the purpose and content of a test plan  
  fl-5.1.2 
  k1 recognize how a tester adds value to iteration and release planning 
  fl-5.1.3 
  k2 compare and contrast entry criteria and exit criteria 
  fl-5.1.4 
  k3 use estimation techniques to calculate the required test effort 
  fl-5.1.5  
  k3 apply test case prioritization 
  fl-5.1.6  
  k1 recall the concepts of the test pyramid 
  fl-5.1.7 
  k2 summarize the testing quadrants and their relationships with test levels and test types 
  5.2 risk management 
  fl-5.2.1 
  k1 identify risk level by using risk likelihood and risk impact  
  fl-5.2.2 
  k2 distinguish between project risks and product risks 
  fl-5.2.3 
  k2 explain how product risk analysis may influence thoroughness and scope of testing 
  fl-5.2.4 
  k2 explain what measures can be taken in response to analyzed product risks 
  5.3 test monitoring test control and test completion 
  fl-5.3.1 
  k1 recall metrics used for testing 
  fl-5.3.2 
  k2 summarize the purposes content and audiences for test reports 
  fl-5.3.3 
  k2 exemplify how to communicate the status of testing 
  5.4 configuration management 
  fl-5.4.1  
  k2 summarize how configuration management supports testing 
  5.5 defect management 
  fl-5.5.1  
  k3 prepare a defect report 
  v4.0 
  page 46 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  5.1 test planning 
  5.1.1    purpose and content of a test plan 
  a test plan describes the objectives resources and processes for a test project a test plan 
    documents the means and schedule for achieving test objectives 
    helps to ensure that the performed test activities will meet the established criteria 
    serves as a means of communication with team members and other stakeholders 
    demonstrates that testing will adhere to the existing test policy and test strategy or explains why 
  the testing will deviate from them 
  test planning guides the testers thinking and forces the testers to confront the future challenges related 
  to risks schedules people tools costs effort etc the process of preparing a test plan is a useful way to 
  think through the efforts needed to achieve the test project objectives 
  the typical content of a test plan includes 
    context of testing e.g. scope test objectives constraints test basis 
    assumptions and constraints of the test project 
    stakeholders e.g. roles responsibilities relevance to testing hiring and training needs 
    communication e.g. forms and frequency of communication documentation templates 
    risk register e.g. product risks project risks 
    test approach e.g. test levels test types test techniques test deliverables entry criteria and 
  exit criteria independence of testing metrics to be collected test data requirements test 
  environment requirements deviations from the organizational test policy and test strategy 
    budget and schedule 
  more details about the test plan and its content can be found in the iso iec ieee 29119 3 standard 
  5.1.2    tester 's contribution to iteration and release planning 
  in iterative sdlcs typically two kinds of planning occur release planning and iteration planning  
  release planning looks ahead to the release of a product defines and re defines the product backlog 
  and may involve refining larger user stories into a set of smaller user stories it also serves as the basis 
  for the test approach and test plan across all iterations testers involved in release planning participate in 
  writing testable user stories and acceptance criteria see section 4.5 participate in project and quality 
  risk analyses see section 5.2 estimate test effort associated with user stories see section 5.1.4 
  determine the test approach and plan the testing for the release 
  iteration planning looks ahead to the end of a single iteration and is concerned with the iteration backlog 
  testers involved in iteration planning participate in the detailed risk analysis of user stories determine the 
  testability of user stories break down user stories into tasks particularly testing tasks estimate test effort 
  for all testing tasks and identify and refine functional and non functional aspects of the test object 
  v4.0 
  page 47 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  5.1.3    entry criteria and exit criteria 
  entry criteria define the preconditions for undertaking a given activity if entry criteria are not met it is 
  likely that the activity will prove to be more difficult time consuming costly and riskier exit criteria define 
  what must be achieved in order to declare an activity completed entry criteria and exit criteria should be 
  defined for each test level and will differ based on the test objectives 
  typical entry criteria include availability of resources e.g. people tools environments test data budget 
  time availability of testware e.g. test basis testable requirements user stories test cases and initial 
  quality level of a test object e.g. all smoke tests have passed 
  typical exit criteria include measures of thoroughness e.g. achieved level of coverage number of 
  unresolved defects defect density number of failed test cases and completion criteria e.g. planned 
  tests have been executed static testing has been performed all defects found are reported all 
  regression tests are automated 
  running out of time or budget can also be viewed as valid exit criteria even without other exit criteria 
  being satisfied it can be acceptable to end testing under such circumstances if the stakeholders have 
  reviewed and accepted the risk to go live without further testing  
  in agile software development exit criteria are often called definition of done defining the team ’s 
  objective metrics for a releasable item entry criteria that a user story must fulfill to start the development 
  and/or testing activities are called definition of ready 
  5.1.4    estimation techniques 
  test effort estimation involves predicting the amount of test related work needed to meet the objectives of 
  a test project it is important to make it clear to the stakeholders that the estimate is based on a number of 
  assumptions and is always subject to estimation error estimation for small tasks is usually more accurate 
  than for the large ones therefore when estimating a large task it can be decomposed into a set of 
  smaller tasks which then in turn can be estimated 
  in this syllabus the following four estimation techniques are described 
  estimation based on ratios in this metrics based technique figures are collected from previous projects 
  within the organization which makes it possible to derive standard ratios for similar projects the ratios 
  of an organization ’s own projects e.g. taken from historical data are generally the best source to use in 
  the estimation process these standard ratios can then be used to estimate the test effort for the new 
  project for example if in the previous project the development to test effort ratio was 3:2 and in the 
  current project the development effort is expected to be 600 person days the test effort can be estimated 
  to be 400 person days 
  extrapolation in this metrics based technique measurements are made as early as possible in the 
  current project to gather the data having enough observations the effort required for the remaining work 
  can be approximated by extrapolating this data usually by applying a mathematical model this method 
  is very suitable in iterative sdlcs for example the team may extrapolate the test effort in the 
  forthcoming iteration as the averaged effort from the last three iterations 
  wideband delphi in this iterative expert based technique experts make experience based estimations 
  each expert in isolation estimates the effort the results are collected and if there are deviations that are 
  out of range of the agreed upon boundaries the experts discuss their current estimates each expert is 
  then asked to make a new estimation based on that feedback again in isolation this process is repeated 
  until a consensus is reached planning poker is a variant of wideband delphi commonly used in agile 
  v4.0 
  page 48 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  software development in planning poker estimates are usually made using cards with numbers that 
  represent the effort size 
  three point estimation in this expert based technique three estimations are made by the experts the 
  most optimistic estimation a the most likely estimation m and the most pessimistic estimation b the 
  final estimate e is their weighted arithmetic mean in the most popular version of this technique the 
  estimate is calculated as e = a + 4*m + b 6 the advantage of this technique is that it allows the 
  experts to calculate the measurement error sd = b a 6 for example if the estimates in person- 
  hours are a=6 m=9 and b=18 then the final estimation is 10±2 person hours i.e. between 8 and 12 
  person hours because e = 6 + 4 9 + 18 6 = 10 and sd = 18 6 6 = 2 
  see kan 2003 koomen 2006 westfall 2009 for these and many other test estimation techniques 
  5.1.5    test case prioritization 
  once the test cases and test procedures are specified and assembled into test suites these test suites 
  can be arranged in a test execution schedule that defines the order in which they are to be run when 
  prioritizing test cases different factors can be taken into account the most commonly used test case 
  prioritization strategies are as follows 
    risk based prioritization where the order of test execution is based on the results of risk analysis 
  see section 5.2.3 test cases covering the most important risks are executed first 
    coverage based prioritization where the order of test execution is based on coverage e.g. 
  statement coverage test cases achieving the highest coverage are executed first in another 
  variant called additional coverage prioritization the test case achieving the highest coverage is 
  executed first each subsequent test case is the one that achieves the highest additional 
  coverage 
    requirements based prioritization where the order of test execution is based on the priorities of 
  the requirements traced back to the corresponding test cases requirement priorities are defined 
  by stakeholders test cases related to the most important requirements are executed first 
  ideally test cases would be ordered to run based on their priority levels using for example one of the 
  above mentioned prioritization strategies however this practice may not work if the test cases or the 
  features being tested have dependencies if a test case with a higher priority is dependent on a test case 
  with a lower priority the lower priority test case must be executed first  
  the order of test execution must also take into account the availability of resources for example the 
  required test tools test environments or people that may only be available for a specific time window 
  5.1.6    test pyramid 
  the test pyramid is a model showing that different tests may have different granularity the test pyramid 
  model supports the team in test automation and in test effort allocation by showing that different goals are 
  supported by different levels of test automation the pyramid layers represent groups of tests the higher 
  the layer the lower the test granularity test isolation and test execution time tests in the bottom layer 
  are small isolated fast and check a small piece of functionality so usually a lot of them are needed to 
  achieve a reasonable coverage the top layer represents complex high level end to end tests these 
  high level tests are generally slower than the tests from the lower layers and they typically check a large 
  piece of functionality so usually just a few of them are needed to achieve a reasonable coverage the 
  number and naming of the layers may differ for example the original test pyramid model cohn 2009 
  defines three layers unit tests service tests and ui tests another popular model defines unit 
  v4.0 
  page 49 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  component tests integration component integration tests and end to end tests other test levels see 
  section 2.2.1 can also be used 
  5.1.7    testing quadrants 
  the testing quadrants defined by brian marick marick 2003 crispin 2008 group the test levels with the 
  appropriate test types activities test techniques and work products in the agile software development 
  the model supports test management in visualizing these to ensure that all appropriate test types and 
  test levels are included in the sdlc and in understanding that some test types are more relevant to 
  certain test levels than others this model also provides a way to differentiate and describe the types of 
  tests to all stakeholders including developers testers and business representatives  
  in this model tests can be business facing or technology facing tests can also support the team i.e. 
  guide the development or critique the product i.e. measure its behavior against the expectations the 
  combination of these two viewpoints determines the four quadrants 
    quadrant q1 technology facing support the team this quadrant contains component and 
  component integration tests these tests should be automated and included in the ci process 
    quadrant q2 business facing support the team this quadrant contains functional tests 
  examples user story tests user experience prototypes api testing and simulations these tests 
  check the acceptance criteria and can be manual or automated 
    quadrant q3 business facing critique the product this quadrant contains exploratory testing 
  usability testing user acceptance testing these tests are user oriented and often manual 
    quadrant q4 technology facing critique the product this quadrant contains smoke tests and 
  non functional tests except usability tests these tests are often automated 
  5.2 risk management 
  organizations face many internal and external factors that make it uncertain whether and when they will 
  achieve their objectives iso 31000 risk management allows the organizations to increase the 
  likelihood of achieving objectives improve the quality of their products and increase the stakeholders 
  confidence and trust  
  the main risk management activities are 
    risk analysis consisting of risk identification and risk assessment see section 5.2.3 
    risk control consisting of risk mitigation and risk monitoring see section 5.2.4 
  the test approach in which test activities are selected prioritized and managed based on risk analysis 
  and risk control is called risk based testing 
  5.2.1    risk definition and risk attributes 
  risk is a potential event hazard threat or situation whose occurrence causes an adverse effect a risk 
  can be characterized by two factors 
    risk likelihood the probability of the risk occurrence greater than zero and less than one 
    risk impact harm the consequences of this occurrence 
  v4.0 
  page 50 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  these two factors express the risk level which is a measure for the risk the higher the risk level the 
  more important is its treatment 
  5.2.2    project risks and product risks 
  in software testing one is generally concerned with two types of risks project risks and product risks 
  project risks are related to the management and control of the project project risks include 
    organizational issues e.g. delays in work products deliveries inaccurate estimates cost cutting 
    people issues e.g. insufficient skills conflicts communication problems shortage of staff 
    technical issues e.g. scope creep poor tool support 
    supplier issues e.g. third party delivery failure bankruptcy of the supporting company 
  project risks when they occur may have an impact on the project schedule budget or scope which 
  affects the project 's ability to achieve its objectives 
  product risks are related to the product quality characteristics e.g. described in the iso 25010 quality 
  model examples of product risks include missing or wrong functionality incorrect calculations runtime 
  errors poor architecture inefficient algorithms inadequate response time poor user experience security 
  vulnerabilities product risks when they occur may result in various negative consequences including 
    user dissatisfaction 
    loss of revenue trust reputation 
    damage to third parties 
    high maintenance costs overload of the helpdesk 
    criminal penalties 
 
  in extreme cases physical damage injuries or even death 
  5.2.3    product risk analysis 
  from a testing perspective the goal of product risk analysis is to provide an awareness of product risk in 
  order to focus the testing effort in a way that minimizes the residual level of product risk ideally product 
  risk analysis begins early in the sdlc 
  product risk analysis consists of risk identification and risk assessment risk identification is about 
  generating a comprehensive list of risks stakeholders can identify risks by using various techniques and 
  tools e.g. brainstorming workshops interviews or cause effect diagrams risk assessment involves 
  categorization of identified risks determining their risk likelihood risk impact and level prioritizing and 
  proposing ways to handle them categorization helps in assigning mitigation actions because usually 
  risks falling into the same category can be mitigated using a similar approach  
  risk assessment can use a quantitative or qualitative approach or a mix of them in the quantitative 
  approach the risk level is calculated as the multiplication of risk likelihood and risk impact in the 
  qualitative approach the risk level can be determined using a risk matrix 
  product risk analysis may influence the thoroughness and scope of testing its results are used to 
  v4.0 
  page 51 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    determine the scope of testing to be carried out  
    determine the particular test levels and propose test types to be performed  
    determine the test techniques to be employed and the coverage to be achieved 
    estimate the test effort required for each task 
    prioritize testing in an attempt to find the critical defects as early as possible 
    determine whether any activities in addition to testing could be employed to reduce risk 
  5.2.4    product risk control 
  product risk control comprises all measures that are taken in response to identified and assessed product 
  risks product risk control consists of risk mitigation and risk monitoring risk mitigation involves 
  implementing the actions proposed in risk assessment to reduce the risk level the aim of risk monitoring 
  is to ensure that the mitigation actions are effective to obtain further information to improve risk 
  assessment and to identify emerging risks 
  with respect to product risk control once a risk has been analyzed several response options to risk are 
  possible e.g. risk mitigation by testing risk acceptance risk transfer or contingency plan veenendaal 
  2012 actions that can be taken to mitigate the product risks by testing are as follows 
    select the testers with the right level of experience and skills suitable for a given risk type 
    apply an appropriate level of independence of testing 
    conduct reviews and perform static analysis 
    apply the appropriate test techniques and coverage levels 
    apply the appropriate test types addressing the affected quality characteristics 
    perform dynamic testing including regression testing 
  5.3 test monitoring test control and test completion 
  test monitoring is concerned with gathering information about testing this information is used to assess 
  test progress and to measure whether the test exit criteria or the test tasks associated with the exit criteria 
  are satisfied such as meeting the targets for coverage of product risks requirements or acceptance 
  criteria  
  test control uses the information from test monitoring to provide in a form of the control directives 
  guidance and the necessary corrective actions to achieve the most effective and efficient testing 
  examples of control directives include 
    reprioritizing tests when an identified risk becomes an issue 
    re evaluating whether a test item meets entry criteria or exit criteria due to rework 
    adjusting the test schedule to address a delay in the delivery of the test environment 
    adding new resources when and where needed 
  v4.0 
  page 52 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  test completion collects data from completed test activities to consolidate experience testware and any 
  other relevant information test completion activities occur at project milestones such as when a test level 
  is completed an agile iteration is finished a test project is completed or cancelled a software system is 
  released or a maintenance release is completed 
  5.3.1    metrics used in testing 
  test metrics are gathered to show progress against the planned schedule and budget the current quality 
  of the test object and the effectiveness of the test activities with respect to the objectives or an iteration 
  goal test monitoring gathers a variety of metrics to support the test control and test completion  
  common test metrics include 
    project progress metrics e.g. task completion resource usage test effort 
    test progress metrics e.g. test case implementation progress test environment preparation 
  progress number of test cases run not run passed failed test execution time 
    product quality metrics e.g. availability response time mean time to failure 
    defect metrics e.g. number and priorities of defects found fixed defect density defect detection 
  percentage 
    risk metrics e.g. residual risk level 
    coverage metrics e.g. requirements coverage code coverage 
    cost metrics e.g. cost of testing organizational cost of quality 
  5.3.2    purpose content and audience for test reports 
  test reporting summarizes and communicates test information during and after testing test progress 
  reports support the ongoing control of the testing and must provide enough information to make 
  modifications to the test schedule resources or test plan when such changes are needed due to 
  deviation from the plan or changed circumstances test completion reports summarize a specific stage of 
  testing e.g. test level test cycle iteration and can give information for subsequent testing  
  during test monitoring and control the test team generates test progress reports for stakeholders to keep 
  them informed test progress reports are usually generated on a regular basis e.g. daily weekly etc 
  and include 
    test period 
    test progress e.g. ahead or behind schedule including any notable deviations 
 
  impediments for testing and their workarounds 
    test metrics see section 5.3.1 for examples 
    new and changed risks within testing period 
    testing planned for the next period 
  v4.0 
  page 53 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  a test completion report is prepared during test completion when a project test level or test type is 
  complete and when ideally its exit criteria have been met this report uses test progress reports and 
  other data typical test completion reports include 
    test summary 
    testing and product quality evaluation based on the original test plan i.e. test objectives and exit 
  criteria 
    deviations from the test plan e.g. differences from the planned schedule duration and effort 
    testing impediments and workarounds 
    test metrics based on test progress reports 
    unmitigated risks defects not fixed 
    lessons learned that are relevant to the testing 
  different audiences require different information in the reports and influence the degree of formality and 
  the frequency of reporting reporting on test progress to others in the same team is often frequent and 
  informal while reporting on testing for a completed project follows a set template and occurs only once  
  the iso iec ieee 29119 3 standard includes templates and examples for test progress reports called 
  test status reports and test completion reports 
  5.3.3    communicating the status of testing 
  the best means of communicating test status varies depending on test management concerns 
  organizational test strategies regulatory standards or in the case of self organizing teams see section 
  1.5.2 on the team itself the options include 
    verbal communication with team members and other stakeholders 
    dashboards e.g. ci cd dashboards task boards and burn down charts 
    electronic communication channels e.g. email chat  
    online documentation 
    formal test reports see section 5.3.2 
  one or more of these options can be used more formal communication may be more appropriate for 
  distributed teams where direct face to face communication is not always possible due to geographical 
  distance or time differences typically different stakeholders are interested in different types of 
  information so communication should be tailored accordingly 
  5.4 configuration management 
  in testing configuration management cm provides a discipline for identifying controlling and tracking 
  work products such as test plans test strategies test conditions test cases test scripts test results test 
  logs and test reports as configuration items 
  v4.0 
  page 54 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
  for a complex configuration item e.g. a test environment cm records the items it consists of their 
  relationships and versions if the configuration item is approved for testing it becomes a baseline and 
  can only be changed through a formal change control process 
  configuration management keeps a record of changed configuration items when a new baseline is 
  created it is possible to revert to a previous baseline to reproduce previous test results 
  to properly support testing cm ensures the following  
    all configuration items including test items individual parts of the test object are uniquely 
  identified version controlled tracked for changes and related to other configuration items so that 
  traceability can be maintained throughout the test process  
    all identified documentation and software items are referenced unambiguously in test 
  documentation 
  continuous integration continuous delivery continuous deployment and the associated testing are 
  typically implemented as part of an automated devops pipeline see section 2.1.4 in which automated 
  cm is normally included 
  5.5 defect management 
  since one of the major test objectives is to find defects an established defect management process is 
  essential although we refer to defects here the reported anomalies may turn out to be real defects or 
  something else e.g. false positive change request this is resolved during the process of dealing with 
  the defect reports anomalies may be reported during any phase of the sdlc and the form depends on 
  the sdlc at a minimum the defect management process includes a workflow for handling individual 
  anomalies from their discovery to their closure and rules for their classification the workflow typically 
  comprises activities to log the reported anomalies analyze and classify them decide on a suitable 
  response such as to fix or keep it as it is and finally to close the defect report the process must be 
  followed by all involved stakeholders it is advisable to handle defects from static testing especially static 
  analysis in a similar way  
  typical defect reports have the following objectives 
    provide those responsible for handling and resolving reported defects with sufficient information 
  to resolve the issue 
    provide a means of tracking the quality of the work product 
    provide ideas for improvement of the development and test process 
  a defect report logged during dynamic testing typically includes 
    unique identifier 
    title with a short summary of the anomaly being reported 
    date when the anomaly was observed issuing organization and author including their role  
 
  identification of the test object and test environment 
    context of the defect e.g. test case being run test activity being performed sdlc phase and 
  other relevant information such as the test technique checklist or test data being used 
  v4.0 
  page 55 of 74 
  2023 04 21 
  © international software testing qualifications board 
  certified tester 
  foundation level 
    description of the failure to enable reproduction and resolution including the steps that detected 
  the anomaly and any relevant test logs database dumps screenshots or recordings 
    expected results and actual results 
    severity of the defect degree of impact on the interests of stakeholders or requirements 
    priority to fix 
    status of the defect e.g. open deferred duplicate waiting to be fixed awaiting confirmation 
  testing re opened closed rejected 
    references e.g. to the test case 
  some of this data may be automatically included when using defect management tools e.g. identifier 
  date author and initial status document templates for a defect report and example defect reports can be 
  found in the iso iec ieee 29119 3 standard which refers to defect reports as incident reports 
  v4.0 
